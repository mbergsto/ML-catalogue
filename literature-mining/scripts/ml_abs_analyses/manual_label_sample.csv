doi,category,clean_abs
10.1016/j.ijpx.2020.100041,supervised,"The implementation of a marker-supported watershed transformation enabled the reliable segmentation of the pellet population for the 3D analysis of individual pellets. Isolated translation- and rotation-invariant object cross-sections expanded the applicability to additional 2D image analysis techniques. The full structural characterisation gave access to over 200 features quantifying aspects of the pellets' size, shape, porosity, surface and orientation. The extracted features were assessed using a ReliefF feature selection method and a supervised Support Vector Machine learning algorithm to build a model for the detection of broken pellets within each capsule. Data of three features from distinct structure-related categories were used to build classification models with an accuracy of more than 99.55% and a minimum precision of 86.20% validated with a test dataset of 886 pellets. This approach to extract quantitative information on particle quality attributes combined with advanced data analysis strategies has clear potential to directly inform manufacturing processes, accelerating development and optimisation."
10.3390/app15126418,supervised,"Masked cold spray additive manufacturing (CSAM) is investigated for fabricating nickel-based electrodes with pyramidal pin-fins that enlarge the active area for the hydrogen-evolution reaction (HER). To bypass the high cost of purely CFD-driven optimization, we construct a two-stage machine learning (ML) framework trained on 48 high-fidelity CFD simulations. Stage 1 applies sampling and a K-nearest-neighbor kernel-density-estimation algorithm that predicts the spatial distribution of impacting particles and re-allocates weights in regions of under-estimation. Stage 2 combines sampling, interpolation and symbolic regression to extract key features, then uses a weighted random forest model to forecast particle velocity and temperature upon impact. The ML predictions closely match CFD outputs while reducing computation time by orders of magnitude, demonstrating that ML-CFD integration can accelerate CSAM process design. Although developed for a masked setup, the framework generalizes readily to unmasked cold spray configurations."
10.1007/s42979-025-04428-w,supervised,"2025.Predictive data analytics (PDA) and Machine learning (ML) into IoT sensor networks facilitates the generation of real-time insights and enables proactive decision-making. By analyzing vast arrays of sensor data such as temperature, humidity, and motion these technologies enhance operational efficiency, predict equipment failures, and identify anomalies. Advances in wireless sensor networks and micro-electromechanical systems have made these networks more practical and valuable, particularly in manufacturing, healthcare, and smart cities. Employing sophisticated algorithms like ARIMA for time-series forecasting and OMLEA for model optimization improves forecast accuracy and resource management. Effective data preparation using methods such as Genetic Algorithms and Particle Swarm Optimization (PSO) ensures the use of high-quality data for model training. Among various machine learning models, the Naive Bayes classifier excels in IoT sensor network applications, achieving an impressive 99.86% accuracy and a 99.91% F1-score, outperforming other models in recall and balance between real positives and false positives/negatives. The results demonstrated the potential of ML and PA to drive innovation and efficiency in IoT environments, despite challenges related to data quality, scalability, and privacy."
10.1117/12.3006709,supervised,"Accompanying the microfabrication and the complexity of the semiconductor manufacturing process, measurement and inspection using a scanning electron microscope (SEM) have become increasingly important for semiconductor manufacturing. Therefore, we have introduced an image denoising algorithm based on supervised deep learning with measurements for model training that transform a low signal-to-noise ratio (S/N) SEM image into a high S/N one, thereby improving the measurement success rate and maintaining measurement precision. Our experimental results demonstrated its effectiveness by an algorithm for enhancing throughput. However, performance may degrade when dealing with images containing features not included in the training dataset because deep learning models generally rely on trained features. Therefore, we propose high throughput CD-SEM metrology using image denoising based on deep learning that include a technique to statistically monitor deviations from the training images during model operation. In this study, we mainly discuss about monitoring module. To verify effectiveness of our proposed monitoring module, we first acquired sets of normal images used for training a deep learning model and sets of deviated images in which the SEM imaging recipe was partially changed. Then, the distribution of statistical values for noise and brightness features in the normal image set was used as a reference to compare the deviated image sets by the proposed method. As a result, the detection rate of the deviated images achieves 100%, and the false detection rate achieve 0% by combining of multiple statistical value distributions. By detecting deviated images that may degrade measurement performance, it is possible to maintain measurement precision and operate high-throughput measurement by using a denoising model based on deep learning."
10.1109/ICCRTEE64519.2025.11052989,supervised,"The agricultural sector sustains economic growth in a major way for nations especially those with a large rural population such as India. The process of selecting crops requires evaluating different factors involving production levels together with market trends and governmental rules. A combination of nutrient deficits together with soil erosion as well as modifications in climate pose significant effects on farmers' crop yields. The research utilizes machine learning to make accurate crop yield predictions to resolve current challenges. Historical data integration and crop characteristics and environmental variables enables this method to perform a supervised learning algorithm assessment. Various algorithm performances are evaluated throughout the study while the latter case demonstrates Root Mean Squared error and Mean Absolute Error with R-squared Score metrics through using Entropy and Gini Index assessment criteria. The main objective is to develop machine learning models which accurately predict yield results in agriculture. The study conducts an extensive exploration of vital factors including the climate and soil conditions along with irrigation systems and crop management practices to find suitable models for various agricultural areas. The core goal exists to present exclusive information about agricultural resource organization and planning methods. The project implements an orderly method that starts with feature engineering before proceeding to exploration data analysis then data pretreatment followed by model selection. Various supervised learning algorithms including Gradient Boosting Regressor, Random Forest Regressor, Ridge, and Linear Regression benefit from performance metric assessment for their effectiveness. Three ML algorithms integrated to process all datasets produced the most accurate yield prediction model with R2 value 0.95 and RMSE at 25.93 and MAE at 1.999."
10.3390/ijms231810404,supervised,"Soil-available nitrogen is the main nitrogen source that plants can directly absorb for assimilation. It is of great significance to detect the concentration of soil-available nitrogen in a simple, rapid and reliable method, which is beneficial to guiding agricultural production activities. This study confirmed that Raman spectroscopy is one such approach, especially after surface enhancement; its spectral response is more sensitive. Here, we collected three types of soils (chernozem, loess and laterite) and purchased two kinds of nitrogen fertilizers (ammonium sulfate and sodium nitrate) to determine ammonium nitrogen (NH4-N) and nitrate nitrogen (NO3-N) in the soil. The spectral data were acquired using a portable Raman spectrometer. Unique Raman characteristic peaks of NH4-N and NO3-N in different soils were found at 978 cm−1 and 1044 cm−1, respectively. Meanwhile, it was found that the enhancement of the Raman spectra by silver nanoparticles (AgNPs) was greater than that of gold nanoparticles (AuNPs). Combined with soil characteristics and nitrogen concentrations, Raman peak data were analyzed by multiple linear regression. The coefficient of determination for the validation ((Formula presented.)) of multiple linear regression prediction models for NH4-N and NO3-N were 0.976 and 0.937, respectively, which deeply interpreted the quantitative relationship among related physical quantities. Furthermore, all spectral data in the range of 400–2000 cm−1 were used to establish the partial least squares (PLS), back-propagation neural network (BPNN) and least squares support vector machine (LSSVM) models for quantification. After cross-validation and comparative analysis, the results showed that LSSVM optimized by particle swarm methodology had the highest accuracy and stability from an overall perspective. For all datasets of particle swarm optimization LSSVM (PSO-LSSVM), the (Formula presented.) was above 0.99, the root mean square errors of prediction (RMSEP) were below 0.15, and the relative prediction deviation (RPD) was above 10. The ultra-portable Raman spectrometer, in combination with scatter-enhanced materials and machine learning algorithms, could be a promising solution for high-efficiency and real-time field detection of soil-available nitrogen."
10.1016/j.mfglet.2023.08.127,supervised,"0 technologies such as Big Data, Internet of Things (IoT) devices, and Machine Learning (ML) has enabled a better connection with machines and factory systems. Data collection made it possible to apply the knowledge-based decision-making process more effectively and thoroughly. The Lean paradigm and the new technologies of Industry 4.0 must be used to build new models that give a competitive edge. This paper presents a new computer-based vision model for automated detection and classification of damaged packages from intact ones. In high-volume production environments, the package manual inspection process through the human eye consumes inordinate amounts of time poring over physical packages. Our proposed computer-based vision approach detects damaged packages to prevent them from moving to shipping operations that would otherwise incur waste in the form of wasted operating hours, wasted resources and lost customer satisfaction. The proposed approach was carried out on a data set consisting of 200 pairs of package images and has achieved high precision, accuracy, and recall values during the training and validation stage, with the resultant trained YOLO v7 model detecting and classifying damaged packages with an average testing precision of 75%."
10.1016/j.ijfatigue.2025.109020,supervised,"Traditional fatigue life prediction methods primarily rely on loading condition analysis and fail to fully account for the impact of manufacturing variations (such as raw material dimensions, process parameters, and joint deformations), which presents challenges for accurate fatigue life prediction. To address this issue, this paper proposes a fatigue life prediction method for MPC joints that combines point cloud measurement and machine learning (ML) models. Random sample consensus (RANSAC) and point cloud segmentation are used to extract the joint deformation contour precisely. Compared to metallographic analysis, this method achieved non-destructive extraction of joint deformation features. Based on this, an integrated dataset covering the entire process from raw materials to fatigue testing is established. Five machine learning models are trained and tested, with results showing that the gradient boosting regression trees (GBRT) model performs the best. The visualization of a single decision tree in the GBRT model is analyzed, providing a transparent decision-making process. A comparison is made between the GBRT model and the traditional Basquin model. In the GBRT model, 100% of the training set and 90% of the testing set fall within the 1.5 times error band, while only 45% of the training set and 60% of the testing set in the Basquin model fall within this range. Additionally, the GBRT model achieves a higher coefficient of determination (R2) on the dataset compared to the Basquin model."
10.1016/j.clwas.2025.100296,supervised,"Sixteen concrete mixtures were prepared with tap water and three types of secondary treated wastewater, varying the fly ash proportions (0 %, 10 %, 20 %, and 30 %). Workability, compressive strength, split tensile strength, and flexural strength were assessed for each mixture. Five machine learning models Linear Regression, LASSO Regression, Decision Tree Regression, Random Forest Regression, and Multi-Layer Perceptron were used to predict concrete's mechanical properties. The results show that M30 grade concrete can be effectively produced using secondary treated wastewater and fly ash, presenting a promising strategy for more sustainable concrete production by reducing freshwater usage and incorporating fly ash as a supplementary cementitious material. Notably, the Random Forest Regressor demonstrated superior prediction accuracy for compressive strength, outperforming the other models and proving to be an invaluable tool for optimizing concrete mix designs. Its ability to reliably predict concrete strength properties ensures higher accuracy in mix design formulation, which is critical for achieving desired performance while minimizing material waste. From a sustainability perspective, using secondary treated wastewater in concrete production significantly reduces the demand for freshwater, conserving this precious resource. Incorporating fly ash, a byproduct of coal combustion, not only enhances concrete properties but also helps divert industrial waste from landfills, reducing environmental impact. The application of machine learning models, especially the Random Forest Regressor, allows for more precise and efficient mix designs, further contributing to the sustainability of concrete production. This approach offers substantial environmental benefits by reducing water usage, promoting recycling of industrial byproducts, and improving the overall efficiency of concrete manufacturing processes."
10.1007/978-3-031-87959-3_11,supervised,"For assessing the safety performance of a structure in service, the ultimate pile bearing capacity is an important parameter. The literature indicates that experimental data on pile bearing capacity can be utilized to make quick and accurate predictions. Random forest is employed for these predictions, while five distinct algorithms are utilized to optimize the process: PSO, SSA, WSO, GWO, and DBO are all optimization algorithms used in engineering and computer science. These algorithms are designed to solve complex optimization problems by mimicking the behavior of animals in their natural habitats. An unused subset is selected randomly and evaluated with appropriate metrics to assess the model. Based on the results, the R2 values for the five models are 0.9103, 0.8766, 0.9410, 0.9133, and 0.9687 for RF-PSO, RF-SSA, RF-WSO, RF-GWO and RF-DBO. As far as Mean Absolute Percentage (MAP) is concerned, the RF-DBO model has the lowest optimal MAP. The RF-DBO prediction model has the lowest RMSE (3.6232) and MAPE among all models, making it the most accurate, stable, and effective in predicting pile capacity. It outperforms the RF-PSO, RF-WSO, and RF-GWO models in these categories."
10.1007/s00704-022-03983-z,supervised,"Climate directly and indirectly influences agriculture, being the main responsible for low and high yields. Prior knowledge on yield helps coffee farmers in their decision-making and planning for the future harvest, avoiding unnecessary costs and losses during the harvesting process. Thus, we sought to predict coffee yield with regressive models using meteorological data of the state of Paraná, Brazil. This study was carried out in 15 localities that produce Coffea arabica in this Brazilian state. The climate data were collected using the NASA/POWER platform from 1989 to 2020, while the data of arabica coffee yield (bags/ha) were obtained by CONAB from 2003 to 2018. The Penman–Monteith method was used to calculate the reference evapotranspiration and the climatological water balance (WB) was calculated based on Thornthwaite and Mather (1955). Multiple linear regression was used in the data modeling, in which C. arabica yield was the dependent variable and air temperature, precipitation, solar radiation, water deficit, water surplus, and soil water storage were the independent variables. The comparison between the estimation models and the actual data was performed using the statistical indices RMSE (accuracy) and adjusted coefficient of determination (R2adj) (precision). Multiple linear regression models can predict arabica coffee yield in the state of Paraná 2 to 3 months before harvest. The maximum air temperature is the climate element that most influences coffee plants, especially during fruit formation (March). Maximum air temperatures of 31.01 °C in March can reduce coffee production. Wenceslau Braz, Jacarezinho, and Ibaiti presented the highest yields, with mean values of 32.5, 29.9, and 29.3 bags ha−1, respectively. The models calibrated for localities that have Argisol had the highest mean accuracy, with an RMSE of 2.68 bags ha−1. The best models were calibrated for Paranavaí (Latosol), with an RMSE of 0.78 bags ha−1 and R2adj of 0.89, and Ibaiti (Argisol), with RMSE and R2adj values of 3.09 bags ha−1 and 0.83, respectively. Paranavaí has a mean difference between the actual and estimated coffee yield of only 0.86 bags ha−1. The highest deviations were observed in Wenceslau Braz (9.17 bags ha−1) and the lowest deviations were found in Paranavaí (0.86 bags ha−1). The models can be used to predict arabica coffee yield, assisting the planning of coffee farmers in the northern region of the state of Paraná."
10.4018/978-1-6684-6418-2.ch007,supervised,"Sustainable agriculture means an integrated agricultural system (IAS), which is a prolonged or long-term support system that fulfils the requirements of agricultural products, improves the environment (by controlling, improving, and monitoring natural biological cycles), and boosts the economy. Crop product quality and quantity have increased significantly over the last half-century, owing in large part to organic chemistry. Organic chemistry, however, remains a key component of crop protection and helps to create techniques to boost crop output. In the modern era of technology, artificial intelligence approaches are used for the analysis of soil nutrients and their optimal management on the basis of supervised learning, depending on behaviour analysis and prior experience. Soil nutrients are an essential component of soil fertility and environmental sustainability. This chapter will cover soil nutrient measurements, water irrigation, and predator control through artificial intelligence techniques such as decision making, artificial neural networks, and machine learning."
10.1021/acs.iecr.5c00726,supervised,"This study proposes a multiscale framework combining machine learning and molecular modeling to identify optimal C2H6-selective metal–organic frameworks (MOFs) for this separation. A database of 505,973 experimental/hypothetical MOFs underwent geometric/chemical prescreening (254,500 retained). Grand canonical Monte Carlo (GCMC) simulations on sampled MOFs trained a Random Forest model to predict adsorption behaviors, enabling rapid screening of the remaining candidates. This yielded 14,927 MOFs verified using GCMC, with 10 top performers selected. Process-level evaluation via vacuum pressure swing adsorption modeling confirmed their robustness under industrial conditions (varying temperatures, pressures, and gas compositions). Comparative analysis demonstrated superior performance over literature-reported MOFs, particularly under realistic operational parameters. The integrated approach establishes an efficient pathway for MOF discovery, bridging molecular properties with industrial process requirements while reducing reliance on energy-intensive distillation."
10.1007/978-3-031-20716-7_27,supervised,"To preserve raw bovine hides (skins) and prevent them from decaying, they must pass through several processes to become tanned or finished leather. Owing to the sheer size of the industry, there can be many unavoidable causes of surface defects sustained during the manufacturing process as well as the life-span of the bovine itself. Currently, the industry continues to rely on a visual inspection and classification process to assess the number, size, type and placement of common defects. Based on these characteristics a trained technician is able to determine the product quality or ‘grade’ of the materials. However, it has been found that inconsistent grading occurs due to the unreliability in the technician’s decision-making ability. Although seldom applied in leather manufacturing processes, the application of computer vision and machine learning algorithms would greatly reduce the possibility of human-error and decrease the classification time while improving the accuracy and ultimately optimising the efficiency of the overall process. This paper provides an overview of various related architectures, techniques, and methods specifically applied to the task of leather surface defect detection and localisation as well as anomaly detection methods for the purposes of the detection of surface defects in unrelated image domains. A discussion of various aspects required in dealing with this challenge is included as well as recommendations for a possible novel solution."
10.3389/fvets.2017.00002,supervised,"Between-farm animal movement is one of the most important factors influencing the spread of infectious diseases in food animals, including in the US swine industry. Understanding the structural network of contacts in a food animal industry is prerequisite to planning for efficient production strategies and for effective disease control measures. Unfortunately, data regarding between-farm animal movements in the US are not systematically collected and thus, such information is often unavailable. In this paper, we develop a procedure to replicate the structure of a network, making use of partial data available, and subsequently use the model developed to predict animal movements among sites in 34 Minnesota counties. First, we summarized two networks of swine producing facilities in Minnesota, then we used a machine learning technique referred to as random forest, an ensemble of independent classification trees, to estimate the probability of pig movements between farms and/or markets sites located in two counties in Minnesota. The model was calibrated and tested by comparing predicted data and observed data in those two counties for which data were available. Finally, the model was used to predict animal movements in sites located across 34 Minnesota counties. Variables that were important in predicting pig movements included between-site distance, ownership, and production type of the sending and receiving farms and/or markets. Using a weighted-kernel approach to describe spatial variation in the centrality measures of the predicted network, we showed that the south-central region of the study area exhibited high aggregation of predicted pig movements. Our results show an overlap with the distribution of outbreaks of porcine reproductive and respiratory syndrome, which is believed to be transmitted, at least in part, though animal movements. While the correspondence of movements and disease is not a causal test, it suggests that the predicted network may approximate actual movements. Accordingly, the predictions provided here might help to design and implement control strategies in the region. Additionally, the methodology here may be used to estimate contact networks for other livestock systems when only incomplete information regarding animal movements is available."
10.3390/en16176172,supervised,"Subsea power cables are critical assets for electrical transmission and distribution networks, and highly relevant to regional, national, and international energy security and decarbonization given the growth in offshore renewable energy generation. Existing condition monitoring techniques are restricted to highly constrained online monitoring systems that only prioritize internal failure modes, representing only 30% of cable failure mechanisms, and has limited capacity to provide precursor indicators of such failures or damages. To overcome these limitations, we propose an innovative fusion prognostics approach that can provide the in situ integrity analysis of the subsea cable. In this paper, we developed low-frequency wide-band sonar (LFWBS) technology to collect acoustic response data from different subsea power cable sample types, with different inner structure configurations, and collate signatures from induced physical failure modes as to obtain integrity data at various cable degradation levels. We demonstrate how a machine learning approach, e.g., SVM, KNN, BP, and CNN algorithms, can be used for integrity analysis under a hybrid, holistic condition monitoring framework. The results of data analysis demonstrate the ability to distinguish subsea cables by differences of 5 mm in diameter and cable types, as well as achieving an overall 95%+ accuracy rate to detect different cable degradation stages. We also present a tailored, hybrid prognostic and health management solution for subsea cables, for cable remaining useful life (RUL) prediction. Our findings addresses a clear capability and knowledge gap in evaluating and forecasting subsea cable RUL. Thus, supporting a more advanced asset management and planning capability for critical subsea power cables."
10.18280/mmep.110414,supervised,"This article is published by IIETA and is licensed under the CC BY 4.0 license ( large-scale manufacturing, ensuring the efficient operation of rotating machines is crucial to avoid breakdowns and failures during production. This article introduces a method for detecting gearbox faults by analyzing vibration signals and employing artificial intelligence techniques, with a particular emphasis on comparing these methods. The diagnostic process consists of three stages: extracting features using Wavelet Packet Transform (WPT) and statistical analysis, selecting optimal properties through the gain ratio method, and using Support Vector Machine (SVM) and Artificial Neural Network (ANN) models to distinguish between faults and assess their performance. The diagnostic outcomes demonstrate that both SVM and ANN models accurately identify various fault patterns depending on the operating conditions. Remarkably, the study highlights the ANN model's superiority over the SVM model in classifying gearbox faults, indicating its suitability for gearbox fault diagnosis. This research yields valuable insights into machine condition monitoring, showcasing the ANN model as a robust tool for gearbox fault detection. The findings advocate for the implementation of ANN-based approaches in real-world applications to enhance the reliability of fault detection and prevention in rotating machines. Furthermore, future research directions may explore additional enhancements and optimizations for ANN models, leading to more advanced machine health monitoring systems in the manufacturing industry."
10.1109/ICCC57093.2023.10178944,supervised,"The hydrophone, also known as an underwater microphone, is placed in industrial tanks and converts sounds under water (or other liquids) into an electrical analogue signal. The bandwidth is typically the audible range, but they can also operate in the ultrasonic range, up to 1 MHz. The analogue signal from the hydrophone is digitized and the time-domain wave file is processed using Fast Fourier Transform to produce a power spectrogram, which is one of the key inputs for further data and signal processing. Artificial Intelligence Deep-Learning techniques help in the machine processing of large amounts of data and automatic classification. The Python package Librosa utilized for the features extraction of audio files. The waterfall spectrogram and RMS are basic tools in this analysis. The csv, numpy and pandas python packages are used to convert.wav files into.csv files on which data processing can be performed. The sklearn python package is used for preprocessing, and the keras and tensorflow python packages are used for model training and evaluation, and for building the neural networks. The trained model can be used to estimate which previous classified type a new sound sample may belong to. The precision of the model improved by raising the number of samples, but only to a certain limit, which must be determined appropriately."
10.1007/978-3-030-86737-9_7,supervised,"Metal additive manufacturing allows for the fabrication of parts at the point of use as well as the manufacture of parts with complex geometries that would be difficult to manufacture via conventional methods (milling, casting, etc.). Additively manufactured parts are likely to contain internal defects due to the melt pool, powder material, and laser velocity conditions when printing. Two different types of defects were present in the CT scans of printed AlSi10Mg dogbones: spherical porosity and irregular porosity. Identification of these pores via a machine learning approach (i.e., support vector machines, convolutional neural networks, k-nearest neighbors’ classifiers) could be helpful with part qualification and inspections. The machine learning approach will aim to label the regions of porosity and label the type of porosity present. The results showed that a combination approach of Canny edge detection and a classification-based machine learning model (k-nearest neighbors or support vector machine) outperformed the convolutional neural network in segmenting and labeling different types of porosity."
10.2118/224387-MS,supervised,"Copyright 2025, Society of Petroleum Engineers.The classification of cutter damage in polycrystalline diamond compact (PDC) drill bits has historically relied on manual dull grading, a process that is time-intensive, subjective, and inconsistent. This study introduces an automated classification approach leveraging machine learning and high-resolution imaging to improve the assessment of PDC cutter wear and failure in Delaware Basin vertical applications. A robotically controlled imaging system captures detailed cutter images before repair, feeding data into a convolutional neural network trained to recognize over ten distinct failure modes. The model employs multilabel classification to identify primary and secondary damage mechanisms, enabling a more comprehensive analysis of cutter degradation. By integrating these classifications with operational drilling parameters- including weight on bit, rate of penetration, torque, and cutter velocity-this study reveals key correlations between cutter damage and drilling conditions. The results indicate that lower weight on bit and higher cutter velocity contribute to secondary failure mechanisms, suggesting that improper engagement with the formation increases cutter instability. Additionally, a strong negative correlation between diamond removal percentage and secondary damage presence suggests that multi-modal failures often emerge before extreme cutter degradation occurs. Cutters exhibiting secondary damage tend to experience more rapid wear, reinforcing the need for early intervention strategies. Multi-modal failures were found to reduce total footage drilled per bit, indicating a direct operational impact that could be mitigated through improved parameter selection. The study demonstrates that automated classification not only enhances the accuracy and consistency of cutter damage assessment but also enables proactive decision-making in bit design and drilling operations. By leveraging machine learning-driven classification with real-time operational data, operators can reduce nonproductive time, improve bit longevity, and refine drilling practices based on objective, scalable damage assessments. The integration of machine learning with operational data provides an opportunity to develop predictive maintenance strategies, helping to prevent catastrophic cutter failure. Future advancements may incorporate real-time imaging systems for on-rig damage monitoring, allowing for dynamic drilling parameter adjustments that further improve efficiency, cost reduction, and bit performance longevity."
10.1016/j.neucom.2019.03.081,supervised,"In this context, data analysis can significantly improve the state-of-the-art techniques, employed, for instance, to determine if a particular component or product is showing an anomalous behavior with respect to a defined nominal state. In fact, through the analysis of data collected on field, it is possible to detect optimal operating regions and to detect anomalies in advance. In this context, we propose a multi-purpose algorithm for unsupervised or semi-supervised learning in order to determine a simple continuous region of points. This region can be adopted in order to describe a component or a product nominal behavior and can be used in order to detect anomalies which are outside it. Such a region can be defined adopting a finite ensemble of thresholds, whose value can be physically interpreted. In order to show the effectiveness of our approach, the proposed method has been tested in an Anomaly Detection problem concerning Predictive Maintenance, exploiting data coming from a naval vessel, characterized by a combined diesel-electric and gas propulsion plant."
10.1109/ICACRS62842.2024.10841592,supervised,"Electricity price prediction is crucial for businesses reliant on heavy machinery or computing services, as it aids in cost management and energy optimization. Accurate predictions allow these businesses to forecast annual electricity expenses, enhancing cost efficiency. This project aims to forecast electricity prices using machine learning techniques, specifically the Random Forest regression algorithm. The project utilizes historical data on electricity consumption and other influencing factors, including date and time, holiday indicators, day of the week, week of the year, forecasted and actual wind production, national load, temperature, wind speed, and CO2 intensity. The methodology involves converting string values to numerical values, handling missing data, and normalizing the dataset, identifying key features that significantly impact electricity prices, Splitting the data into training and testing sets, and training the model using the Random Forest regression algorithm and assessing the model's performance with appropriate metrics to ensure accuracy and reliability. The results demonstrate that the Random Forest model effectively predicts electricity prices with high accuracy. Visualizing these predictions in Power BI provides intuitive insights into the factors influencing electricity prices. These findings enable businesses to better anticipate electricity expenses, optimize energy usage, and improve financial planning. The comprehensive approach outlined in this project offers a valuable tool for understanding and forecasting electricity prices, thereby enhancing resource management and cost efficiency."
10.1109/WSC57314.2022.10015322,supervised,"The article looks to generate synthetic data for machine learning algorithms using discrete-event simulation (DES). The case study used for the DES model was the Composite Centre at the AMRC, where prototype composites products are manufactured. The machine learning algorithm was used to predict the lead times of composite products based on the current state of the system. The machine learning algorithm can calculate the lead times much faster than a simulation model and does not require the expertise of a simulation engineer to execute. Three different types of composites materials and their manufacturing process were initially modelled: dry fiber, prepreg and thermoplastic. The accuracies of three machine learning algorithms were compared. The algorithms chosen were: Artificial Neural Network (ANN), Recurrent Neural Network (RNN) and linear regression. It was found that the RNN provided the most accurate predictions and the linear regression algorithm was the worst performing algorithm."
10.1007/s00170-023-10928-x,supervised,", part of Springer Nature.Data obtained from additive manufactured components can be analyzed to gain a better understanding of the manufacturing physics and to improve the quality of the parts. However, additive manufacturing is a complex process with many sensitivities. Machine learning has recently been used in additive manufacturing to model and evaluate processes. It is not possible to provide a single regression model to predict mechanical behavior as the properties will vary based on the component geometry and in regions within a component. To provide a separate regression model for each region, it is better to categorize several regions for multiple geometries by their post- fabrication properties (maximum and minimum principal stresses and distortion). Clustering is a method for analyzing the quality of parts with similar characteristics in diverse areas. Twenty-three distinct geometries with numerous geometric characteristics, each experiencing a different history of heat during fabrication (due to their thickness and material distribution), are analyzed in this study. Three different clustering methods are employed (self-organizing map, k-means clustering, and fuzzy c-means clustering). The results are presented in two parts. For the first case, a localized approach is taken, where a comprehensive data set is utilized. The observed maximum coefficient of variance is 0.07969. For the second case, each shape is considered as an instance (sample) with general geometric characteristics. Similar trends between different clustering methods were extracted for the global approach, highlighting the potential of this method, but the clustering results are dependent on the clustering method. According to these results, the analysis of the local data provides a deeper understanding of post-fabrication properties clustering. Additional geometric-based characteristics will be developed to refine and improve the global approach."
10.1016/j.petrol.2020.107981,supervised,"V.Waterflood has been widely applied across the world as the most important secondary recovery process to improve reservoir performance. The schemes applied to waterflood projects involve key decision-making which aims to maximize the net present value (NPV) for a given period, improve recovery and sweep efficiency, maintain reservoir pressure, reduce water production, and avoid water recycling. Traditionally, the preferred approach to estimate the future performance of any given waterflood project is through the numerical reservoir simulation. However, despite the great power and intuition associated with the simulation models, sometimes this potential is unachievable due to massive computational requirements. Also, in some other cases, there may exist no simulation model to begin with. To tackle these problems, data-driven proxy models are proposed. In this research, we propose a novel machine-learning-based proxy model for waterflood performance prediction and further apply it for production optimization purpose to obtain the optimal future well control. The data-driven model is realized using the Echo State Network (ESN) under the paradigm of “Reservoir Computing” (RC). Compared with traditional ESNs, this specific methodology includes a feedback loop from the output into the high dimensional “reservoir” to achieve improved prediction results for separated phase production rates. Teacher Forcing (TF) technique is used for easier incorporation of the feedback information without introducing additional recurrent loops during the training process. Furthermore, training ESN proxy models utilizes Ridge Regression, thus all calculations within have analytical solutions that guarantee much improved speed when evaluating forward model-runs, which further lowers the computational demand during the optimization process. The proposed workflow is typically more suitable for mature fields since reliable production data after breakthrough from each producer could greatly improve the training process, and it can be used under the circumstance where no reservoir model has been established. In this research, we present two test examples where we apply ESN to learn the reservoir simulation results of waterflood and further perform open-loop optimization on each of them."
10.1109/ICSPC50992.2020.9305776,supervised,"Data privacy has been an important area of research in recent years. Dataset often consists of sensitive data fields, exposure of which may jeopardize interests of individuals associated with the data. In order to resolve this issue, privacy techniques can be used to hinder the identification of a person through anonymization of the sensitive data in the dataset to protect sensitive information, while the anonymized dataset can be used by the third parties for analysis purposes without obstruction. In this research, we investigated a privacy technique, k-anonymity for different values of k on different number c of columns of the dataset. Next, the information loss due to k-anonymity is computed. The anonymized files go through the classification process by some machine-learning algorithms i.e., Naive Bayes, J48 and neural network in order to check a balance between data anonymity and data utility. Based on the classification accuracy, the optimal values of k and c are obtained, and thus, the optimal k and c can be used for k-anonymity algorithm to anonymize optimal number of columns of the dataset."
10.3390/agronomy11081584,supervised,"The aim of this study was to identify an efficient agrophotovoltaic (APV) system structure for generating electricity from solar radiation without causing an adverse impact on crop growth. In a temperate climate region, it is critical to design an APV system with appropriate structure with the maximum amount of electricity generation because, unlike in desert areas, strong solar radiation is only available for a few hours a day. In this study, APV systems with three different shading ratios (i.e., 32%, 25.6%, and 21.3%) were considered, and the optimum structure in terms of electricity efficiency and profitability was investigated via nonlinear programming. Moreover, an estimation model of electricity generation was developed via a polynomial regression model based on remote sensing data given by the APV system located at Jeollanamdo Agricultural Research and Extension Services in South Korea. To evaluate the impact of the APV on crop production, five different grain crops—sesame (Sesamum indicum), mung bean (Vigna radiata), red bean (Vigna angularis), corn (Zea mays), and soybean (Glycine max)—were cultivated in the system. As a result, the proposed optimization model successfully identified the best APV system structure without reducing existing crop production."
10.1002/bit.28338,supervised,"Biotechnology and Bioengineering published by Wiley Periodicals LLC.Obtaining in situ measurements of biological microparticles is crucial for both scientific research and numerous industrial applications (e.g., early detection of harmful algal blooms, monitoring yeast during fermentation). However, existing methods are limited to offer timely diagnostics of these particles with sufficient accuracy and information. Here, we introduce a novel method for real-time, in situ analysis using machine learning (ML)-assisted digital inline holography (DIH). Our ML model uses a customized YOLOv5 architecture specialized for the detection and classification of small biological particles. We demonstrate the effectiveness of our method in the analysis of 10 plankton species with equivalent high accuracy and significantly reduced processing time compared to previous methods. We also applied our method to differentiate yeast cells under four metabolic states and from two strains. Our results show that the proposed method can accurately detect and differentiate cellular and subcellular features related to metabolic states and strains. This study demonstrates the potential of ML-driven DIH approach as a sensitive and versatile diagnostic tool for real-time, in situ analysis of both biotic and abiotic particles. This method can be readily deployed in a distributive manner for scientific research and manufacturing on an industrial scale."
10.1063/5.0265097,supervised,"Preventative protection has been a vital topic of consciousness among producers for years, assisting to locate energetic device problems earlier than they escalate. In this paper we gift a controversy for the use of system domains for predictive optimization in production control. We demonstrate that system learning can notably improve hardware failure prediction accuracy the usage of multiple algorithms together with random forests, gradient boosting, and deep learning. Our have a look at effects display that predictive preservation can reduce person studying time and preservation, at the same time as increasing the general performance of operations. The outcomes of this mission can offer precious facts to manufacturers trying to put in force predictive optimization strategies and integrated computer expertise in their safety control plans."
10.1109/I-SMAC61858.2024.10714643,supervised,"The rapid development of satellite technology has resulted in an exponential growth in the availability of high-resolution satellite images, which presents both opportunities and challenges for image processing and classification. The study provides a comprehensive overview of the state-of-the-art techniques for satellite image processing and classification, with an emphasis on recent developments in machine learning and deep learning approaches. Understanding environmental dynamics, tracking weather trends, and assisting with disaster relief operations all depend on satellite imaging. Unfortunately, clouds frequently obscure these photos, making it challenging to precisely follow atmospheric conditions and analyse the Earth's surface. In order to improve weather forecasting and catastrophe management, the research work creates a satellite image processing system that uses machine learning to identify clouds, eliminate them, and forecast their movements.Numerous fields, including disaster management, agriculture, urban planning, environmental conservation, climate research, renewable energy, forestry, and geospatial intelligence, are greatly impacted by satellite image processing and cloud detection. Through the provision of enhanced, unobstructed satellite imagery and precise cloud movement forecasts, the project improves capacities for natural resource monitoring and management, better urban development, climate research assistance, energy production optimisation, forest protection, and defence operations support. Accurate satellite data analysis facilitates more informed decision-making, which in turn improves environmental management, readiness for disasters, and strategic planning in these vital areas."
10.1016/j.jmapro.2025.06.059,supervised,"However, this remains a challenge due to persistent data silos in hot strip rolling (HSR) and the limited interpretability of “black box” machine learning (ML) models in capturing complex multivariable interactions. This study developed a four-layer industrial digital twin platform to integrate multisource heterogeneous data into a unified dataset, including composition, process parameters and properties. A dataset reconstruction strategy was introduced to address the challenges posed by large-scale, nonlinear, and noise-prone data. Based on the reconstructed inputs, interpretable ML models were established to characterize the underlying composition-process-property relationships accurately. The light gradient boosting machine (LGBM) model, optimized using particle swarm optimization, achieved superior performance with an R2 of 0.80 and a mean absolute error of 10.02 MPa on the test set. Shapley additive explanations and partial dependence plot analyses further revealed the combined effects of alloying elements, rolling temperature, and deformation on mechanical behavior. The proposed framework was successfully implemented on a 1422 mm HSR production line, providing real-time guidance for alloy design and reducing reliance on manual sampling."
10.1142/S0218625X24300077,supervised,"Digital technologies sustain today's world. Every part of the world is working towards digital technologies, which none of us can eliminate. Enormous growth is achieved only by unexpected acceleration by digital technologies, including the Internet of Everything (IoE), Artificial Neural Networks (ANN), Machine Learning (ML), Internet of Things (IoT), Artificial Intelligence (AI), Deep Learning (DL), and many more. These technologies started occupying all the engineering sectors, including manufacturing. This paper focuses on tribology analysis related to manufacturing concerning various digital manufacturing technologies. The paper narration includes Tribology using digital technologies wherein the journals and patent landscape analysis abet them. In trend, Tribology utilizes all these technologies today and envisages its growth with the predominant technological invention in the border view. The survey of various literature reveals that only three digital technologies, including AI, ML, and ANN, are used by tribologists around the globe. Other Technologies like Evolutionary Algorithm (EA), Support Vector Machine (SVM), and Adaptive Neuro-Fuzzy Interference Systems (ANFIS) are not used predominantly."
10.3390/en15186657,supervised,"Highlights: What are the main findings? A dataset of PEM water electrolysis was constructed for machine learning purposes. Machine learning can be used for optimal PEM water electrolyzer cell design. Adaptive degree prediction can be employed to optimize the polynomial regression models. What is the implication of the main finding? The proposed model can predict the cell design parameters for small-scale and commercial-scale PEM water electrolyzer cells. Optimal PEM water electrolyzer cell design can be modeled using polynomial regression and logistic regression machine learning models. We propose efficient multiple machine learning (ML) models using specifically polynomial and logistic regression ML methods to predict the optimal design of proton exchange membrane (PEM) electrolyzer cells. The models predict eleven different parameters of the cell components for four different input parameters such as hydrogen production rate, cathode area, anode area, and the type of cell design (e.g., single or bipolar). The models fit well as we trained multiple machine learning models on 148 samples and validated the model performance on a test set of 16 samples. The average accuracy of the classification model and the mean absolute error is 83.6% and 6.825, respectively, which indicates that the proposed technique performs very well. We also measured the hydrogen production rate using a custom-made PEM electrolyzer cell fabricated based on the predicted parameters and compared it to the simulation result. Both results are in excellent agreement and within a negligible experimental uncertainty (i.e., a mean absolute error of 0.615). Finally, optimal PEM electrolyzer cells for commercial-scaled hydrogen production rates ranging from 500 to 5000 mL/min were designed using the machine learning models. To the best of our knowledge, we are the first group to model the PEM design problem with such large parameter predictions using machine learning with those specific input parameters. This study opens the route for providing a form of technology that can greatly save the cost and time required to develop water electrolyzer cells for future hydrogen production."
10.3390/jmmp9020049,supervised,"Metal additive manufacturing (MAM) has advanced significantly, yet accurately predicting clad characteristics from processing parameters remains challenging due to process complexity and data scarcity. This study introduces a novel hybrid machine learning (ML) framework that integrates validated multi-physics computational fluid dynamics simulations with experimental data, enabling prediction of clad characteristics unattainable through conventional methods alone. Our approach uniquely incorporates physics-aware features, such as volumetric energy density and linear mass density, enhancing process understanding and model transferability. We comprehensively benchmark ML models across traditional, ensemble, and neural network categories, analyzing their computational complexity through Big O notation and evaluating both classification and regression performance in predicting clad geometries and process maps. The framework demonstrates superior prediction accuracy with sub-second inference latency, overcoming limitations of purely experimental or simulation-based methods. The trained models generate processing maps with 0.95 AUC (Area Under Curve) accuracy that directly guide MAM parameter selection, bridging the gap between theoretical modeling and practical process control. By integrating physics-based simulations with ML techniques and physics-aware features, our approach achieves an R2 of 0.985 for clad geometry prediction and improved generalization over traditional methods, establishing a new standard for MAM process modeling. This research advances both theoretical understanding and practical implementation of MAM processes through a comprehensive, physics-aware machine learning approach."
10.1109/ELECO60389.2023.10415994,supervised,"Electricity, a human necessity since the 19th century, has gained ever-increasing importance as the world population grows, set to reach 10 billion by 2050. The urgency for sustainable and nature-friendly energy production, as well as efficient consumption, parallels the rising demand. Rapid urbanization and industrialization are increasing energy needs and greenhouse gas emissions, prompting countries to reduce emissions through policies and environmental protocols. This study explores the challenges of integrating variable, and weather-dependent renewable energy sources into the grid, which necessitates accurate energy consumption prediction. The load consumption of various domestic users is aimed to be predicted and battery sizing is intended to be optimized accordingly. Data from 15 households of varying sizes with 1 minute resolution, spanning over a year with minute-resolution, was used. Machine learning models, including LSTM, Random Forest Regressor, XGBoost, and Linear Regression were employed, with temperature, holidays, and sunrise/sunset times identified as significant features. The study extends beyond load prediction, promoting consumer savings through variable electricity prices and advocating for battery use for reliable electricity supply. This work represents a pioneering effort in battery optimization based on load prediction data, facilitating a balanced, economical, and sustainable power system."
10.1007/s10845-024-02368-5,supervised,"Given a part design, the task of manufacturing process selection chooses an appropriate manufacturing process to fabricate it. Prior research has traditionally determined manufacturing processes through direct classification. However, an alternative approach to select a manufacturing process for a new design involves identifying previously produced parts with comparable shapes and materials and learning from them. Finding similar designs from a large dataset of previously manufactured parts is a challenging problem. To solve this problem, researchers have proposed different spatial and spectral shape descriptors to extract shape features including the D2 distribution, spherical harmonics (SH), and the Fast Fourier Transform (FFT), as well as the application of different machine learning methods on various representations of 3D part models like multi-view images, voxel, triangle mesh, and point cloud. However, there has not been a comprehensive analysis of these different shape descriptors, especially for part similarity search aimed at manufacturing process selection. To remedy this gap, this paper presents an in-depth comparative study of these shape descriptors for part similarity search. While we acknowledge the importance of factors like part size, tolerance, and cost in manufacturing process selection, this paper focuses on part shape and material properties only. Our findings show that SH performs the best among non-machine learning methods for manufacturing process selection, yielding 97.96% testing accuracy using the proposed quantitative evaluation metric. For machine learning methods, deep learning on multi-view image representations is best, yielding 99.85% testing accuracy when rotational invariance is not a primary concern. Deep learning on point cloud representations excels, yielding 99.44% testing accuracy when considering rotational invariance."
10.1007/s42107-025-01511-8,supervised,"Structural Health Monitoring (SHM) of bridges plays a pivotal role in sustaining infrastructure reliability and public safety. However, conventional vibration-based approaches encounter significant challenges such as susceptibility to environmental variability and heavy dependence on baseline data, which limit their effectiveness in complex operational environments. This systematic review aims to critically evaluate recent advancements in vibration-based SHM methodologies, with a focus on the integration of Artificial Intelligence (AI) and Machine Learning (ML) techniques from 2014 to 2025. A systematic literature review was conducted using Scopus as the primary database, guided by the PRISMA framework, encompassing 51 peer-reviewed journal articles published between 2014 and 2025. The findings highlight significant methodological advancements, including the application of supervised neural networks, unsupervised learning algorithms such as autoencoders, hybrid AI models integrating physics-informed neural networks (PINNs), and Bayesian approaches for uncertainty quantification. AI-driven methods demonstrated enhanced accuracy, robustness, and scalability, addressing critical limitations of conventional SHM systems. However, challenges persist, particularly in terms of computational complexity, the requirement for large labelled datasets, generalization across bridge types, and limited field-based validation. This study underscores the potential of hybrid AI approaches and identifies several research gaps. Future directions include enhanced field-based validations, integration of optimal sensor placement techniques, development of interpretable models, and predictive maintenance strategies incorporating Remaining Useful Life (RUL) estimation."
10.1109/ICTMIM65579.2025.10988363,supervised,"The performance and longevity of Electric Vehicle (EV) batteries are critical for advancing sustainable transportation. This study presents a data-driven machine learning approach to systematically compare Lithium-Ion and Nickel-Metal Hydride batteries using real-world data from the U.S. Department of Energy (DOE) Battery Data Hub. Unlike previous research, which primarily focuses on isolated performance metrics, our study integrates multiple factors such as energy density, charge rate, cycle life, and thermal stability. We employ advanced machine learning models-LSTM, XGBoost, and Random Forest-to predict battery state-of-charge and state-of-health with high accuracy, achieving R2 values above 0.97 in SOC estimation using LSTM. Our findings confirm that Li-ion batteries outperform NiMH in key performance areas, exhibiting higher energy density, slower degradation rates, and better thermal stability. The results offer crucial insights for battery selection in EV applications and highlight the potential of ML-driven approaches in battery management systems (BMS) to enhance real-time monitoring and predictive maintenance. By optimizing battery performance and reducing premature failures, this study contributes to the sustainable adoption of EV technology."
10.21872/2025IISE_6340,supervised,"All rights reserved.The production of defective products leads to substantial material and financial losses. It is critical to detect manufacturing defects as early as possible to reduce waste. To do so, many manufacturers have harnessed technology by installing sensors to monitor their production processes in real time. Nonetheless, a significant portion of the data collected by the sensors remains unanalyzed due to processing and analytical constraints, resulting in missed opportunities for early fault diagnosis and quality improvement. This research leverages real-time sensor data from Rea Magnet Wire, one of the world's largest manufacturers of magnet and nonferrous wire products, to identify process variables responsible for defects in the continuous manufacturing of copper wires. Due to the continuous nature of the manufacturing process, data alignment was performed prior to model training. Three machine learning models (Random Forest, XGBoost, and Logistic Regression) were implemented to predict faults in copper magnet wire production using 21 process variables obtained from real-time sensor data from their Lafayette plant. We observe that interactions between process variables are critical for fault diagnosis, given that nonlinear methods have better performance. Furthermore, we study the effect of process variables on quality measures using cumulative local effects."
10.1109/IMPACT55510.2022.10029154,supervised,"Rolling Element Bearing (REB) failure in heavy rotating machines or assembly lines might cause the machine to shut down, affecting the total cost and quality of the product. Bearing condition monitoring prevents failure and reduces the time and expense of preventative maintenance. With the advent of machine learning in the area of condition monitoring of mechanical systems, Artificial Neural Network (ANN) is becoming more widely used, redefining the state-of-the-art in defect diagnosis and classification. This work provides a real-time online fault detection approach for rolling bearings based on the ANN algorithm in order to realize the predictive maintenance of rolling element bearings in the industry. The training of the fault diagnostic model and the real-time fault diagnosis are the two primary steps of the procedure. The vibration signal is first preprocessed, which includes data categorization, data segmentation, and feature extraction before the defect diagnosis model is trained and optimized. The extraction of the characteristic features of the vibration signal is utilized to implement the online fault diagnosis through the fault diagnostic model. The fault data for analysis is accessed from the open-source Paderborn university bearing data. The fault categories taken are of multiple faults on the inner and the outer raceways. Optimization is carried out in the ANN model with regard to its number of hidden layers, size of the layers and the activation function to seek for a set of these parameters, which result in the best performance in diagnosing the bearing defects for the fault categories under consideration. The ANN approach is proved to be a useful technique for detecting faults and improving classification accuracy, making it more suitable for rolling bearing fault diagnosis. A maximum fault classification accuracy of 98.5% was achieved with a single hidden layer of size 25 and the Tanh activation function. The corresponding training time was 3.9831 seconds, and the prediction speed was found to be 24000 observations per second."
10.1145/3473714.3473821,supervised,"This paper builds a mathematical model based on data mining to study the related issues of fraud. This paper constructs a recognition model from two aspects of traditional recognition and intelligent algorithms, uses Logistic model, BP neural network model and decision tree model to identify fraudulent data in manufacturing, and uses confusion matrix to use classification accuracy, recall rate, and F value And accuracy and other indicators to evaluate the accuracy of recognition. Therefore, substitute manufacturing-related data into the recognition model, compare the recognition results of the three models, and select the model with the highest recognition accuracy to predict the sixth year of the manufacturing industry."
10.1109/ICoDSE53690.2021.9648445,supervised,"Automated Optical Inspection (AOI) machines inspect the Printed Circuit Board (PCB) manufacturing visually using a camera autonomously scans the device under test for both catastrophic failure (e.g. missing component) and quality defects (e.g. fillet size, shape or component skew). High false call rate is a fundamental concern of AOI machines that occurs when a component is considered as a 'fail' incorrectly that then have to be verified manually. In order to alleviate this problem, we train and compare different machine learning models (Decision Tree, Random Forest, K-Nearest Neighbors and Artificial Neural Network) and thresholds using logged fail data and extracting the efficient categorical and numerical features. The results show that the trained classifiers are able to identify the false calls well and increase the accuracy without increasing the error slip much. The K-Nearest Neighbor model, with a low threshold achieves the best result."
10.1016/j.engappai.2025.111430,supervised,"However, these faults have received relatively limited attention in the existing literature, particularly in terms of robust detection and classification approaches. This study proposes a sequential binary classification framework for multi-fault detection systems, focusing on transient Misfire and Firethrough faults. In contrast to a multi-classification scheme, an initial binary classification distinguishes healthy from faulty states, leading to a second classifier that discriminates intra-faults, improving detection accuracy. Statistical features alongside Shannon, Rényi, and Tsallis entropy were extracted, and a Sequential Feature Selector with Maximum Mean Discrepancy identifies the most informative features. Widely applicable machine learning tools in the field of fault detection have been selected to test the sequential binary-classification scheme with a multi-classification framework. Logistic Regression, k-Nearest Neighbors, Decision Tree, Support Vector Machine, Random Forest, Categorical Boosting, and Multi-Layer Perceptron are used with Bayesian hyperparameter optimization, and TabNet is optimized with Optuna. To achieve realistic operating conditions, randomness is introduced in fault occurrence, and Gaussian noise is superimposed on the signals. Results demonstrate that the sequential binary classification method outperforms direct multi-class approaches in detecting and identifying short-duration faults, enhancing predictive maintenance strategies in power electronics. By effectively isolating brief fault events, the proposed technique offers a computationally efficient solution that strengthens the reliability of electric vehicle systems and mitigates risks of severe damage."
10.1109/ACCESS.2018.2794685,supervised,"Cyber-Physical Systems (CPS) are integrations of computation, networking, and physical processes. Its process control is often referred to as embedded systems. Generally, CPS and Internet of Things have the same basic architecture, whereas the former shows a higher combination and coordination between physical and computational elements, i.e., wireless sensor networks can be a vital part of CPS applications. With the rapid development, CPS has been applied to healthcare industry, where a wide range of medical sensors are used within a healthcare organization. However, these sensors may generate a large number of false alarms in practice, which could significantly reduce the system effectiveness. Targeting on this issue, in this work, we attempt to design a Medical Fuzzy Alarm Filter (named MFAFilter) for healthcare environments by means of fuzzy logic, especially fuzzy if-Then rules, which could handle the vague and imprecise among data. In the evaluation, we conducted two major experiments to explore the performance of our approach in a simulated and a real network environment, respectively. Experimental results demonstrate that the use of fuzzy if-Then rules could achieve a better accuracy as compared to the traditional supervised algorithms, and that our designed filter is effective in the practical environment."
10.1007/978-3-031-29857-8_12,supervised,"The market of modern industry is oriented towards the technology of additive manufacturing, which encompasses several processes, among which we find FDM (fused deposition modeling), which has become increasingly used due to its advantageous contribution compared to traditional techniques. Its advantages concern in particular the reduction of manufacturing time, the resistance to temperature and the limitation of human intervention, which also decreases the risks that the user of this technology may have. However, despite these advantages, FDM has some limitations, especially with regard to defects that influence the manufacturing and, of course, the quality of the final product. As a result, and because of the recognised effectiveness of machine learning algorithms in the field of FDM, we have prepared this summary paper to review recent research involving the application of these algorithms to the FDM manufacturing process. The purpose of this work is to show the applicability of ML in various tasks related to this type of process. These tasks include surface roughness prediction, part deviation detection, cost estimation and defect prediction. The results of this paper show that ML algorithms contribute effectively to achieving good prediction and classification accuracies for several tasks associated with FDM manufacturing. This work opens the door for further research to apply these ML algorithms in other tasks related to this type of process."
10.1007/s12247-025-10203-4,supervised,"This study presents an AI-driven pharmaceutical data analysis tool designed to streamline drug formulation and quality control processes. Built using R’s app framework, the application integrates advanced machine learning techniques, statistical analyses, and interactive visualizations into a user-friendly interface. Users can upload their own datasets, perform comprehensive exploratory data analysis (EDA), and generate actionable insights through predictive modeling and simulated real-time monitoring. The tool demonstrates proof-of-concept alert mechanisms designed to highlight potential anomalies and formulation trends, though these features are currently implemented in a simulated environment. Results from the analysis highlight critical factors influencing tablet hardness and disintegration time, such as excipients like Mannitol and Microcrystalline Cellulose, as well as physical properties like Angle of Repose and Bulk Density. Classification models achieve high accuracy (85.71%) and robust performance metrics, including sensitivity, specificity, and Kappa statistics. Regression models reveal challenges in predicting hardness due to complex interactions between variables. The ROC curve demonstrates excellent discriminatory power, underscoring the reliability of the classification model. This integrated approach empowers formulation scientists to prioritize key variables, address anomalies, and enhance product consistency. By combining AI-driven insights with interactive features, this tool bridges the gap between data science and pharmaceutical research, offering a scalable solution for optimizing drug development and manufacturing processes."
10.2118/197327-ms,supervised,"However, the complexity of the asset makes it challenging to derive a theoretical framework for managing the control parameters. The current frontier for a real time monitoring exploits the ""digital tansformation"", i.e. the acquisition and the analysis of large datasets recorded along the whole asset lifecycle, which are used to infer ""data driven"" relations and to predict the evolution of the asset integrity. This paper presents some results of a research project for the design, implementation and testing of a ""machine learning"" approach to vibroacoustic data recorded continuously by acquisition units installed every 10-20 km along a pipeline. In a fluid transportation system, vibroacoustic signals are generated by the flow regulation equipment (i.e. pumping, valves, metering), by the fluid flowing (i.e. turbulence, cavitation, bubbles), by third party interference (i.e. spillage, sabotage, illegal tapping), by internal inspection using PIGs operations), and by natural hazards (i.e. microseismic, subsidence, landslides). The basic principle of machine learning is to ""observe"", for an appropriate time interval, a series of descriptors, in this stage related to vibroacoustic signals but that can be integrated with other physical data (i.e. temperature, density, viscosity), in order to ""learn"" their safe range of variation or, when properly fed to a classification procedure, to obtain automatically a discrete set of operational status. The classification criteria are then applied to new data, highlighting the presence of system anomalies. The paper considers vibroacoustic signals collected at the flow stations of an oil trunkline in Nigeria. The vibroacoustic signals are the static pressure, the acceleration and the pressure transients recorded at the departure and at the arrival terminals. More than one year of data is available. Derived smart indicators are defined, which are directly linked to the asset parameters: for instance, the cross-correlation of the pressure transients at adjacent measuring locations permits to estimate the fluid channel continuity (correlation value), the sound velocity (time of correlation peak), and the sound attenuation (amplitude versus frequency amplitude decay). A portion of the data during normal operation is used for training and tuning a reference model. After that, new data are compared with the model, and anomalies are automatically detected. Two kind of errors are raised: i) sensors; ii) alerts. Sensor errors are referred to missing or corrupted sensors data. Alerts are raised when the measured physical quantities are not coherent with the functional and known service behaviors of the transport system. The system model is not static over time, and in fact it can be updated by the operators' feedback, that can tag false alarms and thus, automatically, re-define the set of operational scenarios of the upstream system. The medium-long term construction and update of data driven models is effective for predictive maintenance, automatic anomalies detection, optimization of operational procedures. Moreover, the new policy of data management and the opportunity of gaining awareness by interconnecting the monitoring experience of different assets leverages the introduction of new technologies (cloud, big data), new professional figures (smart data scientist), new operational and business models."
10.1016/j.procs.2022.12.330,supervised,"Published by ELSEVIER B.V.In Artificial Intelligence (AI) in general and in Machine Learning (ML) in particular, which are important and integral components of modern Industry 4.0, we often deal with uncertainty, e.g., lack of complete information about the objects we are classifying, recognizing, diagnosing, etc. Traditionally, uncertainty is considered to be a problem especially in the responsible use of AI and ML tools in the smart manufacturing domain. However, in this study, we aim not to fight with but rather to benefit from the uncertainty to improve the classification performance in supervised ML. Our objective is a kind of uncertainty-driven technique to improve the performance of Convolutional Neural Networks (CNNs) for image classification. The intuition behind our suggested ""decontextualize-and-extrapolate""approach is as follows: any image not necessarily contains all the needed information for perfect classification; any trained CNN will give for the entire image (with some uncertainty) the probability distribution among possible classes; the same CNN may also give similar probability distribution to the ""part""of the image (i.e., with the higher uncertainty); one may discover the trend of the probability distribution change with the change of uncertainty value; a better (refined) probability distribution could be computed from these two distributions as the result of their extrapolation towards the less uncertainty. In this paper, we suggested several ways and corresponding analytics to discover reasonable part(s) of the images and to make the extrapolation to get better (refined) image classification results. We have considered image representation at the level of pixels as well as at the level of the discovered features. Our preliminary experiments show that the suggested refinement techniques (applied during the testing phase of the CNNs) can improve their classification performance."
10.1007/s42417-023-01144-8,supervised,"Gearboxes are critical equipment in many industrial applications such as machine manufacturing, petrochemical industry, renewable energy, etc. However, due to their complex structure and regularly harsh working environment, gearboxes are inevitably prone to a variety of faults and defects during operation. Therefore, intelligent condition monitoring techniques are crucially important for early gear and bearing fault recognition and detection to avoid any industrial failure due to machine breakdowns. In this paper, an intelligent algorithm for gear and bearing fault diagnosis is suggested based on several approaches mainly: robust empirical mode decomposition (REMD), time domain features are used for the feature extraction step, while equilibrium optimizer (EO) in the feature selection. For feature classification, random forest (RF), ensemble tree (ET) and nearest neighbors (KNN) are chosen as classifiers. REMD is used to alleviate the mode mixing problem by monitoring the sifting process and selecting the optimal iteration number. EO is a recent optimization approach based on the laws of physical theory in nature. EO reduces the high-dimensional data problem, by filtering redundant features, and increasing model generalization efficiency by avoiding the over-fitting curse. The proposed approach is applied to real-time vibration signals from a healthy gearbox and four different faulty gear and bearing conditions. According to our approach, data signals are decomposed by REMD to several intrinsic mode functions (IMFs). Thereafter, time-domain features are computed for each IMF to construct the feature matrix for every gear and bearing health status. After that, EO is applied to every matrix in the feature selection step. Finally, RF, ET and KNN are used to calculate classification accuracy and give the confusion matrix. Compared to several feature selection techniques, experimental results prove the efficiency of the proposed approach in detecting, identifying, and classifying all gear and bearing defects even under different operating modes."
10.1002/ieam.1708,supervised,"Published 2015. This article is a US Government work and is in the public domain in the USA.Life cycle assessment (LCA) has considerable merit for holistic evaluation of product planning, development, production, and disposal, with the inherent benefit of providing a forecast of potential health and environmental impacts. However, a technical review of current life cycle impact assessment (LCIA) methods revealed limitations within the biological effects assessment protocols, including: simplistic assessment approaches and models; an inability to integrate emerging types of toxicity data; a reliance on linear impact assessment models; a lack of methods to mitigate uncertainty; and no explicit consideration of effects in species of concern. The purpose of the current study is to demonstrate that a new concept in toxicological and regulatory assessment, the adverse outcome pathway (AOP), has many useful attributes of potential use to ameliorate many of these problems, to expand data utility and model robustness, and to enable more accurate and defensible biological effects assessments within LCIA. Background, context, and examples have been provided to demonstrate these potential benefits. We additionally propose that these benefits can be most effectively realized through development of quantitative AOPs (qAOPs) crafted to meet the needs of the LCIA framework. As a means to stimulate qAOP research and development in support of LCIA, we propose 3 conceptual classes of qAOP, each with unique inherent attributes for supporting LCIA: 1) mechanistic, including computational toxicology models; 2) probabilistic, including Bayesian networks and supervised machine learning models; and 3) weight of evidence, including models built using decision-analytic methods. Overall, we have highlighted a number of potential applications of qAOPs that can refine and add value to LCIA. As the AOP concept and support framework matures, we see the potential for qAOPs to serve a foundational role for next-generation effects characterization within LCIA. Integr Environ Assess Manag 2016;12:580-590. Published 2015. This article is a US Government work and is in the public domain in the USA."
10.1177/01423312231191569,unsupervised,"Motor rolling bearings are the important supporting components of motors. It can ensure the stable operation of motor equipment in the power grid, and bearing life prediction of it is a key issue. To solve the problem of low accuracy of remaining useful life (RUL) prediction for motor rolling bearings, a neural network model based on Weibull proportional hazards model (WPHM) and stochastic configuration networks (SCNs) is proposed. To better extract and analyze features of the bearing vibration signal in both time and frequency domains, kernel principal component analysis (KPCA) is used to reduce the dimensionality of the data. Then, a WPHM model using the top three contributing feature parameters is built, which sets the start time based on the failure rate curve and reliability function. Finally, the validity of the model is verified with the rolling bearing full life cycle dataset from the IEEE PHM 2012 Data Challenge, and a comparison with other machine learning models shows that the accuracy of the proposed model in RUL prediction is higher."
10.1016/j.compag.2024.109860,unsupervised,"In fact, if on one hand numerous researchers are studying the problem selecting most efficient animals, on the other hand, few studies have focused on the definition of tools forecasting the productivity of dairy cows in the future lactations starting from the data collected in past lactations. This aspect has a particular importance in the first years of a cow since, as well known, first lactation usually has lower production than subsequent lactations. For a farmer it is important to know, as soon as possible, if a specific animal will have on a long term, lactations with high, medium or low milk productivity. The current availability of large dataset collected by automatic milking systems or by electronic milking parlors, paves the way for application of big data approaches based on machine learning algorithms with classification learner representing one of the most promising data-driven tools. In this study, firstly two supervised learning methods, i.e., Super Vector Machine and K-Nearest Neighbors, have been applied to a large dataset of 720 complete lactations, with the object to train machine learning tools able to classify and separate first and second lactation. The two classification algorithms have been applied to the raw dataset and after the application of a dimensionality reduction method. Four different dimensionality reduction methods (i.e., ISOMAP, UMAP, MDS and t-SNE) have been tested to evaluate the most efficient for this application. Finally, the same two classification algorithms have been used for the attribution of the productivity level of the second lactation starting from data of the first lactation. The two classification methods reached very encouraging accuracy values, ranging from 70% to 73%, indicating that selected predictors despite their simplicity look very promising and entail for the definition of enhanced future models. In fact, the method is particularly interesting for practical applications, as it represents a viable support-to-decision tool for selecting the most productive animals. Interpretive summary The need to increase the sustainability of the animal production sector makes essential to search for new tools to support farmers and vets, and in this the modern numerical techniques based on artificial intelligence are becoming increasingly popular. Especially in the dairy sector, the increase in sustainability is closely linked to the selection of the cows capable of guaranteeing high milk production. In this work a new approach based on machine learning models is proposed for the identification of the most productive animals and for the assessment of the long-term milk productivity class of a specific cow."
10.1016/j.ifacol.2025.09.354,unsupervised,"Copyright © 2025 The Authors.The advancement of intelligence technology for production and the continuous increase in demand for personalized products demonstrate the challenge towards implementing mass customization (MC) strategy into production. This article presents an AI-based approach to support the decision-making of production managers regarding enhancing the level of MC based on the example of manufacturing companies in the automotive industry. Firstly, data was acquired within over 100 European manufacturing enterprises in Poland, the automotive industry, regarding scope of MC, applying Industry 4.0 technologies and effects of MC implementation. Next, subsymbolic machine learning methods were used to develop a classifier determining the level of MC processes in a company. At this stage, the k-means method was used to identify groups of analysed enterprises with a similar level of MC, then the data created in this way was used to train and test the appropriate classifier using artificial neural networks (ANNs). Finally, AI-driven data analytics model was developed and verified. The accuracy was achieved in the training and testing phases 93.9% and 89.3%, respectively. This is a universal tool supporting proactive management of MC in production."
10.1007/s10845-024-02479-z,unsupervised,"As machine learning is widely applied to improve the efficiency and effectiveness of manufacturing systems, the automated selection of appropriate algorithms and hyperparameters becomes increasingly important. This paper presents a model selection approach to multivariate anomaly detection for applications in manufacturing systems using a multi-output regression-based meta-learning method. The proposed method exploits the capabilities of meta-learning to explore and learn the intricate relationships within multivariate data sets in order to select the best anomaly detection model. It also facilitates the construction of an ensemble of algorithms with dynamically assigned weights based on their respective performance levels. In addition to the framework, new meta-features for the application domain are presented and evaluated. Experiments show the proposed method can be successfully applied to achieve significantly better results than benchmark approaches. This enables an automated selection of algorithms that can be used for enhanced anomaly detection under changing operating conditions."
10.1007/s10845-023-02192-3,unsupervised,"More and more organisations are trying to install tool health analytics dashboards for CNC machines to avoid unexpected failures, maintain machining accuracy, and optimise tool change. This paper aims at developing a cyber physical production system framework for a smart tool health management system to prescribe the optimum cutting parameters to managers/operators for optimising the remaining useful life and/or material removal rate at a predefined surface finish (individually or simultaneously). This is achieved by developing (i) a machine learning algorithm to predict the remaining useful life of a cutting tool, (ii) regression models to prescribe optimum cutting parameters (iii) a machine learning algorithm for anomaly detection, and (iv) a knowledge-based system for chip conditions and tool life curves. Experiments are designed and conducted based on Taguchi L-27 orthogonal array with varying combinations of cutting parameters during the milling of a difficult to machine material (AISI H13 tool steel). The effect of cutting parameters is analysed statistically; using analysis of variance (ANOVA), response tables, and main effect plots; to prescribe optimum cutting parameters based on managerial requirements. A novel knowledge-based system is also presented that updates knowledge and information about the chip colour at different health conditions of a tool. The present work will be a significant step towards improving productivity, product quality, and reducing maintenance costs by providing practitioners with an active decision support tool that will assist them to confidently adopt optimum management and control strategies within an Industry 4.0 environment."
10.2351/7.0001414,unsupervised,"Selective laser melting (SLM), an emerging technology, constructs components through layer-by-layer material deposition and has gained popularity in the industry due to its advantages such as shorter lead time, higher flexibility, lower material wastage, and the capability to fabricate complex geometries. However, the development of process databases for new materials is often time-consuming and laborious because SLM involves multiple physical fields and multiple process steps with numerous process parameters. Recently, machine learning is renowned for its excellent capabilities in tasks such as classification, regression, and clustering. In this study, hybrid Gaussian boosted regression that combines Gaussian process regression with gradient boosting machine was used to obtain a process database for CuCrZr alloy, optimizing for density with laser power and scanning speed as characteristic parameters, under limited samples. A machine learning model was developed using fivefold cross-training on 36 datasets. With a determination coefficient (R2) of 0.96587, the model demonstrated a high level of fit. Next, by extending the prediction range, we achieved process parameters for the highest five densities of samples. Finally, the model’s precision was confirmed with experiments on the five predicted maximum densities, with all predictions falling within a ±0.09% error margin from the experimental values. This research precisely predicted the densities of SLM-formed CuCrZr parts, created a comprehensive process parameter database, and substantiated both theoretical and practical backing for the 3D printing of CuCrZr parts."
10.1109/GINOTECH63460.2025.11076852,unsupervised,"The Industrial Internet of Things (IIoT) allows real-time monitoring and data collection from interconnected devices and systems, revolutionising manufacturing and industrial processes. One of the biggest uses of IIoT is predictive maintenance, which predicts equipment breakdowns to save downtime and boost efficiency. Advanced machine learning is applied to IIoT predictive maintenance procedures in this study. Machine learning algorithms can identify equipment failure patterns and abnormalities using historical and real-time sensor data. We extensively reviewed predictive maintenance models and found that classic statistical methods generally fail to adapt to complex and dynamic industrial situations. Our method improves predicted accuracy with machine learning models, including supervised and unsupervised learning. In particular, Random Forest, Support Vector Machines, and deep learning architectures are tested for equipment failure and maintenance prediction. A manufacturing plant with IIoT sensors was used in our case study to analyse operational data over several months. With prediction accuracy gains of up to 30% over standard methods, unexpected downtime is reduced. We also highlight the economic benefits of machine learning-driven predictive maintenance, including reduced downtime and optimised maintenance schedules. This paper provides a paradigm for predictive maintenance using machine learning, advancing IIoT. Our findings highlight the need of sophisticated analytics to optimise industrial operations and provide a path for IIoT-enabled efficiency and productivity. Future work will improve machine learning algorithms for predictive power and explore AI integration in IIoT applications."
10.18517/ijaseit.13.4.19020,unsupervised,"0 International License.Cameras utilized for product defect detection in the production line of the manufacturing process create noise due to environmental changes such as camera angle and direction of light. This causes a lack of manufacturing process data and reduces the efficiency of anomaly detection. Therefore, it is necessary to produce a method that detects defects occurring in the production line and guarantees product quality and safety using anomaly detection technology combined with artificial intelligence. Therefore, this thesis proposes PatchCore-based anomaly detection using major object segmentation. The proposed method pre-processes product packaging data by using Green Channel thresholding, Major Connected Component Selection, Extracting Outer Contour, and FloodFill with Centroid. As for the pre-processed data main objects are masked, and the image data is segmented. Through PatchCore model, normality and anomaly detection results are binarily classified. In the performance evaluation, the accuracy is compared between the pre-existing anomaly detection method and the proposed method through the pre-/post-preprocessing data, and high performance is proven. The conventional method showed an accuracy of 0.7684, while our approach achieved an accuracy of 0.9784. Additionally, among the CNN models, VGG19 demonstrated an accuracy of 0.5833, and EfficientNet80 showed an accuracy of 0.7, both of which were lower than our method's accuracy. Therefore, even a small data set shows strong performance through the proposed method. The proposed method is expected to be utilized as an effective defect detection model in diverse fields."
10.1177/16878132231218586,unsupervised,"Surface defects generated during the production process of steel balls can lead to bearing failures, which makes it crucial to promptly detect and classify these defects. Defects classify is helpful for analysis and improving the production process. An algorithm that incorporates K-fold cross-validation (K-CV) with improved grid search is proposed to optimize the parameters of SVM, in order to detect surface defects with steel balls. Principal Component Analysis (PCA) was employed to reduce the dimensionality of the effective features data. The K-CV algorithm was employed in conjunction with an improved grid search method to find the optimal parameters “c” and “g.” This approach not only reduced the search time but also diminished the influence of individual samples on the model, thereby enhancing its robustness and ultimately improving the classification accuracy. The model’s performance was evaluated using a confusion matrix, and a comparison was made with three other machine learning models. The experimental results demonstrated the effectiveness of the proposed algorithm in classifying defects on highly reflective metal surfaces such as steel balls. The model achieved a classification accuracy of 97.15%."
10.1117/12.2581468,unsupervised,"The Semiconductor industry relies on the metrology to keep up with a highly competitive production environment and technology ramp up. To reduce metrology costs without degrading quality we propose to use sensors data such as scanner leveling data as a new way to detect maverick lots and wafers enabling a smarter measurement sampling scheme. To achieve this, data preparation and data cleaning with Zernike polynomials method is required. Then the pre-processed data are used to feed an unsupervised density based machine learning algorithm (DBSCAN) that can detect outliers as an human expert would. Finally, a solution (Random Forest Discriminant Analysis) for root cause detection of abnormal fingerprints is tested in this paper. A method working on other use cases (Partial Least Square Discriminant Analysis) is also used for result crossing."
10.1038/s41597-022-01877-3,unsupervised,"The paper describes the MetroPT data set, an outcome of a Predictive Maintenance project with an urban metro public transportation service in Porto, Portugal. The data was collected in 2022 to develop machine learning methods for online anomaly detection and failure prediction. Several analog sensor signals (pressure, temperature, current consumption), digital signals (control signals, discrete signals), and GPS information (latitude, longitude, and speed) provide a framework that can be easily used and help the development of new machine learning methods. This dataset contains some interesting characteristics and can be a good benchmark for predictive maintenance models."
10.1007/s00170-025-15473-3,unsupervised,", part of Springer Nature 2025.The manufacturing of an aircraft is a complex process, requiring exceptional precision and adherence to strict quality standards for every component. This process demands continuous sharing of information and knowledge, as any errors occurring during these stages may lead to problems that affect the entire product lifecycle. In this context, anomaly detection becomes a crucial domain of study, particularly in the early stages of product lifecycle management (PLM). Collecting and processing data in real-time facilitates early failure prediction in production processes, aids in decision-making for reworking defective parts, and enhances overall process optimisation. This paper aims to address the problem of lack of standardisation in the product design and manufacturing of parts by proposing an intelligent system to detect and diagnose anomalies in the product design and manufacturing of aerospace sheet metal parts. The proposed approach uses automated feature recognition (AFR) to classify the topological elements of the boundary model and recognise features through semantic rules. Then, machine learning techniques for anomaly detection, such as k-nearest neighbours (KNN), are applied to identify anomalies in the test data. Finally, ontologies are integrated as a method of knowledge formalisation and representation to assist the decision-making process for reworking the anomaly part, suggesting productive processes and corrective tools for anomaly correction. As a result, the approach can identify anomalies in 3D model parts based on their project requirements and geometric features. It allows anomaly visualisation and offers support in decision-making during manufacturing, determining corrective actions, and thus optimising the manufacturing process."
10.1016/j.ejor.2019.07.053,unsupervised,"V.One of the greatest 21st century challenges is meeting the need to feed a growing world population which is expected to increase by about 35% by 2050. To meet this challenge, it is necessary to make major improvements on current food production and distribution systems capabilities, as well as to adapt these systems to expected trends such as climate change. Changing climate patterns may present opportunities for unidentified, geographical regions with adequate climate patterns to produce high-value agricultural products in a profitable and sustainable manner. This paper focuses on the design and planning aspects of a discovery process to unearth agri-food supply chains capable of generating attractive return on investments. A stochastic optimization framework is used to develop planting and harvesting schedules for a set of identified regions with complementary weather characteristics. To address the high-level of variability in the problem context, a two-stage stochastic decomposition method is used to consider a larger number of scenarios. As part of the solution process, a modeling scheme is developed that learns past interactions between entering discretized, weather scenarios and optimal first-stage solutions. In this context, machine learning and dimensionality reduction techniques are used to iteratively estimate each region's probability of belonging to first-stage solutions based on previous solution-scenario results. The implementation of the stochastic framework is shown through a case study applied to multiple locations within the US southwest states of Arizona and New Mexico."
10.1016/j.ebiom.2024.105286,unsupervised,"Methods: Here, we present an unsupervised Bayesian framework to identify disease-associated genes by integrating risk SNPs with long-range chromatin interactions (iGOAT), including SNP-SNP interactions extracted from ∼500,000 patients and controls from the UK Biobank, and enhancer–promoter interactions derived from multiple brain cell types at different developmental stages. Findings: The application of iGOAT to three psychiatric disorders and three neurodegenerative/neurological diseases predicted sets of high-risk (HRGs) and low-risk (LRGs) genes for each disorder. The HRGs were enriched in drug targets, and exhibited higher expression during prenatal brain developmental stages than postnatal stages, indicating their potential to affect brain development at an early stage. The HRGs associated with Alzheimer's disease were found to share genetic architecture with schizophrenia, bipolar disorder and major depressive disorder according to gene co-expression module analysis and rare variants analysis. Comparisons of this method to the eQTL-based method, the TWAS-based method, and the gene-level GWAS method indicated that the genes identified by our method are more enriched in known brain disorder-related genes, and exhibited higher precision. Finally, the method predicted 205 risk genes not previously reported to be associated with any brain disorder, of which one top-risk gene, MLH1, was experimentally validated as being schizophrenia-associated. Interpretation: iGOAT can successfully leverage epigenomic data, phenotype–genotype associations, and protein–protein interactions to advance our understanding of brain disorders, thereby facilitating the development of new therapeutic approaches. Funding: The work was funded by the National Key Research and Development Program of China ( 2024YFF1204902), the Natural Science Foundation of China ( 82371482), Guangzhou Science and Technology Research Plan ( 2023A03J0659) and Natural Science Foundation of Guangdong ( 2024A1515011363)."
10.1109/ACCESS.2019.2958284,unsupervised,"In recent decades, Industrial Control Systems (ICS) have been affected by heterogeneous cyberattacks that have a huge impact on the physical world and the people's safety. Nowadays, the techniques achieving the best performance in the detection of cyber anomalies are based on Machine Learning and, more recently, Deep Learning. Due to the incipient stage of cybersecurity research in ICS, the availability of datasets enabling the evaluation of anomaly detection techniques is insufficient. In this paper, we propose a methodology to generate reliable anomaly detection datasets in ICS that consists of four steps: attacks selection, attacks deployment, traffic capture and features computation. The proposed methodology has been used to generate the Electra Dataset, whose main goal is the evaluation of cybersecurity techniques in an electric traction substation used in the railway industry. Using the Electra dataset, we train several Machine Learning and Deep Learning models to detect anomalies in ICS and the performed experiments show that the models have high precision and, therefore, demonstrate the suitability of our dataset for use in production systems."
10.19678/j.issn.1000-3428.0067396,unsupervised,"All rights reserved.Kubeflow is a project that integrates machine learning and cloud computing technology, integrating a large number of machine learning tools and providing a feasible solution for the deployment of production-grade machine learning platforms. Machine learning relies on specialized Graphics Processing Unit（GPU）s to improve training and inference speed. As the size of cloud computing clusters is dynamically adjusted, computing nodes of different computing architectures can be added or removed from the cluster, and traditional round-robin scheduling strategies cannot realize the dynamic adjustment of heterogeneous computing power resources. To solve the allocation and optimization problems of Kubeflow's heterogeneous computing power, improve the utilization rate of platform resources, and achieve load balancing, a cloud-based Central Processing Unit-GPU（CPU-GPU） heterogeneous computing power scheduling strategy is proposed. This scheduling strategy adopts two judgment indicators：weighted load balancing degree and priority, and fine-grained allocation of display memory to achieve granularity of computing power resources. The optimal deployment scheme of Pod is designed according to the resource weight matrix of each node in the cluster, and an improved genetic algorithm is used for optimal deployment. The experimental results show that this scheduling strategy performs better for parallel tasks. It can execute optimal loads under overflow of resource requests. Compared with the original platform-native strategy, the degree of resource fine-tuning is one order of magnitude higher, and the cluster load balancing performance is also significantly improved."
10.1109/CAC59555.2023.10451795,unsupervised,"Unsupervised image anomaly detection and segmentation algorithms hold significant importance in enhancing product quality in real-world industrial manufacturing. Anomaly detection methods based on the knowledge distillation framework perform detection by characterizing differences between anomalous samples. However, knowledge distillation-based anomaly detection methods often employ similar or identical architectures for constructing both teacher and student models. This practice has led to the issue of vanishing anomaly activation values, resulting in detection failures. Hence, the proposed Multi-Channel Knowledge Distillation model (MCKD) consists of a pair of student networks proficient at effectively capturing defect-related information. One branch of the student network enhances its diverse representation of anomalies by restoring the input's multi-scale representations. The other branch enriches the model's capacity to represent detailed defect information by extracting features from different scales. Additionally, our design of the Residual Features Aggregation Module (RFAM) ensures better retention of normal pattern information within the student network while disregarding information from abnormal patterns, resulting in enhanced modeling of positive samples. The proposed framework achieves state-of-the-art (SOTA) on the well-known MVTec AD dataset, with an area under the receiver operating characteristic curve of 97.1% for anomaly detection across all 15 categories and an area under the anomaly segmentation of 98.14%."
10.2118/200879-MS,unsupervised,"Copyright 2021, Society of Petroleum Engineers.Basin-wide heterogeneity of production in unconventional resources creates additional risk in field development planning. In the past few years, several data-driven models have been developed to increase the accuracy in predicting the recovery from shale gas and tight oil wells. However, many of the machine learning methods with so called ""black box"" approach provide deterministic results. Therefore, understanding the uncertainty associated with different development scenarios would be difficult to obtain. We have investigated the underlying statistical distribution functions that govern the production rates and decline behavior of unconventional wells. Identification and quantification of these distribution functions provide a strong tool to accurately forecast the cumulative production of a large group of wells in an unconventional basin. By understanding the relationship among geologic characteristics of different sections of the asset, and the impact of varying drilling and completion parameters, capital allocation can be done in a more efficient manner. In this paper, we have identified the statistical distribution parameters of decline behavior is a Power Law model. In doing so, we have used unsupervised clustering techniques to find an optimal number of clusters that enable observing well behaved and identifiable underlying distribution functions. Furthermore, we quantified different types of distribution functions in a trial and error workflow to provide a tool for accurately evaluating the impact of varying geologic parameters on the decline behavior of these wells. Our results show that the leading term (or leading coefficient), which also highly correlates with long term cumulative recovery, demonstrates Gamma distribution, while the power degree (or power coefficient) demonstrate Normal distribution. Peak production rate (maximum average daily rate), terminal rate (rate after switch point), and the time of terminal rate occurrence, all demonstrate Log Normal distribution."
10.1177/09266801241291401,unsupervised,"This work explores the use of generative adversarial networks (GANs) to tackle cyber-security challenges, including threat identification, anomaly detection, and mitigation strategies, particularly in complex systems and critical infrastructures like industrial control systems for energy production and distribution. GANs address a key obstacle in machine learning (ML)-based systems: the scarcity of quality data for training models capable of fully leveraging ML and deep learning in cyber-security applications, such as intrusion detection systems and malicious behaviour detectors. The study highlights GANs’ potential to enhance data augmentation by generating realistic synthetic network traffic flows. These flows simulate common cyber-attacks targeting operational technologies (OTs) and information technologies (ITs). A primary contribution of this research is the creation of a large, high-quality dataset of OT and IT network traffic, designed to improve the robustness of ML models used in cyber-defense systems. Additionally, the work includes statistical analyses to evaluate the reliability of GAN-based data augmentation, laying the foundation for further research. This approach promises significant advancements in developing resilient ML models capable of addressing evolving cyber-security threats."
10.1016/j.compchemeng.2024.108891,unsupervised,"Traditional Computational Fluid Dynamics (CFD) simulations provide detailed insights but often involve lengthy computation times and complexity, hindering their practicality for real-time applications. This study introduces a novel multivariate unsupervised learning algorithm that clusters bioreactors into physically meaningful regions based on CFD-generated and real-world data. These clusters not only facilitate the determination of internal reactor regimes but also serve as a foundational step for developing compartment models. Our approach utilizes a custom k-means clustering algorithm, which ensures spatial continuity of clusters by incorporating geometric data, and optimizes the number of compartments to maximize physical significance and data retention. This optimization is guided by a Pareto front analysis, balancing the need for clear compartment definition with the preservation of maximum information from the dataset. The effectiveness and versatility of this methodology were verified through case studies involving a 202 m³ Rushton impeller bioreactor (steady state simulation) and an 840 m³ airlift reactor (dynamic simulation). In the airlift reactor, the clustering algorithm accounted for dynamic fluctuations by averaging the simulation results, providing a robust method for incorporating temporal variations into the compartment analysis. The findings highlight the advantages of 3-D compartmentalization in capturing the intricate dynamics of fluid motion and cellular activities, thereby advancing the design of bioreactors and scaling down experiments for more efficient industrial applications."
10.1177/14759217211040269,unsupervised,"Leakages in the underground water distribution networks (WDNs) waste over 1 billion gallon of water annually in the US and cause significant socio-economic loss to our communities. However, detecting and localization leakage in a WDN remains a challenging technical problem despite of significant progresses in this domain. The progresses in machine learning (ML) provides new ways to identify the leakage by data-driven methods. However, in-service WDNs are short of labeled data under leaking conditions, which makes it infeasible to use common ML models. This study proposed a novel machine learning (ML)-based framework for WDN leak detection and localization. This new framework, named clustering-then-localization semi-supervised learning (CtL-SSL), uses the topological relationship of WDN and its leakage characteristics for WDN partition and sensors placement, and subsequently utilizes the monitoring data for leakage detection and leakage localization. The CtL-SSL framework is applied to two testbed WDNs and achieves 95% leakage detection accuracy and around 83% final leakage localization accuracy by use of unbalanced data with less than 10% leaking data. The developed CtL-SSL framework advances the leak detection strategy by alleviating the data requirements, guiding optimal sensor placement, and locating leakage via WDN leakage zone partition. It features excellent scalability, extensibility, and upgradeability for applications to various types of WDNs. It will provide valuable a tool in sustainable management of the WDNs."
10.1016/j.heliyon.2022.e09634,unsupervised,"The major drawbacks include the open-source Internet of Things (IoT) platform vulnerabilities, node failures, computational latency, and small memory capacity in IoT sensing nodes. This article provides reliable predictive analytics with the optimisation of data transmission characteristics in StreamRobot. Software-defined reliable optimisation design is applied in the system architecture. For the IoT implementation, the edge system model formulation is presented with a focus on edge cluster log-normality distribution, reliability, and equilibrium stability considerations. A real-world scenario for accurate data streams generation from in-built TelosB sensing nodes is converged at a sink-analytic dashboard. Two-phase configurations, namely off-taker and on-demand, link-state protocols are mapped for deterministic data stream offloading. An orphan reconnection trigger mechanism is used for reliable node-to-sink resilient data transmissions. Data collection is achieved, using component-based programming in the experimental testbed. Measurement parameters are derived with TelosB IoT nodes. Reliability validations on remote monitoring and prediction processes are studied considering neural constrained software-defined networking (SDN) intelligence. An OpenFlow-SDN construct is deployed to offload traffic from the edge to the fog layer. At the core, fog detection-to-cloud predictive machine learning (FD-CPML) is used to predict real-time data streams. Prediction accuracy is validated with decision tree, logistic regression, and the proposed FD-CPML. The data streams latency gave 40.00%, 33.33%, and 26.67%, respectively. Similarly, linear predictive scalability behaviour on the network plane gave 30.12%, 33.73%, and 36.15% respectively. The results show satisfactory responses in terms of reliable communication and intelligent monitoring of node failures."
10.18420/inf2024_147,unsupervised,"All rights reserved.In cooperation with a medium-sized industrial partner, we developed and evaluated two ML-based approaches for quality control in glass bottle printing. Our first approach utilized various filters to suppress reflections, image quality metrics for image comparison, and supervised classification models, resulting in an accuracy of 84%. We used the ORB algorithm for image alignment and to estimate print rotations, which may indicate manufacturing anomalies. In our second approach, we fine-tuned pre-trained CNN models, which resulted in an accuracy of 87%. Utilizing Grad-CAM, an Explainable AI method, we localized and visualized frequently defective bottle print regions without explicitly training our models for this use case. These insights can be used to optimize the actual manufacturing process beyond classification. This paper also describes our general approach and the challenges we encountered in practice with data collection during ongoing production, unsupervised preselection, and labeling."
10.3390/aerospace8040103,unsupervised,"Licensee MDPI, Basel, Switzerland.Predictive maintenance has received considerable attention in the aviation industry where costs, system availability and reliability are major concerns. In spite of recent advances, effective health monitoring and prognostics for the scheduling of condition-based maintenance operations is still very challenging. The increasing availability of maintenance and operational data along with recent progress made in machine learning has boosted the development of data-driven prognostics and health management (PHM) models. In this paper, we describe the data workflow in place at an airline for the maintenance of an aircraft system and highlight the difficulties related to a proper labelling of the health status of such systems, resulting in a poor suitability of supervised learning techniques. We focus on investigating the feasibility and the potential of semi-supervised anomaly detection methods for the health monitoring of a real aircraft system. roposed methods are evaluated on large volumes of real sensor data from a cooling unit system on a modern wide body aircraft from a major European airline. For the sake of confidentiality, data has been anonymized and only few technical and operational details about the system had been made available. We trained several deep neural network autoencoder architectures on nominal data and used the anomaly scores to calculate a health indicator. Results suggest that high anomaly scores are correlated with identified failures in the maintenance logs. Also, some situations see an increase in the anomaly score for several flights prior to the system’s failure, which paves a natural way for early fault identification."
10.1002/qre.2538,unsupervised,"Remaining useful life (RUL) prediction plays an important role in predictive maintenance systems to support decision-makers for arranging maintenance tasks and related resources. We propose a hybrid approach that is combined an exponential weighted moving average (EWMA) control chart for anomaly detection and machine learning models such as support vector regression (SVR) and random forest regression (RFR) with differential evolution (DE) algorithm to predict the RULs of ball bearings. Here, DE algorithm is used to find the optimal hyperparameters of SVR model. The datasets of ball bearings from the Prognostics Data Repository of NASA are used to compare the prediction performance of different methods. The degradation behavior of training data from the anomaly time to the end of life is used to transfer learning for the testing data in the SVR and RFR models. The results indicate that the proposed methods outperform the other four existing methods in terms of score. Therefore, the proposed hybrid approach is a reliable tool for the RUL prediction of ball bearings."
10.3390/rs14020339,unsupervised,"Licensee MDPI, Basel, Switzerland.Human activities in the sea, such as intensive fishing and exploitation of offshore wind farms, may impact negatively on the marine mega fauna. As an attempt to control such impacts, surveying, and tracking of marine animals are often performed on the sites where those activities take place. Nowadays, thank to high resolution cameras and to the development of machine learning techniques, tracking of wild animals can be performed remotely and the analysis of the acquired images can be automatized using state-of-the-art object detection models. However, most state-of-the-art detection methods require lots of annotated data to provide satisfactory results. Since analyzing thousands of images acquired during a flight survey can be a cumbersome and time consuming task, we focus in this article on the weakly supervised detection of marine animals. We propose a modification of the patch distribution modeling method (PaDiM), which is currently one of the state-of-the-art approaches for anomaly detection and localization for visual industrial inspection. In order to show its effectiveness and suitability for marine animal detection, we conduct a comparative evaluation of the proposed method against the original version, as well as other state-of-the-art approaches on two high-resolution marine animal image datasets. On both tested datasets, the proposed method yielded better F1 and recall scores (75% recall/41% precision, and 57% recall/60% precision, respectively) when trained on images known to contain no object of interest. This shows a great potential of the proposed approach to speed up the marine animal discovery in new flight surveys. Additionally, such a method could be adopted for bounding box proposals to perform faster and cheaper annotation within a fully-supervised detection framework."
10.1109/ISCC53001.2021.9631508,unsupervised,"Natural gas, as a kind of clean energy, has attracted significant attention in the global market. However, how to ensure the safety and high efficiency in natural gas production becomes a hot research problem in the gas industry. The real-time abnormal status detection of the natural gas well empowers the decision-maker to prevent potentially catastrophic damage and correct unexpected situations. In this paper, we systematically evaluate the 9 state-of-the-art machine learning methods to detect such anomalous status on large sensor data collected from 4 natural gas wells. In addition, we have identified the most important features that can improve anomaly detection performance. The challenges and potential research directions have been discussed. This is the first work to investigate different types of anomaly detection methods on natural gas well sensor data. Our research results provide valuable insights for developing specific anomaly detection systems in the natural gas industry."
10.2118/225545-MS,unsupervised,"Copyright 2025, Society of Petroleum Engineers.Identifying anomalies in daily time series data can be critical for maintaining the performance and integrity of a petroleum production system. Previously numerous attempts have shown that statistical and machine learning approaches can provide a means to detect and identify the types of anomalies that may occur on a given set of monitored equipment. The recent advances in leveraging generative pre-trained Large Language Models (LLMs) have been shown to be extendable to tasks on time series data by treating the data as a series of textual characters. In this work we investigate the capability of so-called Vision-Language Models (VLMs) for anomaly detection in time series data from production wells. Our approach presents the relevant time series data as an image to the VLM together with a text-based prompt. Due to the pre-training on large-scale datasets and task-instruction pre-training of the used VLMs we are able to leverage the capabilities of these models as flexible way of describing the presented data and querying for anomalies. We constrain the VLM to a structured output format, ensuring adherence to a specified data-model of required attributes e.g. the presence of an anomaly, the description, and the direction of change in the signal. We evaluate our proposed methodology on a dataset of 1000 expert-annotated instances acquired from various operational settings of Aker BPs production wells and its ability to assign an indicator of whether a time series merits inspection by an engineer. We compare against simple statistical baselines, perform a number of ablations, as well as investigate a risk-based evaluation approach enabled by the probabilistic nature of VLMs. Our findings show that VLMs should be considered as an integral and highly flexible component in a production monitoring system."
10.1016/j.neucom.2025.131138,unsupervised,"V.Acromegaly, a chronic condition caused by excessive Growth Hormone (GH) production, leads to significant physical changes. These physical manifestations can severely affect patients' social interactions, potentially leading to interpersonal difficulties and the development of personality disorders. The Inventory of Interpersonal Problems (IIP) is a widely used tool for assessing interpersonal difficulties, which are often linked to personality disorders. However, applying the IIP to acromegaly patients presents unique challenges due to the complex interplay between physical appearance and psychological distress. To address these limitations, this study developed a new model that combines the IIP with additional psychological evaluations specifically tailored to acromegaly patients. The novelty of the proposed model lies in its robust and clinically informed approach to detecting interpersonal problems in acromegaly patients. By combining psychological evaluation with clinical parameters and deep learning, it provides a more holistic and accurate understanding of patient well-being. It confirms its superior predictive capabilities, offering a practical solution for both clinicians and mental health professionals. This work not only advances the field of medicine but also addresses an important unmet need in the comprehensive management of acromegaly. Here, a dimension reduction procedure was performed using Multiscale Weighted Principal Component Analysis (MWPCA) and T-Distributed Stochastic Neighbor Embedding (t-SNE). The relationship between IIP values and various parameters, such as age, gender, and GH values, is analyzed with the help of MWPCA and t-SNE. The results from MWPCA and t-SNE are concatenated and fed into the Hybrid Dilation and Attention-based Adaptive Bi-Directional Gated Recurrent Unit (HDA-ABiGRU) to detect the IIP in acromegaly patients based on the IIP values. Here, the hyperparameters of the Bi-Directional Gated Recurrent Unit (Bi-GRU) are tuned using the Refined and Efficient Fossa Optimization Algorithm (RE-FOA). The suggested HDA-ABiGRU effectively predicted the IIP in Acromegaly patients to enhance the quality of life. The proposed HDA-ABiGRU model effectively predicts the IIP in acromegaly patients, thereby enhancing their quality of life. Finally, extensive experimental validation is performed to confirm the effectiveness of the developed model in IIP detection. The findings indicated that the developed model achieved high accuracy in detecting acromegaly from facial images. This is particularly valuable as facial changes in acromegaly can be gradual and difficult to notice early on."
10.1007/978-981-19-7867-8_14,unsupervised,"After ground-breaking achievements through the application of modern deep learning, there is a considerable push towards using machine learning systems for visual inspection tasks part of most industrial manufacturing processes. But whilst there exist a lot of successful proof-of-concept implementations, productive use proves problematic. Whilst missing interpretability is one concern, the constant presence of data drift is another. Changes in pre-materials or process and degradation of sensors or product redesigns impose constant change towards statically trained machine learning models. To handle these kind of changes, a measurement of system confidence is needed. Since pure model output probabilities often lack in this concern better solutions are required. In this work, we compare and contrast several pre-existing methods used to describe model confidence. In contrast to previous works, they are evaluated on a large set of real-world manufacturing data. It is shown that utilizing an approach based on auto-encoder reconstruction error proves to be most promising in all scenarios tested."
10.1145/3461615.3486571,unsupervised,"In order to effectively generate actionable user insights using biometric data, a deep understanding of the psychophysiological processes involved is required. However, despite a few notable commercial exceptions, psychophysiology remains primarily an academic discipline. Isolating the video game sector as a case study, this work brushes on some of the factors that hold back the adoption of psychophysiology in the industry and introduces an unsupervised approach that aims to facilitate the adoption of multimodal physiological data in product development and decision making."
10.2514/1.I010971,unsupervised,"In recent years, there has been a rapid growth in applying machine learning techniques that leverage aviation data collected from commercial airline operations to improve safety. Anomaly detection and predictive maintenance have been the main targets for machine learning applications. However, this paper focuses on the identification of precursors, which is a relatively newer application. Precursors are events correlated with adverse events that happen before the adverse event itself. Therefore, precursor mining provides many benefits, including the identification of factors relevant to the occurrence of an adverse event and their signatures, which can be tracked throughout a flight to alert the operators of the potential for an adverse event in the future. This work proposes using the multiple-instance learning framework, a weakly supervised learning task, combined with a carefully designed binary classifier leveraging a Multi-Head Convolutional Neural Network–Recurrent Neural Network (MHCNN-RNN) architecture. Multiclass classifiers are then created and compared, enabling the prediction of different adverse events for any given flight by combining binary classifiers, and by modifying the MHCNN-RNN to handle multiple outputs. Results obtained showed that the multiple binary classifiers perform better and are able to accurately forecast high-speed and high-path-angle events during the approach phase. Multiple binary classifiers are also capable of determining the aircraft parameters that are correlated to these events. The identified parameters can be considered precursors to the events and may be studied/tracked further to prevent these events in the future."
10.1145/3730576,unsupervised,"Material defects (MD) represent a primary challenge affecting product performance and giving rise to safety issues in related products. The rapid and accurate identification and localization of MD constitute crucial research endeavors in addressing contemporary challenges associated with MD. In recent years, propelled by the swift advancement of machine learning (ML) technologies, particularly exemplified by deep learning, ML has swiftly emerged as the core technology and a prominent research direction for material defect detection (MDD). Through a comprehensive review of the latest literature, we systematically survey the ML techniques applied in MDD into five categories: unsupervised learning, supervised learning, semi-supervised learning, reinforcement learning, and generative learning. We provide a detailed analysis of the main principles and techniques used, together with the advantages and potential challenges associated with these techniques. Furthermore, the survey focuses on the techniques for defect detection in composite materials, which are important types of materials enjoying increasingly wide application in various industries such as aerospace, automotive, construction, and renewable energy. Finally, the survey explores potential future directions in MDD utilizing ML technologies. This survey consolidates ML-based MDD literature and provides a foundation for future research and practice."
10.1109/ECTC51687.2025.00298,unsupervised,"With the increasing density of semiconductor packages, it is becoming increasingly difficult to control the pattern shapes of the functional materials used. For example, the pattern shapes of materials in connections involved in semiconductor signal transmission influence physical properties such as long-term reliability. Cross-section observation of the pattern shape is essential for material design and optimizing process conditions. When observing the cross-sections of functional materials such as interlayer insulations and solder resist (SR) applied to substrates, various combinations of film thickness and via size must be observed for each process condition, depending on the semiconductor package design. Therefore, a polishing machine is often used to observe cross-sections from efficiency. However, it requires a high skill level to aim at the center of the via diameter by polishing. It takes several days from substrate fabrication to the end of cross-section observation, and this process is repeated during the trial-and-error of material design, but the optimal solution is rarely achieved within a limited time frame. In addition, the experiment is often conducted within a limited process range due to the schedule. In this study, as one of the means to efficiently derive optimal material design and process conditions, we developed a system to predict cross-section images of pattern shapes from experimental conditions. The system is constructed by combining regression analysis, a type of machine learning, and variational autoencoder (VAE), which is used in image generation artificial intelligence (AI). The system has two functions to predict pattern shapes by inputting experimental conditions and to propose process conditions by inputting desired pattern shapes and constraint conditions. This system takes only a few seconds to output, which makes screening conditions more efficient and is expected to shorten not only material design but also the mass production cycle for new packages, contributing to speeding up the development of semiconductor packages that require advanced matching technology."
10.1007/978-3-031-61037-0_8,unsupervised,"Purpose: Bankruptcies have increased dramatically in recent years. The manufacturing industry is one of the most important contributors to the country’s Gross Domestic Product (GDP). The GDP of a country reflects its development and progress. More and more bankruptcies in the manufacturing business will have a significant influence on the country's GDP. The primary goal of this study is to conduct a comparative analysis of numerous bankruptcy predictive models in order to recommend the optimal model with the highest accuracy for bankruptcy prediction. Methodology/Approach: This research employs a number of machine-learning forecasting approaches. Logistic Regression, Decision Tree, Artificial Neural Networks (ANN), and Random Forest are the machine learning techniques employed in this paper. A comparison study is conducted with and without Principal Component Analysis (PCA). A total of 15 financial factors were identified from prior studies, and a comparative analysis was conducted with those variables. From 1 April 2017 to 31 March 2020, the Insolvency and Bankruptcy Board of India (IBBI) database is used to collect information on bankrupt companies. Data for the previous three years is gathered from the annual reports of 70 enterprises (35 bankrupt, 35 non-bankrupt). Contribution: This paper adds to the existing research on bankruptcy. There is relatively limited research on bankruptcy prediction after the implementation of the Insolvency and Bankruptcy Code (IBC), 2016. Most studies on bankruptcy prediction in India used logistic regression or ANN because of their widespread use and good accuracy. In India, very few research used decision tree-based methodologies to forecast bankruptcy. This research, on the other hand, contributes to decision tree-based studies and they are showing more accurate results as compared to ANN or logistic regression. Limitations: One of the major limitations of this paper is that it mainly considers financial variables for research. Recent research has considered not just financial variables, but also corporate governance indicators and macroeconomic variables. Another disadvantage is that this report primarily focuses on the manufacturing industry, thus bankruptcy research in other industries is required."
10.1109/IEA.2018.8387124,unsupervised,"The area of predictive maintenance has taken a lot of prominence in the last couple of years due to various reasons. With new algorithms and methodologies growing across different learning methods, it has remained a challenge for industries to adopt which method is fit, robust and provide most accurate detection. Fault detection is one of the critical components of predictive maintenance; it is very much needed for industries to detect faults early and accurately. In a production environment, to minimize the cost of maintenance, sometimes it is required to build a model with minimal or no historical data. In such cases, unsupervised learning would be a better option model building. In this paper, we have chosen a simple vibration data collected from an exhaust fan, and have fit different unsupervised learning algorithms such as PCA T2 statistic, Hierarchical clustering, K-Means, Fuzzy C-Means clustering and model-based clustering to test its accuracy, performance, and robustness. In the end, we have proposed a methodology to benchmark different algorithms and choosing the final model."
10.21595/vp.2019.20617,unsupervised,"A wind turbine works under variable load and environmental conditions because of which failure rate has been on the rise. Failure of a gearbox, an integral part of producing wind energy, contributes to 80 % of the total downtime for the wind turbine. For ensuring better utilization of the wind turbines, Fault prognosis and condition monitoring of bearings are of utmost importance as it helps to reduce the downtime by early detection of faults which further increases the power output. In this paper, vibration signals produced and machine learning approach to determine the Remaining Useful Life (RUL) for a degraded bearing is studied. The methodology includes statistical feature extraction analysis with regression models. Further the feature selection is done using Principal Component Analysis (PCA) technique which produces training and testing sets which acts as an input parameter for regression models such as Support Vector Regressor (SVR) and Random Forest (RF). Weibull Hazard Rate Function is used for calculating the RUL of the bearing. Results This study shows the potential application of regression model as an effective tool for degradation performance prediction of bearing."
10.1177/09721509251363410,unsupervised,"Using Python-based text mining techniques, 3,216 customer reviews from a major e-commerce platform were analyzed. Methods included sentiment analysis, word frequency, topic modelling, association rule mining and clustering to extract key consumer viewpoints. Results reveal generally positive sentiments but highlight inconsistencies between star ratings and review content, challenging assumptions in online consumer behaviour research. N-gram analysis uncovered recurring patterns in both positive and negative feedback, while association rule mining and clustering identified dominant themes such as comfort, softness, dryness, leak prevention, absorbency and material quality. The lack of specific brand mentions suggests a gap in brand recognition, signalling the need for improved brand management. This study not only enhances understanding of sustainable product adoption but also demonstrates the value of mining unstructured consumer data in emerging markets. The findings support practitioners in designing effective brand and product strategies and contribute to the broader agenda of responsible consumption. Overall, this research aligns with Sustainable Development Goals (SDG) 12 by promoting sustainable consumer practices through data-driven insights."
10.1016/j.procir.2021.05.137,unsupervised,"The management and controlling of product costs play an important role in the early stages of value creation, since 70 - 80 % final product costs are determined in product development and design processes. Traditionally, the focus in business practice is often on the organizational controlling unit that records the corresponding costs when they occur. In those, later phases of the product lifecycle, the possibilities of exerting influence are very limited. Consequently, an accurate estimation of costs in the early design phase is an important instrument to support strategic decisions in the product engineering process. An intelligent approach based on machine learning to support cost management in the early design stage is presented. In a real-world case study using wheel cost data from a large original equipment manufacturer (OEM) we investigate the performance of a cross-validated machine learning framework using a greedy sequential forward feature selection method for dimensionality reduction, as well as grid search hyperparameter tuning in order to compare six regression algorithms. The results of the study show that it is possible to predict the costs of product components in the early design phase with an R2 of 0.960 using only seven features coming from the product design and development department. By a cluster analysis and scatter plots of prediction accuracies it is shown where the deviations in cost estimation come from. The study supports the statement that machine learning models are a promising instrument for product managers and cost engineers."
10.24138/jcomss-2021-0068,unsupervised,"Demand forecasting is the process of estimating the consumption of products or services for future time periods. It plays an important role in the field of inventory control and Supply Chain, since it enables production and supply planning and therefore can reduce delivery times and optimize Supply Chain decisions. This paper presents an extensive literature review about demand forecasting methods for time-series data. Based on analysis results and findings, a new demand forecasting tool for inventory control is proposed. First, a forecasting pipeline is designed to allow selecting the most accurate demand forecasting method. The validation of the proposed solution is executed on Stock&Buy case study, a growing online retail platform. For this reason, two new methods are proposed: (1) a hybrid method, Comb-TSB, is proposed for intermittent and lumpy demand patterns. CombTSB automatically selects the most accurate model among a set of methods. (2) a clustering-based approach (ClustAvg) is proposed to forecast demand for new products which have very few or no sales history data. The evaluation process showed that the proposed tool achieves good forecasting accuracy by making the most appropriate choice while defining the forecasting method to apply for each product selection."
10.1109/CVPRW63382.2024.00561,unsupervised,"Open-world recognition has recently gained significant attention owing to its ability to bridge the gap between experimental scenarios and real-world applications. Since continual learning can learn from a sequence of dynamic data streams, it obtains extensive applications in open-world recognition. However, because of the production of data annotation is usually time-consuming and labor-intensive in real-world scenarios, it's necessary to develop unsupervised continual learning. Recent studies start to investigate unsupervised continual learning (i.e., UCL), but mainly focus on rehearsal and regularization strategies to enhance the anti-forgetting capability of UCL. In practice, rehearsal and regularization are information-dependent, which require information from previous data as supervised signals, e.g., replayed data and previous model. In this paper, we propose an information-free method, Alternate Task Discrimination (ATD), which is a self-supervised pretext task for continuity and improves anti-forgetting capability via encouraging the model to discriminate which data stream current sample is from. The whole process doesn't rely on any previous information. In order to perform ATD effectively in UCL framework, we design an alternating optimization algorithm where UCL and ATD are optimized respectively. We validate the effectiveness of the proposed method on multiple standard UCL benchmarks, where it obtains considerable improvements compared with baseline methods. In addition, our approach can be used as a plug-in unit, which makes further achievements when collaborated with existing popular UCL methods."
10.3390/math11020398,unsupervised,"A robot is essential in many industrial and manufacturing facilities due to its efficiency, accuracy, and durability. However, continuous use of the robotic system can result in various component failures. The servo motor is one of the critical components, and its bearing is one of the vulnerable parts, hence failure analysis is required. Some previous prognostics and health management (PHM) methods are very limited in considering the realistic operating conditions of industrial robots based on various operating speeds, loading conditions, and motions, because they consider constant speed data with unloading conditions. This paper implements a PHM for the servo motor of a robotic arm based on variable operating conditions. Principal component analysis-based dimensionality reduction and correlation analysis-based feature selection are compared. Two machine learning algorithms have been used to detect fault features under various operating conditions. This method is proposed as a robust fault-detection model for industrial robots under various operating conditions. Features from different domains not only improved the generalization of the model’s performance but also improved the computational efficiency of massive data by reducing the total number of features. The results showed more than 90% accuracy under various operating conditions. As a result, the proposed method shows the possibility of robust failure diagnosis under various operating conditions similar to the actual industrial environment."
10.1080/17509653.2023.2267505,unsupervised,"This study aims to assess the economic resilience of manufacturing firms through a combination of output-oriented data envelopment analysis (DEA) and machine learning techniques. The research draws on economic resilience factors identified in the literature and focuses on three categories: economic-related factors (financial flexibility, microeconomic market, macroeconomic stability), production-related factors (restoration of production, backup inventories, resource pooling/sharing), and management-related factors (diversification of activities, good governance (management), relocation). Using DEA, a mathematical approach, the study computes and analyzes the contributions of various components to economic resilience. The results of DEA normalization indicate that the highest weighted criteria are financial flexibility, good governance (management), and resource pooling (sharing). To gain a deeper understanding of the data structure, the K-means algorithm is employed for clustering and analysis. K-means clustering is a popular exploratory data analysis technique that aims to group samples into clusters of equal variances by minimizing inertia or the sum of squares within each cluster. The combination of these techniques with sensitivity analysis provides a novel analytical approach for policy formulation and decision-making. The findings have implications for practitioners and domain experts, offering valuable insights into enhancing economic resilience in the manufacturing sector."
10.3390/cryst11091048,unsupervised,"Many automated optical inspection (AOI) companies use supervised object detection networks to inspect items, a technique which expends tremendous time and energy to mark defectives. Therefore, we propose an AOI system which uses an unsupervised learning network as the base algorithm to simultaneously generate anomaly alerts and reduce labeling costs. This AOI system works by deploying the GANomaly neural network and the supervised network to the manufacturing system. To improve the ability to distinguish anomaly items from normal items in industry and enhance the overall performance of the manufacturing process, the system uses the structural similarity index (SSIM) as part of the loss function as well as the scoring parameters. Thus, the proposed system will achieve the requirements of smart factories in the future (Industry 4.0)."
10.1016/j.ijhydene.2022.06.239,unsupervised,"For a H70-T40 dispenser, a fueling process is required to control the temperature to be below 85 °C; the pressure to be under 70 MPa; and the final state-of-charge (SOC) to be between 95% and 100%. Table-based or MC (total heat capacity) formula-based fueling protocols are traditionally used to achieve such control. In this paper, we propose using a machine learning model to predict the key parameters of fueling processes: the final SOC, the final temperature, and the final pressure in the vehicle tank. To handle outliers and noise in real operation, we adopt a two-stage method. In the first stage, after clustering fueling processes using soft dynamic time warping, a small number of fueling processes are selected from a large amount of historical data. In the second stage, based on initial and current operating conditions, the final SOC, temperature, and pressure of fueling processes are predicted using three models: least absolute shrinkage and selection operator (LASSO), Gaussian process regression (GPR), and robust regression. The experiments on real operational data collected from four hydrogen refueling stations show that the robust regression model achieves better performance than LASSO and GPR for three out of the four stations, and that the robust regression model captures the normal states of regular operation. The computational time of the robust regression model is also scalable for real-time operation. Our study provides a feasible machine learning model for predicting the key fueling parameters, which facilitates the optimization of HRS operation."
10.1007/978-3-031-98138-8_7,unsupervised,"The article intends to explore the emerging revolution that machine learning creates in the automation framework for sectors spanning manufacturing, health, transportation, and finance. The chief aim is to experimentally analyse the applicability of various machine learning approaches, such as supervised, unsupervised, reinforcement, deep learning, in productivity enhancement, judgment at real-time, and manual effort and errors in operations. Following the perspective of earlier studies and real-work implementations, the article further identifies critical challenges that are present while implementing an ML-automated system. These challenges are concerns related to the quality of data, computational complexities, and ethical issues in applying ML. These hurdles need to be addressed for the optimal use of ML effects. The findings show where agility and automation have significantly improved processes using machine learning and indicate other gaps in knowledge requiring further investigation On the whole, the paper suggests future areas for study on sustainable and efficient machine-learning automation to extend and inspire scholarship and practice for ingenious projects in this direction."
10.1109/ICMLA51294.2020.00109,unsupervised,"Wire Arc Additive Manufacturing (WAAM) offers the possibility to build up large-scale metal parts. Data which is obtained from a multivariate sensor system in-situ must be analyzed automatically to ensure an early and reliable detection of defects to reduce the costs due to production scrap. For that reason, a modular anomaly detector for multivariate time series in WAAM was investigated in this paper. The approach adressed major topics in real-life data sets of industrial applications such as miscellaneous signal sample rates, lack of synchronization and concept drift. A reference data set based on an anomaly-dependently splitted time horizon was defined to reduce the sensitivity loss of the detector after an anomaly. To avoid the need for labeled data, an unsupervised anomaly detection method based on neural networks was used. Hence, no time and costs for artificial defect creation on the machine tool are required when implementing the approach in industrial applications."
10.1016/j.cie.2020.106851,unsupervised,"To facilitate the planning and execution of maintenance activities, throughput bottlenecks in the production system must be identified and diagnosed. Various research efforts have developed data-driven approaches using real-time machine data to identify throughput bottlenecks in the system. However, these efforts have mainly focused on identifying bottlenecks and only offer limited maintenance-related diagnostics for them. Moreover, these research efforts have been proposed from an academic perspective using rigorous scientific methods. A number of challenges must be addressed, if existing data-driven approaches are to be adapted to real-world practice. These include identifying relevant data types, data pre-processing and data modelling. Such challenges can be better addressed by including maintenance-practitioner input when developing data-driven approaches. The aim of this paper is therefore to demonstrate a data-driven approach to diagnosing throughput bottlenecks, using the combined knowledge of the maintenance and data-science domains. Diagnostic insights into throughput bottlenecks are obtained using unsupervised machine-learning techniques. The demonstration uses real-world machine datasets extracted from the production line. The novelty of the research presented in this paper is that it shows how inputs from maintenance practitioners can be used to develop data-driven approaches for diagnosing throughput bottlenecks having more practical relevance. By gaining these diagnostic insights, maintenance practitioners can better understand shop-floor throughput bottleneck behaviours from a maintenance perspective and thus prioritise various maintenance actions."
10.1007/978-3-031-93631-9_15,unsupervised,"This paper extends previous work in predictive maintenance that implement a self-adaptive evolutionary strategy (SA-ES) for feature selection in multi-label anomaly detection tasks. We incorporate Shapley Additive exPlanations (SHAP), an explainable artificial intelligence (XAI) method, to evaluate the relevance and classification performance of features selected by the SA-ES, and compare their effectiveness against those with the highest absolute Shapley values. A comparative analysis is performed using three multi-label classifiers on a public predictive maintenance dataset, with evaluation conducted through 5-fold cross-validation. Our findings validate the efficiency of the SA-ES in reducing feature dimensions and minimizing Hamming Loss. Additionally, we present insightful visualizations and interpretations for multi-label anomaly classification, facilitating the application of predictive maintenance in real-world industrial scenarios."
10.1088/1742-6596/2692/1/012023,unsupervised,"A robust to uncertainty Machine Learning (ML) based Structural Health Monitoring methodology for populations of composite aerostructures is postulated. The methodology is founded upon a number of unsupervised ML algorithms for damage detection and a supervised counterpart for damage characterization. Damage detection is specifically based on two types of Healthy Subspace representations: A Multiple Model (MM) and a varying radii Hyper-Sphere (HS) type. Both are built upon response-only vibration acceleration and/or strain signals at properly selected sensor locations. Based on them, Multiple Input Single Output (MISO) Transmittance Function AutoRegressive with eXogenous (TF-ARX) excitation data driven models representing the partial structural dynamics are obtained. Decision making is then based on the model parameter vector that may be transformed and reduced via Principal Component Analysis (PCA). Damage detection is achieved via multi-level information fusion using acceleration and/or strain sensors. Damage characterization, referring to damage type, location, and level determination, is achieved via a hierarchical cosine similarity based algorithm. The methodology is successfully assessed via hundreds of experiments using a population of small-scale composite coupons for the detection and characterization of Delamination and Impact damage under material/manufacturing, temperature, excitation, and experimental uncertainty."
10.1016/B978-0-443-33498-6.00008-X,reinforcement,"All rights are reserved, including those for text and data mining, AI training, and similar technologies.The inclusion of modern technologies in Industry 5.0 and Society 5.0 programs is unprecedented, highlighting the seamless interaction of human-centered approaches and technological advances as Industry 5 is built on Industry 4 principles, including aims to create a harmonious industrial environment where human intelligence, machines, and productivity coexist in balance. A concept from Japan is that Society 5.0 seeks to solve social challenges by integrating virtual and physical spaces, leading to improved and sustainable well-being, this chapter examines several issues to model practical applications and challenges associated with different models. A significant case study examines the use of reinforcement learning (RL) augmented memetic algorithm for multiobjective flexible job shop scheduling (FJSS). This study demonstrated the effectiveness of Industry 5 technologies in decreasing the duration of jobs and the workforce needed in an aircraft repair facility. While the findings have yielded positive results, their potential for application in other industries is restricted. Another case study investigated sophisticated RL techniques for intelligent manufacturing in the settings of Industry 4.0 and 5.0. The study emphasized the capability of these technologies to improve manufacturing efficiency and adaptability. However, the existence of biases in data sources and the need for continuous technological advancements pose substantial challenges. Furthermore, the use of the Industrial Internet of Things (IoT) and machine learning (ML) methods to enhance energy efficiency in a process-producing firm, in line with the Industry 5 concept, has underscored the importance of artificial intelligence in achieving sustainability goals. Nevertheless, notable obstacles were recognized with concerns about the integrity of data and the incorporation of intricate systems. An important investigation in the field of Society 5 focused on developing a security system that is aware of the surroundings and can protect data privacy in settings enabled by the IoT. The research presented a strategy that utilizes edge intelligence for attribute learning to decrease network latency, energy usage, and packet loss. The limitations of correct context-aware attribute learning and computational complexity were discovered despite the usefulness of the system. ML algorithms used in healthcare systems within Society 5 have shown a notable level of precision in predicting diseases, hence highlighting the capabilities of quantum ML in expediting data processing. However, there are still problems that need to be resolved, such as the inability to manage all the data, exceeding budget, and the need for more sophisticated design. It also examines the more significant problems that make using this cutting-edge technological feature difficult. An important investigation in the field of Society 5 focused on developing a security system that is aware of the surroundings and can protect data privacy in settings enabled by the IoT. The research presented a strategy that utilizes edge intelligence for attribute learning to decrease network latency, energy usage, and packet loss. The limitations of correct context-aware attribute learning and computational complexity were discovered despite the usefulness of the system. ML algorithms used in healthcare systems within Society 5 have shown a notable level of precision in predicting diseases, hence highlighting the capabilities of quantum ML in expediting data processing. Still, there are problems that are required to be addressed including inadequate data processing, overspending on expenses, and the requirement of more sophisticated design. The research also examines more general issues that complicate the usage of this innovative technological tool. If the data are erroneous or the models are too complicated due to their inadequate accuracy and flaws, ML choices might be wrong. Promoting equity and transparency helps reduce inequality and build trust through these tools. Also exacerbating socioeconomic inequalities is the digital divide, often defined as the gap between technological access and requirements. In this context, improved methods of encryption and appropriate policies are needed to improve digital literacy. Particularly in view of the rising amount of data being gathered, data privacy is of great relevance. Strong data security policies and raising knowledge about cybercrime are very essential to stop the abuse of personal data. Furthermore, developing ML programs more acceptable and better at what they do calls for acquiring new abilities, adjusting cultures, and bringing personnel from other companies to collaborate. The shift to Industry 5 and Society 5 alters our perspective and application of major technology advancements. These models underline the significance of appreciating human well-being and sensible use of technology in a sequence of sustainability. Dealing with the problems brought forward will enable one to optimize these technologies and ensure a future that is both environmentally and socially conscientious as well as financially successful. Also, making ML programs more acceptable and better at what they do requires learning new skills, changing cultures, and getting people from different businesses to work together. The move to Industry 5 and Society 5 changes how we think about and use technological progress in a big way. These models underline the requirement of appreciating human well-being and suitable technology use in a sequence of sustainability. Dealing with the problems raised will enable one to optimize these technologies and ensure a future that is environmentally, socially, and financially sustainable."
10.1016/j.ssaho.2025.101401,reinforcement,"AI technology holds significant potential to enhance accessibility, inclusivity, and equity in quality education. The research utilizes the Preferred Reporting Items for Systematic Reviews and Meta-Analyses approach to analyze publications from articles and conference papers published in the Scopus database between 2014 and 2023. The key findings indicate that AI is reshaping vocational education by personalizing learning experiences, improving curriculum development, and enhancing practical training through automation and robotics, particularly in the manufacturing and logistics sectors. Ethical issues, such as privacy and algorithmic bias, are also highlighted as key concerns. The bibliometric analysis reveals that journal articles have a higher citation count than conference papers, reflecting their greater influence in the field. Network visualization demonstrates the interconnection between AI, vocational education, and related concepts, such as e-learning and machine learning. Furthermore, AI contributes to the achievement of the United Nations Sustainable Development Goals (SDGs) 2030, particularly SDG 4 (quality education access), SDG 8 (decent work and economic growth), and SDG 9 (industry, innovation, and infrastructure). The study also identifies challenges that need to be addressed, including data privacy, infrastructure readiness, and teacher training, while providing guidance for future research and educational policy development."
10.3390/pr13072256,reinforcement,"The global trend toward Industry 4.0 has intensified the demand for intelligent, adaptive, and energy-efficient manufacturing systems. Machine learning (ML) has emerged as a crucial enabler of this transformation, particularly in high-mix, high-precision environments. This review examines the integration of machine learning techniques, such as convolutional neural networks (CNNs), reinforcement learning (RL), and federated learning (FL), within Taiwan’s advanced manufacturing sectors, including semiconductor fabrication, smart assembly, and industrial energy optimization. The present study draws on patent data and industrial case studies from leading firms, such as TSMC, Foxconn, and Delta Electronics, to trace the evolution from classical optimization to hybrid, data-driven frameworks. A critical analysis of key challenges is provided, including data heterogeneity, limited model interpretability, and integration with legacy systems. A comprehensive framework is proposed to address these issues, incorporating data-centric learning, explainable artificial intelligence (XAI), and cyber–physical architectures. These components align with industrial standards, including the Reference Architecture Model Industrie 4.0 (RAMI 4.0) and the Industrial Internet Reference Architecture (IIRA). The paper concludes by outlining prospective research directions, with a focus on cross-factory learning, causal inference, and scalable industrial AI deployment. This work provides an in-depth examination of the potential of machine learning to transform manufacturing into a more transparent, resilient, and responsive ecosystem. Additionally, this review highlights Taiwan’s distinctive position in the global high-tech manufacturing landscape and provides an in-depth analysis of patent trends from 2015 to 2025. Notably, this study adopts a patent-centered perspective to capture practical innovation trends and technological maturity specific to Taiwan’s globally competitive high-tech sector."
10.1109/ISCA52012.2021.00083,reinforcement,"The revolution of machine learning poses an unprecedented demand for computation resources, urging more transistors on a single monolithic chip, which is not sustainable in the Post-Moore era. The multichip integration with small functional dies, called chiplets, can reduce the manufacturing cost, improve the fabrication yield, and achieve die-level reuse for different system scales. DNN workload mapping and hardware design space exploration on such multichip systems are critical, but missing in the current stage.This work provides a hierarchical and analytical framework to describe the DNN mapping on a multichip accelerator and analyze the communication overhead. Based on this framework, we propose an automatic tool called NN-Baton with a pre-design flow and a post-design flow. The pre-design flow aims to guide the chiplet granularity exploration with given area and performance budgets for the target workload. The post-design flow focuses on the workload orchestration on different computation levels -package, chiplet, and core - in the hierarchy. Compared to Simba, NN-Baton generates mapping strategies that save 22.5%∼44% energy under the same computation and memory configurations.The architecture exploration demonstrates that area is a decisive factor for the chiplet granularity. For a 2048-MAC system under a 2 mm2 chiplet area constraint, the 4-chiplet implementation with 4 cores and 16 lanes of 8-size vector-MAC is always the top-pick computation allocation across several benchmarks. In contrast, the optimal memory allocation policy in the hierarchy typically depends on the neural network models."
10.1007/s10845-024-02562-5,reinforcement,"The capability to automatically learn from the design and manufacturing data of discrete manufacturing processes is essential for the development of future data-driven Computer-Aided Process Planning systems. This investigation presents an integrated learning approach, merging principles of deep learning with those of machine learning, to address the issue of detecting minuscule features due to constrained voxel resolution. The proposed model effectively learns local and global features of voxelized workpieces and better understands how quality information impacts classification performance. The model architecture consists of a dual-branch network that combines hybrid convolutional neural networks with a batch-attention Transformer encoder. The hybrid convolution branch extracts shape features, while the Transformer encoder extracts machining information features. These features are fused to jointly learn shape and quality attributes. A decision tree is also trained on a newly constructed dataset to distinguish between finishing and roughing processes. Finally, an ensemble learning strategy is employed, where a learnable linear layer fuses the output probabilities of both models. The proposed approach was evaluated on the MDP and EMDP datasets, achieving accuracies of 100 and 99.72%, respectively, which represents an improvement of 7.59 and 6.66% over the baseline model, outperforming 13 state-of-the-art backbone network models."
10.1016/j.oceaneng.2024.117534,reinforcement,"To tackle this problem, this paper addresses adaptive neural network (NN) optimized control for dynamic positioning (DP) of marine vessels suffering from unknown model uncertainties and control gains, ocean disturbances, and full-state/input constraints. To realize model-free optimized control, the reinforcement learning (RL) with a critic–actor–identifier architecture is constructed on the basis of NN approximation, in which the actor, critic, and identifier NNs are designed to perform control actions, evaluate control performance, and estimate unknown dynamics, respectively. To effectively guarantee the system safety, the critics and actors in the corresponding subsystems are decomposed into a guaranteed safety-related constraint term with respect to the barrier Lyapunov function (BLF) and an unknown dynamic term to be learned. Such a control strategy can ensure that all the state variables are restricted to a predefined safety region, even in the learning control process. From the above logical ideas, the adaptive optimized kinematic and kinetic control laws are presented to guarantee that the whole vessel system is optimized. Moreover, the motion control responses of vessels in various scenarios are realistically simulated through convincing simulations and model-scale tests. The validation results prove the applicability and feasibility of the proposed DP control strategy for practical offshore engineering."
10.13196/j.cims.2023.0042,reinforcement,"All rights reserved.To deal with the uncertain remanufacturing scheduling optimization problem with re-entrant operation and flexible machines, a new remanufacturing re-entrant flexible job-shop scheduling model was proposed with bi-fuzzy theory to describe the uncertainty of processing time and cost. To solve this model, an improved NSGA-II algorithm was proposed, which integrated reinforcement learning to dynamically adjust the crossover rate for maintaining population diversity. Besides, in the algorithm, a new two-dimensional coding scheme was proposed to improve the algorithmic efficiency, a hybrid population initialization strategy was embedded to improve the initial population quality, and a local search strategy was adopted to enhance the local search capability. Finally, simulation experiments demonstrated the performance and effectiveness of the proposed algorithm."
10.1088/1742-6596/2626/1/012051,reinforcement,"Ideally, optimum power for a single turbine is obtained when the wind-turbine is aligned with the wind direction. However in multi-turbine wind-farm set-up, wake effects lead to decreased power production from downstream turbine [1, 2, 3, 4, 5]. Hence, a control strategy based on wake steering involves misalignment of upstream turbines with the wind direction causing their wakes to deflect away from downstream wind turbines needs to be investigated. A great deal of work has been put into dynamically controlling the orientation of the individual wind turbines to maximize the power output of the farm [6, 7, 8, 9]. In the wake-steering based control, the misaligned wind turbines produce less power, while the performance of downstream turbines gets enhanced which increases overall net power gain for the wind power plant. Traditionally, the benefits of wake steering have been demonstrated assuming fixed wind directions (e.g., using high-fidelity modeling). Amongst the most recent techniques, particularly promising is the use of Reinforcement learning (RL), which is a branch of machine learning where models are trained to make decisions based on observations of their environment. It is a flexible framework for devising strategies for solving optimal control problems in a broad range of applications across the sciences. Early attempts at using Reinforcement learning for wake steering have been carried out [7, 8, 9], and show promising results. In practice, however, wake-steering controllers must operate in dynamic wind environments in which the wind conditions are estimated from imperfect measurements. Hence, a reinforcement learning framework is developed in this work for dynamic wind conditions. The results show that the framework is promising, and we compare the deep reinforcement learning approach against a considerably more expensive traditional optimization approach which serves as a good baseline. Future work could include looking at more realistic wake models, steering in the presence of noisy observations, and incorporating weather predictions."
10.1109/TASE.2024.3371250,reinforcement,"Cloud manufacturing (CMfg) converts the traditional manufacturing system into an Internet-of-things-enabled (IoT-enabled) manufacturing system, where both manufacturing and computational tasks must be scheduled among distributed and heterogeneous resources. Deep reinforcement learning (DRL) has recently become a promising idea for task scheduling in CMfg. However, existing DRL-based methods depend heavily on problem-specific reward engineering and struggle to represent hybrid decision variables. To this end, this paper proposed the sparse-reward deep reinforcement learning (SDRL) method to solve the hybrid task scheduling problem in CMfg. First, the hybrid task scheduling model in CMfg is constructed to minimize the makespan. We reformulate the studied problem as a partially observable Markov decision process (POMDP). Then, the objective hindsight experience replay (objective HER) mechanism is proposed to alleviate the sparse reward issue, through which the scheduling policy can be effectively trained without problem-specific reward engineering. The continuous action space is defined to represent hybrid decision variables, and the implicit action-selection mapping is utilized to alleviate the boundary effect. Numerical experiments validated the effectiveness and superiority of our method compared to eleven popular scheduling algorithms including evolutionary algorithms and DRL. Compared to mainstream DRL scheduling methods, the proposed SDRL outperforms the second-best one at most by 23.6% regarding generalization, and a scheduling solution can be generated in 0.5 seconds. Note to Practitioners - With the intelligentization of the CMfg platform, hybrid tasks, including manufacturing and computational tasks, need to be scheduled simultaneously. However, this hybrid task scheduling problem is rarely considered by existing works. DRL exhibits many benefits in addressing scheduling problems, but the strong dependency on problem-specific reward engineering limits its application. Additionally, most DRL-based scheduling algorithms are discrete-action DRL, restricting their capacity to effectively represent hybrid decision variables. The studied problem originates from the CMfg platform, but the proposed method holds potential for broader application. The scheduling framework and the POMDP modeling can be applied to similar problems, including hybrid, manufacturing, or computational task scheduling problems. The proposed objective HER serves as a general approach to addressing challenges associated with sparse rewards, which can be extended to diverse combinatorial optimization problems aimed at optimizing an objective. We will open-source our codes to help others to apply the method to other fields."
10.1109/OJCOMS.2025.3553302,reinforcement,"This paper explores the integration of Artificial Intelligence into 6G networks, focusing on optimizing communication, resource allocation, and enhancing security. As communication systems transition from 5G to 6G, Artificial Intelligence's role in addressing the increasing complexity of network management becomes pivotal. The paper reviews key AI technologies such as machine learning, deep learning, and reinforcement learning, demonstrating their applications in predictive maintenance, traffic management, and energy efficiency optimization. It also highlights how Artificial Intelligence enables intelligent network slicing, spectrum management, and resource allocation through dynamic algorithms. Furthermore, Artificial Intelligence-driven solutions are presented for addressing security concerns in 6G networks, focusing on intrusion detection, anomaly detection, and blockchain-based decentralized security. Challenges such as computational overhead, data privacy, and ethical concerns in implementing Artificial Intelligence in 6G systems are also discussed, along with future directions, including quantum AI and federated learning. This paper provides a comprehensive analysis of how Artificial Intelligence can enhance the capabilities of 6G networks, ensuring improved performance, security, and scalability for future communication technologies."
10.1007/978-3-319-48743-4_31,reinforcement,"Paper manufacturing is energy demanding and improved modelling of the pulp bleach process is the main non-invasive means of reducing energy costs. In this paper, time it takes to bleach paper pulp to desired brightness is examined. The model currently used is analysed and benchmarked against two machine learning models (Random Forest and TreeBoost). Results suggests that the current model can be superseded by the machine learning models and it does not use the optimal compact subset of features. Despite the differences between the machine learning models, a feature ranking correlation has been observed for the new models. One novel, yet unused, feature that both machine learning models found to be important is the concentration of bleach agent."
10.1002/btm2.70013,reinforcement,"Bioengineering & Translational Medicine published by Wiley Periodicals LLC on behalf of American Institute of Chemical Engineers.Managing delivery of complex multidrug infusions in anesthesia and critical care presents a significant clinical challenge. Current practices relying on manual control of infusion pumps often result in unpredictable drug delivery profiles and dosing errors—key issues highlighted by the United States Food and Drug Administration (FDA). To address these issues, we introduce the SMART (synchronized-pump management algorithms for reliable therapies) framework, a novel approach that leverages low Reynolds number drug transport physics and machine learning to accurately manage multidrug infusions in real-time. SMART is activated based on the Shafer number ((Formula presented.)), a novel non-dimensional number that quantifies the relative magnitude of a drug's therapeutic action timescale to its transport timescale within infusion manifolds. SMART is useful when (Formula presented.), where drug transport becomes the rate limiting step in achieving the desired therapeutic effects. When activated, SMART monitors multidrug concentrations within infusion manifolds and leverages this information to perform end-to-end management of drug delivery using an ensemble of deterministic and deep reinforcement learning (RL) decision networks. Notably, SMART RL networks employ differentially sampled split buffer architecture that accelerates learning and improves performance by seamlessly combining deterministic predictions with RL experience during training. SMART deployed in standalone infusion pumps under simulated clinical conditions outperformed state-of-the-art manual control protocols. This framework has the potential to revolutionize critical care by enhancing accuracy of medication delivery and reducing cognitive workloads. Beyond critical care, the ability to accurately manage multi-liquid delivery via complex manifolds will have important bearings for manufacturing and process control."
10.1016/j.scitotenv.2024.174665,reinforcement,"This work is situated within the ambit of the Sustainable Development Goals (SDGs), advocating for a transition towards renewable energy sources. With substantial and accessible bioenergy resources, notably in Hubei Province, China, biogas technology has emerged as an emission-cutting solution. This research, focused on the Jianghan Plain, employs an integrated approach combining spatial analyses with machine learning tools to evaluate crop yield stability over two decades, with the aim of maximising the biogas yield from agricultural byproducts, i.e., crop straw and livestock manure. Using Multi-Criteria Decision Analysis (MCDA), which is informed by grey-based DEMATEL, 9 constraints and 13 environmental, social, and economic criteria were assessed to identify optimal sites for biogas facilities. The findings underscore the significant bioenergy potential of agricultural byproducts from the plain of 6.3 × 1012 kJ/year at an 11.4 kJ/m2 density. Stability analyses revealed consistent biomass availability, with rice in Gongan and Shayang and wheat in Jiangling being the primary contributors. Through the MCDA, 45–66 optimal biogas plants were identified across 4 critical counties (Zhongxiang, Shangyang, Jingshan, and Yichen), balancing the energy supply and demand under various stable scenarios. Furthermore, this study demonstrated the criticality of moderate biomass stability for stakeholder consensus and identified areas of high stability essential for energy demand fulfilment. Theoretically, this study offers a practical model for bioenergy resource exploitation that aligns with global sustainability and carbon neutrality goals to address the urgent need for renewable energy solutions amidst the global energy crisis. Practically, this study sets a precedent for policy and planning in environmental, agricultural, and renewable sectors, signifying a step forwards in achieving environmental sustainability and an energy-efficient future."
10.1002/9781119515326.ch4,reinforcement,"All rights reserved.Prognostics and health management (PHM) facilitates maintenance decision-making and provides usage feedback for the product design and validation process. Electronic component and product manufacturers need new ways to gain insights from the massive volume of data recently streaming in from their systems and sensors, and this can be accomplished by using machine learning (ML). This chapter provides the fundamentals of ML. ML algorithms can be divided into the following four categories depending on the amount and type of supervision they need while training: supervised, unsupervised, semi-supervised, and reinforcement learning. ML algorithms can be classified into two different learning methods based on whether or not the algorithms can learn incrementally from a stream of incoming data: batch and online learning. Probability theory plays a significant role in ML, specifically as the design of learning algorithms often depends on probabilistic assumption of the data."
10.1109/CASE59546.2024.10711602,reinforcement,"The discovery of partial differential equations (PDEs) directly from data has significant implications for automation and manufacturing fields. This approach leverages advanced computational techniques and data-driven methodologies to identify the underlying mathematical models that govern the physical processes in various systems. In this article, a deep symbolic regression framework is developed for PDE discovery which is enhanced by reinforcement learning with spatio-temporal rewards. Within this framework, a dense encoder-decoder network is proposed to adeptly extract the information of temporal dynamics related to PDEs from the data, and a refined reinforcement learning reward shaping technique is further put forward that incorporates the extracted dynamics, specifically designed for PDE symbolic regression tasks. An example of Cahn-Hilliard equation, which is widely used to describe the phase separation process in multi-component mixture systems, is used to validate the effectiveness of the proposed approach. The experimental results show that the proposed deep symbolic regression approach outperforms the baselines in identifying PDEs, achieving higher accuracy with less data. Additionally, we provide a thorough analysis on how adjustable parameters affect the PDE discovery performance, further verifying the effectiveness of the proposed approach."
10.1371/journal.pone.0290120,reinforcement,"This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.The global food prices have surged to historical highs, and there is no consensus on the reasons behind this round of price increases in academia. Based on theoretical analysis, this study uses monthly data from January 2000 to May 2022 and machine learning models to examine the root causes of that period’s global food price surge and global food security situation. The results show that: Firstly, the increase in the supply of US dollars and the rise in oil prices during pandemic are the two most important variables affecting food prices. The unlimited quantitative easing monetary policy of the US dollar is the primary factor driving the global food price surge, and the alternating impact of oil prices and excessive US dollar liquidity are key features of the surge. Secondly, in the context of the global food shortage, the impact of food production reduction and demand growth expectations on food prices will further increase. Thirdly, attention should be paid to potential agricultural import supply chain risks arising from international uncertainty factors such as the ongoing Russia-Ukraine conflict. The Russian-Ukrainian conflict has profoundly impacted the global agricultural supply chain, and crude oil and fertilizers have gradually become the main driving force behind the rise in food prices."
10.1007/s10586-025-05456-0,reinforcement,"Industry 5.0 places the combination of human decision-making and machine technology at the heart of high industrial automation. The real-time hybrid tasks resilient collaborative scheduling are the challenging problems as resilient and human-centric systems through human–machine collaboration. Current mainstream research usually perform manufacturing task scheduling and computing task scheduling separately to pursue their specific goals. Exist collaborative scheduling methods mainly focus on improving scheduling performance, ignore the dependencies between manufacturing and computing tasks, and the highly dynamic nature of the edge environment. In this paper, we propose a hybrid task scheduling model for the resilient collaborative scheduling problem of manufacturing and computing tasks. Firstly, based on the dependency between manufacturing tasks and computing tasks, we design a multi-agent graph reinforcement learning algorithm to balance the productivity and computational latency. Then, we propose an adaptive learning framework based on meta-learning for the highly dynamic edge computing environment, which fully utilizes the fast environment learning capability of meta-learning, enabling the algorithm to converge rapidly with fewer training steps when the environment changes. Finally, experiments show that our method can improve the performance efficiently."
10.1109/JIOT.2025.3604413,reinforcement,"Industry 5.0 represents a significant advancement from Industry 4.0, emphasizing improved cooperation between humans and machines, eco-friendly practices, and customized solutions in manufacturing. In contrast to earlier research on Industry 4.0, this survey provides a thorough examination of the function of machine learning (ML) in Industry 5.0 by examining the ways in which various learning paradigms facilitate sustainable production, human–machine cooperation, and customized industrial solutions. We first examine cutting-edge learning approaches, encompassing supervised, unsupervised, semi-supervised, and reinforcement learning methodologies, and their role in advancing Industry 5.0 objectives. Next, we emphasizes the incorporation of ML techniques to improve manufacturing productivity and optimize decision-making processes. Even with advancements, Industry 5.0 may suffer several challenges and limitations, such as intelligent decision-making, security, data privacy, etc. To address the challenges of Industry 5.0, it is crucial to comprehend its protocols, which this survey examines alongside relevant technologies. Therefore, our survey also explores the primary challenges encountered when incorporating ML into Industry 5.0, such as integrating data, ensuring interoperability, and maintaining sustainability. Furthermore, the study elaborates on how these techniques drives substantial progress in various emerging applications by enhancing operational procedures and enabling innovative capabilities. Finally, we discuss potential research routes to overcome these hurdles and achieve the practical implementation of Industry 5.0."
10.32604/cmc.2022.020066,reinforcement,"All rights reserved.In recent years, progressive developments have been observed in recent technologies and the production cost has been continuously decreasing. In such scenario, Internet of Things (IoT) network which is comprised of a set of Unmanned Aerial Vehicles (UAV), has received more attention from civilian to military applications. But network security poses a serious challenge to UAV networks whereas the intrusion detection system (IDS) is found to be an effective process to secure the UAV networks. Classical IDSs are not adequate to handle the latest computer networks that possess maximum bandwidth and data traffic. In order to improve the detection performance and reduce the false alarms generated by IDS, several researchers have employed Machine Learning (ML) and Deep Learning (DL) algorithms to address the intrusion detection problem. In this view, the current research article presents a deep reinforcement learning technique, optimized by Black Widow Optimization (DRL-BWO) algorithm, for UAV networks. In addition, DRL involves an improved reinforcement learning-based Deep Belief Network (DBN) for intrusion detection. For parameter optimization of DRL technique, BWO algorithm is applied. It helps in improving the intrusion detection performance of UAV networks. An extensive set of experimental analysis was performed to highlight the supremacy of the proposed model. From the simulation values, it is evident that the proposed method is appropriate as it attained high precision, recall, F-measure, and accuracy values such as 0.985, 0.993, 0.988, and 0.989 respectively."
10.1109/ICMLA.2007.35,reinforcement,This paper presents the application of a reinforcement learning (RL) approach for the near-optimal control of a re-entrant line manufacturing (RLM) model. The RL approach utilizes an algorithm based on a gradient-descent TD(X) method to obtain both estimates of the optimal cost function and the control actions. Numerical experiments demonstrated the efficacy of the approach in estimating optimal actions by showing close approximations in performance w.r.t. the optimal strategy. Generalizations of the RL approach may have the advantage of scaling appropriately for RLM models with different dimensions in the state and action spaces. © 2007 IEEE.
10.1016/j.ifacol.2024.09.119,reinforcement,"Copyright © 2024 The Authors.The automatic generation of maintenance orders facilitates the prompt detection and root cause analysis of deviations or failures in the assembly process. The aim of this project is to use supervised learning models to recognise deviations in the throughput times of a fully automated assembly process carried out by robots. The model identifies errors, categorises their causes and transmits the information back to the Enterprise Resource Planning (ERP) system. The data collected comes from a development and test assembly station with an industrial robot. The data set from the assembly station was expanded using agent-based simulation in order to train the four models Support Vector Machine, K-Neares Neighbour, Naive Bayes and Decision Tree. The SVM model proved to be the most suitable model for automatic fault detection with an accuracy of 99.51 %. The model was integrated into the assembly station and an algorithm was developed to automatically generate maintenance messages to transmit the failure code to the ERP system."
10.31181/dmame712024885,reinforcement,"Taking an integrated approach towards production, maintenance, and control in manufacturing systems is crucial due to the profound impact of their interconnections. Investigating these aspects in isolation may lead to infeasible solutions. This research focuses on the real-time and autonomous decision-making process concerning joint production planning, maintenance, and quality problem in a stochastic deteriorating production system with limited maintenance activities. Formulating the problem as a continuous semi-Markov decision process accounts for the complexities of the real production system and the occurrence of events over an uneven and continuous period. While dynamic programming is a common tool for addressing joint optimization problems, it has limitations, such as the curse of dimensionality. In this study, the optimal policy of the decision-maker agent is obtained by the goal-directed machine learning method called (R-SMART) and agent-based modeling. To the author's knowledge, the proposed approach is novel, and there is little research on such an implementation of the joint optimization problem. The quality of the optimal policy is evaluated through heuristic and simulation-optimization methods in various scenarios. The results demonstrate that the proposed RL-based method outperforms others in most scenarios, achieving a stable, integrated optimal policy."
10.1016/j.ijhydene.2025.01.034,reinforcement,"In this study, machine learning algorithms are used to facilitate the optimization of the biomass gasification process with the goals of H2 promotion and tar inhibition. Four machine learning predicting models are constructed, and the best algorithm is PSO-SVR, achieving R2 = 0.8701 for the tar yield prediction and R2 = 0.9105 for the H2 concentration prediction. The combination of SHAP and dual-objective PDP reveals temperature is the primary factor influencing tar generation and has a notable effect on H2 concentration. The optimal gasification temperature should be approximately 920∼980 °C, at which the predicted H2 concentration will be the highest and tar yield will be significantly reduced. Moreover, improving fluidized beds, doping ores with catalytic effects in reactor material, using steam as gasification agent, and adding catalysts play positive roles. Future studies could explore the optimization of reactor design parameters and design specific catalyst. This study offers distinctive perspectives and supports of tar inhibition for the application of biomass gasification."
10.1016/j.ssci.2021.105529,reinforcement,"Thus, the new industrial paradigm of Industry 4.0 has gained interest worldwide, leading many manufacturers to a significant digital transformation. Digital technologies have enabled a novel approach to decision-making processes based on data-driven strategies, where knowledge extraction relies on the analysis of a large amount of data from sensor-equipped factories. In this context, Predictive Maintenance (PdM) based on Machine Learning (ML) is one of the most prominent data-driven analytical approaches for monitoring industrial systems aiming to maximise reliability and efficiency. In fact, PdM aims not only to reduce equipment failure rates but also to minimise operating costs by maximising equipment life. When considering industrial applications, industries deal with different issues and constraints relating to process digitalisation. The main purpose of this study is to develop a new decision support system based on decision trees (DTs) that guides the decision-making process of PdM implementation, considering context-aware information, quality and maturity of collected data, severity, occurrence and detectability of potential failures (identified through FMECA analysis) and direct and indirect maintenance costs. The decision trees allow the study of different scenarios to identify the conditions under which a PdM policy, based on the ML algorithm, is economically profitable compared to corrective maintenance, considered to be the current scenario. The results show that the proposed methodology is a simple and easy way to implement tool to support the decision process by assessing the different levels of occurrence and severity of failures. For each level, savings and the potential costs have been evaluated at leaf nodes of the trees aimed at defining the most suitable maintenance strategy implementation. Finally, the proposed DTs are applied to a real industrial case to illustrate their applicability and robustness."
10.1016/j.compedu.2020.104052,reinforcement,"For this purpose, a study was conducted with 1071 in-service teachers. The instrument was validated with respect to its factorial structure, and the relation between teachers' digital competence and personal and contextual factors was analysed using three different analyses: (i) simple linear regression, (ii) multiple linear regression, and (iii) machine learning. The results show that all the analyses conducted confirm the prevalence of personal factors over contextual ones, as well as their stronger predictive capacity. Gender and age differences were found, but the number of tools used for teaching and learning was the strongest predictor of teachers' digital competence, followed by ease of use, confidence in using digital technology, and openness to new technology. The article shows the soundness of the DigCompEdu framework and provides knowledge that could benefit teacher training programmes and inform policy and practice."
10.1109/LCA.2025.3580562,reinforcement,"Workload partitioning and mapping are critical to optimizing performance in multi-chiplet systems. However, existing approaches struggle with scalability in large search spaces and lack transferability across different workloads. To overcome these limitations, we propose Stardust, a scalable and transferable workload mapping on multi-chiplet systems. Stardust combines learnable graph clustering to downscale computation graphs for efficient partitioning, topology-masked attention to capture structural information, and deep reinforcement learning (DRL) for optimized workload mapping. Evaluations on production-scale AI models show that (1) Stardust-generated mappings significantly outperform commonly used heuristics in throughput, and (2) fine-tuning a pre-trained Stardust model improves sample efficiency by up to 15× compared to training from scratch."
10.1016/j.jclepro.2025.145958,reinforcement,"This study uses advanced double machine learning methods, analyzing panel data from 273 Chinese cities spanning 2006 to 2022 to explore the effects of smart city policy (SCP) on urban SEPCCR. The research reveals that SCP significantly enhances the SEPCCR, a conclusion that remains robust after a series test such as model replacements and addressing potential endogeneity issues. This study aims to elucidate the mechanisms through which SCP influences SEPCCR, illustrating that the policy can enhance the synergy effect by strengthening government modern governance, promoting intelligent development in enterprises, driving industrial upgrading, and guiding the public participation in green initiatives. Heterogeneity analysis shows that the promoting effects of SCP are more pronounced in cities in eastern region, large cities, cities with higher administrative levels, non-old industrial base cities, and cities with a focus on environmental protection, highlighting the necessity of tailored advancement of SCP. This research provides valuable insights to fortify smart city development endeavors, effectively enhance SEPCCR, and achieve future “dual-carbon” objectives."
10.3389/frsus.2024.1388771,reinforcement,"Copyright © 2024 Abed.Supply chains (SCs) serve many sectors that are, in turn, affected by e-commerce which rely on the make-to-order (MTO) system to avoid a risk in following the make-to-stoke (MTS) policy due to poor forecasting demand, which will be difficult if the products have short shelf life (e.g., refrigeration foodstuffs). The weak forecasting negatively impacts SC sectors such as production, inventory tracking, circular economy, market demands, transportation and distribution, and procurement. The forecasting obstacles are in e-commerce data types that are massive, imbalanced, and chaotic. Using machine learning (ML) algorithms to solve the problem works well because they quickly classify things, which makes accurate forecasting possible. However, it was found that the accuracy of ML algorithms varies depending on the SC data sectors. Therefore, the presented conceptual framework discusses the relations among ML algorithms, the most related sectors, and the effective scope of tackling their data, which enables the companies to guarantee continuity and competitiveness by reducing shortages and return costs. The data supplied show the e-commerce sales that were made at 47 different online stores in Egypt and the KSA during 413 days. The article proposes a novel mechanism that hybridizes the CatBoost algorithm with Dingo Optimization (Cat-DO), to obtain precise forecasting. The Cat-DO has been compared with other six ML algorithms to check its superiority over autoregressive integrated moving average (ARIMA), long short-term memory (LSTM), deep neural network (DNN), categorical data boost (CatBoost), support vector machine (SVM), and LSTM-CatBoost by 0.52, 0.73, 1.43, 8.27, 15.94, and 13.12%, respectively. Transportation costs were reduced by 6.67%."
10.1007/978-3-031-51647-4_1,reinforcement,"With the ever-increasing trend in the global population, providing sufficient nutritious food to everyone has become a serious challenge. The situation is undoubtedly more critical in developing countries where the population explosion, poverty, joblessness, illiteracy, undernourishment, lack of awareness, and infrastructural insufficiency in the field of food production and marketing, etc. are more pronounced compared to the developed countries. Moreover, several unprecedented incidents viz. the COVID-19 pandemic, the Russia-Ukraine war, etc. have posed a great negative impact on the existing situation. However, some countries have taken several initiatives to face the challenges of food and nutritional security by adopting sustainable agricultural practices, modifying food distribution and delivery systems, introducing novel marketing strategies, etc. This chapter, thus, focuses on the present status of food demand in the developing countries of the world, the key determinants of food insecurity, the measures taken by the farmers and others concerned, the policy regulations to attenuate the problems, etc. in detail. The role of advanced food production and preservation technologies along with conscious usage of non-renewable natural resources have also been discussed. The application of innovative tools and techniques like machine learning, remote sensing, artificial intelligence, global positioning system, etc. has also been mentioned. It was observed that the establishment of food security is a multidimensional approach that can only be possible by co-ordinating the traditional and modern agro-industrial practices, disease management strategies, and proper execution of planning in this sector with the help of national and international committees."
10.1016/j.eswa.2024.125616,reinforcement,"This study investigates a hybrid flow shop scheduling problem dominant in real-world printed circuit board assembly shops. A novel multi-objective hyper-heuristic combining Q-learning, i.e., two-stage improved spider monkey optimization (TS-ISMO), is tailored to address the complexities of the flow shop scheduling problems. The proposed method aims to simultaneously optimize conflicting objectives such as minimizing makespan, total energy consumption, and total tardiness time while incorporating lot streaming considerations. For multi-objective hyper-heuristic techniques, the algorithm dynamically selects and adapts a diverse set of low-level heuristics to explore the solution space comprehensively and strike a balance among competing objectives. The proposed TS-ISMO algorithm incorporates several significant features aimed at enhancing its performance. These features encompass hybrid heuristics for solution initialization, a contribution value method for comprehensive convergence and diversity assessment, diverse evolutionary state judgments to promote the algorithm's balance between exploration and exploitation capabilities, and a Q-learning strategy for self-adaptive parameter tuning. The integration of Q-learning facilitates intelligent parameter control, enabling the algorithm to autonomously adjust its behavior based on past experiences and evolution dynamics. This adaptive mechanism enhances convergence speed and solution quality by effectively guiding the search process toward promising regions of the solution space. Extensive computational experiments are conducted on benchmark instances of hybrid flow shop scheduling problems with lot streaming to evaluate the performance of the proposed algorithm. Comparative analyses against state-of-the-art approaches demonstrate its superior solution quality and computational efficiency."
10.1145/3716097.3716103,reinforcement,"The food industry faces the persistent and multifaceted problem of food waste at all levels of its supply chain, significantly impacting sectors that deal with perishable products. This issue primarily arises due to inadequate and inefficient purchasing and replenishment management practices. In the context of Peru, fish stands out as a crucial product, with the fishing and food industry experiencing a remarkable growth rate of 27% over the last decade. This sector now contributes approximately 4% to the national manufacturing GDP and employs a significant portion of the labor force, underpinning its economic importance. However, despite its growth and significance, this industry suffers from substantial levels of waste, accounting for 23% of the total food waste generated in its processes. This is particularly concerning given the global context where hunger levels are growing in Peru and 828 million people around the world suffer from hunger. Motivated by the pressing need to reduce global food waste, particularly in the fish industry, we have developed an integrated and innovative methodology. This methodology combines Demand Driven Material Requirements Planning (DDMRP) for effective inventory management with advanced Machine Learning techniques for accurate demand forecasting. Our approach meticulously identifies the optimal replenishment policy, leading to significant reductions in waste. The study conclusively demonstrates that the application of these advanced techniques can effectively and efficiently address food waste issues within the fish industry. Based on comprehensive bibliographic evidence, it has been shown that it is possible to reduce waste levels by up to 75% using the described tools and methodologies. This research offers a promising pathway for other industries facing similar challenges."
10.1201/9781003396260-2,reinforcement,"This research investigated the changes in land cover and land use (LCLU), crop intensity, and cropping systems in the Ganges Basin over the past 20 years, driven by urban expansion and agricultural intensification, using remote sensing-based Earth observation data. It assessed the impacts of these changes on ecosystem services and used advanced machine learning algorithms to map land cover changes from 2000 to 2015. The study revealed that cropland was the dominant land cover type, with significant changes occurring in grassland, shrubland, waterbody, and forest areas. A case study focusing on the Delhi National Capital Region in India showed a significant increase in urban areas and a decrease in farmland. The research also developed an automatic fishpond mapping workflow using Sentinel-2 images on the Google Earth Engine platform to study the transition from crop cultivation to fish farming in Bangladesh. It efficiently identified and classified small, all-year-inundated water bodies into fishponds and non-fishponds with a precision score of 0.788. Using time-series imagery and harmonic regressions, the study detected crop intensity in Bangladesh, revealing that the dominant cropping system was double cropping with a Kharif season (May to October) and a Rabi season (November to April), and that three-season cropping was relatively rare. The research developed a spatially explicit integrated modeling approach to optimize the seasonal and spatial allocation of crop cultivation and nitrogen fertilizer use, demonstrating substantial improvements in the economic-environmental performance of crop production. However, it also highlighted the limitations of using price as a policy instrument due to the complex relationship between crop prices and cropping areas. The study presented an approach that complements other policy analysis and decision-support tools to optimize the use of nitrogen fertilizers for maximizing farm income and food security while maintaining environmental sustainability. The Nutrient Delivery Ratio (NDR) model showed strong seasonal and spatial variations, with lower values in winter due to less rainfall and higher values in the southeastern region due to fewer croplands and a low fertilizer application rate. The study also found no significant correlation between rural migration and the number of natural shocks but a significant effect of landholding on migration. A web portal was developed to disseminate the data and products from this project, providing stakeholders and the public with visualization and downloading of the LCLU products derived from satellite images and model-derived geospatial information data."
10.1016/j.jafr.2025.101762,reinforcement,"Artificial intelligence (AI) is one such exponent of change that offers possible solutions in a number of agricultural production fields. Emphasis will be placed on robotic automation, machine learning applications, and the concept of precision farming. This research explores how integration in agriculture has made AI an excellent support for decision processes in crop management, providing real-time monitoring and predictive analytics. Higher agricultural yields and resilience are made possible by genetic advancements and AI in resource optimization. However, due to technological, societal, and legal obstacles, the promise for AI in agriculture has not yet materialized. Against this background, this study requires holistic policy frameworks, education, and stakeholder engagement as countermeasures to such challenges. The future potential applications of AI in agriculture continue to change the sector on behalf of improving global food security and sustainability; this concludes the study. This paper tries to bring to light the critical role that AI is most likely to play in shaping future agricultural practices based on an in-depth analysis of the current state of technology and upcoming opportunities."
10.1117/12.3034282,reinforcement,"In the photomask manufacturing industry, photomask source design data needs to be converted into several different target formats, such as MEBES fracture, writer file, die-to-database inspection data etc. Due to the various conversion needs in the manufacturing flow, different EDA tools from different software vendors are employed during conversion. Two different EDA tools that are given the same input can result in slight differences in the output pattern and this will lead to causation of CD errors relative to the underlying pattern tolerances and/or specifications. During the photomask production process, it is very challenging to identify and classify these small differences in the output pattern caused by the conversion of data. In this study, we developed a novel solution to alert on pattern discrepancy by utilizing the classification generated by the application of machine leaning techniques and Smart-MRC tools. A Convolutional Neural Network (CNN) model is being introduced in this study and is trained by learning pre-classified data and classification result would be generated after inputting data to the CNN model. This new Mask Data Preparation (MDP) technique is expected to reduce the use of human resources in the classification process and will bring significant enhancement to our data validation steps to ensure pattern integrity across the entire photomask manufacturing tool chain. Furthermore, the risk of anomalies introduced by updating EDA software tools and their respective version is also mitigated."
10.1109/TCE.2025.3563895,reinforcement,"Deep neural networks have achieved remarkable success in various computer vision tasks. However, in real world applications, such as the Internet of Things (IoT), these models often struggle due to the long-tailed data distributions. For instance, in scenarios such as Holographic Counterpart Integration in IoT-based predictive maintenance for home systems or smart repair services, common operational states are prevalent in the dataset. In contrast, rare failures, such as hardware malfunctions or system breakdowns, are represented by only a few samples. This imbalance severely impacts models, making it difficult to accurately predict rare failures, leading to costly downtime or unanticipated equipment failure. Current contrastive learning-based methods are effective at optimizing feature distributions but often overlook inter-class relationships and are highly sensitive to class imbalance, which limits their generalization ability. To address these challenges, we propose the Adversarial Mixup-based supervised contrast learning (AMCL) framework, which integrates Mixup-based data augmentation with contrastive learning and incorporates an adversarial inspired sample policy generator. AMCL generates boundary samples via a dynamically optimized Mixup strategy to enhance inter-class relationship modeling and improve predictions on ambiguous boundaries. Furthermore, we introduce a new MixCo loss function to account for the non-one-hot distribution of Mixup-generated targets, ensuring better alignment with augmented data and improving optimization efficiency. AMCL is easy to implement and achieves a performance superior to recent approaches for long-tailed recognition across various datasets such as ImageNet-LT, iNaturalist18, CIFAR-10-LT, and CIFAR-100-LT."
10.1186/s40537-025-01178-7,reinforcement,"As the world faces pressing climate and energy challenges, Artificial Intelligence is proven as a transformative force in advancing renewable energy systems. This study reviews the current and future applications of Artificial Intelligence in renewable energy, highlighting its transformative role in enhancing the efficiency, reliability, and scalability of renewable energy systems. The study draws from over 400 recent publications, selected based on their relevance to Artificial Intelligence and renewable energy systems. We discuss the use of Artificial Intelligence techniques including machine learning, deep learning, and reinforcement learning models for optimizing energy production, forecasting demand, predictive maintenance, and managing decentralized energy systems. Emerging fields such as quantum machine learning and Artificial Intelligence-augmented reality are also considered because of their potential to transform energy infrastructures. The survey reviews significant innovations in wind and solar energy, energy storage, and smart grid technologies, focusing on how Artificial Intelligence addresses challenges like intermittency and variability. Furthermore, we discuss the importance of big data, the Internet of Things, and real-time analytics in advancing Artificial Intelligence models, along with the evolving landscape of Artificial Intelligence-driven policy and market modeling for renewable energy adoption. Real-world case studies, like Google’s collaboration with DeepMind for optimizing wind energy output and Australia’s National Electricity Market integrating Artificial Intelligence for grid stability, underscore the practical impact of Artificial Intelligence in renewable energy. This paper highlights challenges that are hindering Artificial Intelligence adoption in renewable energy systems and offers recommendations for improving the available technology to maximize Artificial Intelligence’s potential in promoting sustainable energy and addressing climate change."
10.1007/978-3-031-71633-1_25,reinforcement,"With the digitalization of industries, manufacturing systems are becoming increasingly complex and diverse. There is a growing focus on production flexibility and automation, leading to active research on production logistics (PL) systems that can effectively address these challenges. PL systems significantly influences the quality and productivity of products, and the proper design and optimization of path planning for logistics robots are crucial. This paper proposes a novel approach, Digital Twin (DT)-driven reinforcement learning (RL) for dynamic path planning of automated guided vehicles (AGVs) systems. The complex real-world path planning problem is represented as a Markov Decision Process (MDP) and a DT-based Q learning algorithm that can solve the represented path planning problem is proposed. To validate the effectiveness and adaptability of the proposed approach, a system is implemented and applied to an actual manufacturing site."
10.1093/scipol/scae060,reinforcement,"Published by Oxford University Press. All rights reserved.The paper investigates whether the penetration of advanced manufacturing technologies can be better explained at the regional or national level. If regional effects prevail, policy actions would focus on local investments, while if country effects make regional covariates redundant, they should be redirected to more structural reform of the national systems of innovation. In this respect, the contribution is 2-fold. First, data on acquisitions of industrial robots in the five largest European economies are rescaled at regional levels to draw a clear picture of winners and losers in the robotics race after the 2008 financial crisis. Second, we explain differential of growth rates in robot adoption with (1) traditional measures of industrial variety, (2) an unsupervised machine learning approach classifying a region’s industry profile (3) usual determinants of innovation and, thereafter test the robustness of the results when country effects are added. As the main result, we highlight a process of regional convergence in which country-fixed effects hold greater explanatory power, although related variety and the number of skilled people are statistically significant regional explanatory factors. We do not discover a specific industry mix associated with the rise of adoption, but we highlight the one associated with its decline."
10.1007/978-3-031-60227-6_10,reinforcement,"Process mining aims to extract knowledge from event data to understand, analyze, and improve Processes. Utilizing the benefits of Reinforcement Learning enables the automation of the business processes discovery, by systematically exploring the state space based on a certain environment interaction to achieve a certain goal, that reduces time and effort required for manual analysis and decision-making. This paper proposes an automated system capable of discovering certain organization’s business processes and identifying the optimal sequence of transitions towards the ticket terminal state avoiding the bottleneck. To identify the structure of the business processes, the available source/target transitions are extracted, along with the computed transition probabilities between each possible transition. These probabilities are then incorporated into the reward design, which is needed to adjust the agent’s behavior. By applying the Q-Learning algorithm, a Q-function learns the quality (q-value) of taking each possible action, given a certain state, encoded as a table that is updated iteratively during the training until reaching an optimal policy. Finally, after a certain number of episodes, the optimal sequence of transitions is identified. The Deep Q-Network (DQN) algorithm is applied to compare the results between the two approaches, and the Q-Learning agent tends to produce the optimal path that is aligned with the business processes."
10.1145/3610548.3618235,reinforcement,"The packing problem, also known as cutting or nesting, has diverse applications in logistics, manufacturing, layout design, and atlas generation. It involves arranging irregularly shaped pieces to minimize waste while avoiding overlap. Recent advances in machine learning, particularly reinforcement learning, have shown promise in addressing the packing problem. In this work, we delve deeper into a novel machine learning-based approach that formulates the packing problem as conditional generative modeling. To tackle the challenges of irregular packing, including object validity constraints and collision avoidance, our method employs the score-based diffusion model to learn a series of gradient fields. These gradient fields encode the correlations between constraint satisfaction and the spatial relationships of polygons, learned from teacher examples. During the testing phase, packing solutions are generated using a coarse-to-fine refinement mechanism guided by the learned gradient fields. To enhance packing feasibility and optimality, we introduce two key architectural designs: multi-scale feature extraction and coarse-to-fine relation extraction. We conduct experiments on two typical industrial packing domains, considering translations only. Empirically, our approach demonstrates spatial utilization rates comparable to, or even surpassing, those achieved by the teacher algorithm responsible for training data generation. Additionally, it exhibits some level of generalization to shape variations. We are hopeful that this method could pave the way for new possibilities in solving the packing problem."
10.1016/j.hybadv.2024.100277,reinforcement,"This comprehensive review paper aims to provide readers with a deep understanding of AI's applications & implementations, workings, and potential impacts across different sectors. It also discusses its future, threats, and integration into new policy. Through extensive research on more than 200 research and many other sources, the authors have made every effort to present an accurate overview of the numerous applications of AI nowadays in industries such as agriculture, education, autonomous systems, healthcare, finance, entertainment, transportation, military, manufacturing, and more. The paper explores various AI technologies, including machine learning, deep learning, robotics, big data, the Internet of Things, natural language processing, image processing, object detection, virtual reality, augmented reality, speech recognition, and computer vision. It provides real-world examples of their applications and implementations. Moreover, it highlights and evaluates the future potential, challenges, and limitations associated with the widespread use of AI. Our study incorporates the latest research to offer a comprehensive and nuanced understanding of AI's potential benefits and challenges. This data-driven review case study highlights the immense potential of AI technology and addresses the ethical, societal, and economic considerations related to its implementation."
10.1016/j.watres.2024.122086,reinforcement,"However, a real-time control for optimal MCDI operation has not been investigated yet. In this study, we aimed to develop a reinforcement learning (RL)-based control model and investigate the model to find an energy-efficient MCDI operation strategy. To fulfill the objectives, we established three long-short term memory models to predict applied voltage, outflow pH, and outflow electrical conductivity. Also, four RL agents were trained to minimize outflow concentration and energy consumption simultaneously. Consequently, actor-critic (A2C) and proximal policy optimization (PPO2) achieved the ion separation goal (<0.8 mS/cm) as they determined the electrical current and pump speed to be low. Particularly, A2C kept the parameters consistent in charging MCDI, which caused lower energy consumption (0.0128 kWh/m3) than PPO2 (0.0363 kWh/m3). To understand the decision-making process of A2C, the Shapley additive explanation based on the decision tree model estimated the influence of input parameters on the control parameters. The results of this study demonstrate the feasibility of RL-based controls in MCDI operations. Thus, we expect that the RL-based control model can improve further and enhance the efficiency of water treatment technologies."
10.1016/j.engappai.2024.109851,reinforcement,"However, the existing literature on this topic is comparatively insufficient. This study investigated the considered problem with total flowtime (TF) criterion by developing three evolutionary algorithms (EAs) and their reinforcement learning (RL) based variants. First, two heuristic rules are proposed to initialize population with diversity. Second, six elaborated local search operators are incorporate with the basic EAs considering the problem's characteristics. Then, the RL algorithms e.g., Q-Learning and Sarsa, are employed to select high-quality local search operators during algorithms' iterations to improve their performance. Three problem characteristic based RL strategies are designed for mapping the RL algorithms and local search operators. Finally, detailed calibration according to 81 large-scale instances is performed to illustrate the effectiveness of the proposed algorithms for solving the DAPFSP."
10.1016/j.ijpe.2022.108640,reinforcement,"V.This study evaluates the effect of carbon emission control policies on organizations' production planning and inventory management. Considering the variation of demands, breakdowns, and environmental uncertainties, we consider environmental Hedging Point Policy to control production level in relation to the costs of inventory, backlog, and emission. The effect of Cap-and-Trade, and Command-and-Control environmental policies on product lines’ strategies are evaluated. We aim to develop a production plan through optimization-based simulation and provide a solution for variable demand. Therefore, a simulation-based optimization on multi-objective particle swarm algorithm has been applied (RMSE = 0.82). To acquire practical and managerial implications, through machine learning, the environmental Hedging Point Policy parameters for variable demands are obtained. The results reveal that the Cap-and-Trade policy is more flexible and effective than the Command-and-Control in terms of reducing costs and using environmentally friendly technologies. Our approach offers an effective solution to help decision makers to dynamically plan operations for variable demands, utilize resources, and manage inventories, and increase productivity."
10.1109/WF-IoT48130.2020.9221098,reinforcement,"Failure of mission-critical equipment interrupts production and results in monetary loss. The risk of unplanned equipment downtime can be minimized through Predictive Maintenance of revenue generating assets to ensure optimal performance and safe operation of equipment. However, the increased sensorization of the equipment generates a data deluge, and existing machine-learning based predictive model alone becomes inadequate for timely equipment condition predictions. In this paper, a model-free Deep Reinforcement Learning algorithm is proposed for predictive equipment maintenance from an equipment-based sensor network context. Within each equipment, a sensor device aggregates raw sensor data, and the equipment health status is analyzed for anomalous events. Unlike traditional black-box regression models, the proposed algorithm self-learns an optimal maintenance policy and provides actionable recommendation for each equipment. Our experimental results demonstrate the potential for broader range of equipment maintenance applications as an automatic learning framework."
10.1115/MSEC2016-8559,reinforcement,"Copyright © 2016 by ASME.Over the past few decades, both small- and medium-sized manufacturers as well as large original equipment manufacturers (OEMs) have been faced with an increasing need for low cost and scalable intelligent manufacturing machines. Capabilities are needed for collecting and processing large volumes of real-time data generated from manufacturing machines and processes as well as for diagnosing the root cause of identified defects, predicting their progression, and forecasting maintenance actions proactively to minimize unexpected machine down times. Although cloud computing enables ubiquitous and instant remote access to scalable information and communication technology (ICT) infrastructures and high volume data storage, it has limitations in latency-sensitive applications such as high performance computing and real-time stream analytics. The emergence of fog computing, Internet of Things (IoT), and cyber-physical systems (CPS) represent radical changes in the way sensing systems, along with ICT infrastructures, collect and analyze large volumes of real-time data streams in geographically distributed environments. Ultimately, such technological approaches enable machines to function as an agent that is capable of intelligent behaviors such as automatic fault and failure detection, self-diagnosis, and preventative maintenance scheduling. The objective of this research is to introduce a fogenabled architecture that consists of smart sensor networks, communication protocols, parallel machine learning software, and private and public clouds. The fog-enabled architecture will have the potential to enable large-scale, geographically distributed online machine and process monitoring, diagnosis, and prognosis that require low latency and high bandwidth in the context of data-driven cyber-manufacturing systems."
10.1145/3603148,reinforcement,"Publication rights licensed to ACM.Peer-to-peer (P2P) energy trading is a decentralized energy market where local energy prosumers act as peers, trading energy among each other. Existing works in this area largely overlook the importance of user behavioral modeling and assume users' sustained active participation and full compliance in the decision-making process. To overcome these unrealistic assumptions, and their deleterious consequences, in this article, we propose an automated P2P energy-trading framework that specifically considers the users' perception by exploiting prospect theory. We formalize an optimization problem that maximizes the buyers' perceived utility while matching energy production and demand. We prove that the problem is NP-hard and we propose a Differential Evolution-based Algorithm for Trading Energy (DEbATE) heuristic. Additionally, we propose two automated pricing solutions to improve the sellers' profit based on reinforcement learning. The first solution, named Pricing mechanism with Q-learning and Risk-sensitivity (PQR), is based on Q-learning. Additionally, given the scalability issues of PQR, we propose a Deep Q-Network-based algorithm called ProDQN that exploits deep learning and a novel loss function rooted in prospect theory. Results based on real traces of energy consumption and production, as well as realistic prospect theory functions, show that our approaches achieve 26% higher perceived value for buyers and generate 7% more reward for sellers, compared to recent state-of-the-art approaches."
10.1109/ICAACCA51523.2021.9465259,reinforcement,"In the different situations present in the industry, combinatorial problems are increasingly frequent. This paper presents the interaction of Metaheuristics and Machine Learning, specifically as Machine Learning can be a support to enhance Metaheuristics. The resolution of the Set Covering Problem is presented, using the Grey Wolf Optimizer and Sine Cosine Algorithm metaheuristics that have been improved by adding a Q-Learning technique for the selection of a Discretization Scheme, using two-steps, intelligently choosing which transfer function to use and which binarization technique to apply in each iteration. The results show a better result for the Grey Wolf Optimizer with Q-Learning configuration, compared to other configurations in the literature, obtaining a better balance between exploration and exploitation."
10.1007/s42979-025-03695-x,reinforcement,"2025.Predictive Maintenance (PdM) aims to ensure the continuous operation of high-risk industrial systems. This challenge is especially critical in environments where equipment failure can cause major financial losses and disrupt operations. Traditional PdM approaches, while fairly effective, often fall short in accurately predicting failures due to their reliance on simple statistical methods and predefined rules. The proposed work introduces an Intelligent IoT-Driven Advanced Predictive Maintenance System (APdM) that addresses these limitations. By integrating advanced machine learning techniques, including supervised and reinforcement learning, with IoT technologies to enhance predictive accuracy as well as the operational efficiency. The system leverages Explainable AI (XAI) to ensure transparency in decision-making and employs federated learning for distributed model training, preserving data privacy across multiple edge devices. The proposed APdM system was evaluated using the Kaggle ""Air Compressor Predictive Maintenance"" Dataset, which provided extensive sensor data from heavy vehicle operations. Comparative analysis against four prevailing PdM approaches—Traditional PdM, Decision Support System-PdM, Genetic Algorithm-based PdM, and AI-based PdM—demonstrated the superior performance of our system. The results show that the APdM system, powered by intelligent IoT integration, diminishes the Mean Error Percentage (MEP) by up to 38.4% compared to traditional methods and decreases the Mean Absolute Error (MAE) by 36.7% relative to DSS-PdM. Additionally, the system achieves a 78% improvement in Symmetric Mean Absolute Percentage Error (SMAPE) over GA-PdM, underscoring its robust performance in real-world industrial scenarios. These outcomes validate the effectiveness of the proposed APdM system, marking a significant improvement in the field of predictive maintenance through the intelligent integration of IoT technologies."
10.1016/j.atech.2025.101307,reinforcement,"This systematic literature review investigates how integrating AI/ML with sensor-based IoT technologies can address key challenges in poultry production, including disease outbreaks, welfare monitoring, and environmental management. The findings reveal that Convolutional Neural Networks (CNN), especially YOLOv8, offer superior performance in visual-based poultry health detection, achieving over 90 % accuracy for conditions like bumblefoot and woody breast. IoT-enabled sensors continuously track temperature, humidity, and flock activity, allowing automated systems to adjust ventilation, lighting, and feed distribution. Edge-AI solutions further reduce latency and dependence on cloud computing, making on-site monitoring feasible in low-connectivity environments. This review introduces a structured taxonomy of AI/ML applications grouped into five domains: disease detection, behaviour analysis, environmental control, automation, and productivity optimization. A comparative table of state-of-the-art techniques and their respective performance metrics is provided to highlight the strengths and limitations of each approach. Challenges such as limited infrastructure, high initial costs, and digital illiteracy among smallholders hinder broader adoption. Research gaps are identified in dataset generalizability, multi-modal sensor fusion, and the lack of scalable real-world trials. Future directions include developing lightweight, energy-efficient models, enhancing user-friendly interfaces, and promoting policy frameworks that support ethical and inclusive AI adoption. By critically evaluating current methodologies and outlining actionable strategies, this review contributes to advancing sustainable, efficient, and welfare-oriented poultry farming systems through smart technologies."
10.1016/j.measurement.2020.108665,unknown,"On the other hand, the complexity associated with the two-phase flow system makes the computational determination of bottom-hole pressure difficult and time-consuming, so in the current work, two novel machine learning approaches based on Gradient tree boosting (GTB) and Extreme Learning Machine (ELM) have been proposed. The comparison of 458 actual pressure values and proposed GTB and ELM outputs has clarified that machine learning approaches have excellent performance in oil field calculations with R-squared values of 1 and 0.999 and also mean relative errors lower than 4% for these models. Additionally, sensitivity analysis on the input variables shows that the most effective parameter in the determination of bottom-hole pressure is well-head pressure."
10.19636/j.cnki.cjsm42-1250/o3.2020.001,unknown,"All right reserved.The concept of big data with digital twin and artificial intelligence is profoundly influencing the fourth industrial revolution. At the same time, facing severe challenges in advanced manufacturing and safety assessment of high-performance materials and structures, classical computational mechanics has more and more limitations in achieving the goal of 'half-time and half-cost' of R&D cycle. Data-driven computational mechanics emerged in this context and showed great vitality. This paper aims to discuss and analyze the trend of data-driven computational mechanics by reviewing recent research achievements. In this paper, the algorithms in the framework of data-driven computational mechanics are summarized into two categories: the first one is based on energy functional, the key point of which is to construct the constitutive relationship by using material data; while the second category is based on distance functional, the specificity of which lies in directly embedding the material data into mechanical simulations. Several related data-driven algorithms of each category are briefly recalled, and the challenges and prospects of data-driven computational mechanics are discussed."
10.1212/WNL.0000000000009778,unknown,"Objective To incorporate standardized documentation into an epilepsy clinic and to use these standardized data to compare patients' perception of epilepsy diagnosis to provider documentation.MethodsUsing quality improvement methodology, we implemented interventions to increase documentation of epilepsy diagnosis, seizure frequency, and type from 49.8% to 70% of adult nonemployee patients seen by 6 providers over 5 months of routine clinical care. The main intervention consisted of an interactive SmartPhrase that mirrored a documentation template developed by the Epilepsy Learning Healthcare System. We assessed the weekly proportion of complete SmartPhrases among eligible patient encounters with a statistical process control chart. We used a subset of patients with established epilepsy care linked to existing patient-reported survey data to examine the proportion of patient-to-provider agreement on epilepsy diagnosis (yes vs no/unsure). We also examined sociodemographic and clinical characteristics of patients who disagreed vs agreed with provider's documentation of epilepsy diagnosis.ResultsThe median SmartPhrase weekly completion rate was 78%. Established patients disagreed with providers with respect to epilepsy diagnosis in 18.5% of encounters ( = 0.13), indicating that they did not have or were unsure if they had epilepsy despite having a provider-documented epilepsy diagnosis. Patients who disagreed with providers were similar to those who agreed with respect to age, sex, ethnicity, marital status, seizure frequency, type, and other quality-of-life measures.ConclusionThis project supports the feasibility of implementing standardized documentation of data relevant to epilepsy care in a tertiary epilepsy clinic and highlights an opportunity for improvement in patient-provider communication."
10.4018/978-1-7998-6985-6.ch012,unknown,"In this chapter, a comprehensive description of a generic framework aimed at solving various predictive data-driven related use cases, occurring in the manufacturing industry, is provided. The framework is rooted in a general mathematical model so called queue directed graph (QDG). With the aid of QDGs and containerized microservices implementations, the typology of the system is analyzed, and real use cases are explained. The goal is for this framework to be able to be used with all use cases which fit in this typology. As an example, a data generation distribution model is proposed, the parameter stability and predictive robustness are studied, and automated machine learning approaches are discussed to predict the throughput time of products in a manufacturing production line just by knowing the processing time in their first stations."
10.3390/bdcc9080203,unknown,"Backfilling materials are commonly employed materials in mines for filling mining waste, and the strength of the consolidated backfill formed by the binding material directly influences the stability of the surrounding rock and production safety in mines. The traditional approach to obtaining the strength of the backfill demands a considerable amount of manpower and time. The rapid and precise acquisition and optimization of backfill strength parameters hold utmost significance for mining safety. In this research, the authors carried out a backfill strength experiment with five experimental parameters, namely concentration, cement–sand ratio, waste rock–tailing ratio, curing time, and curing temperature, using an orthogonal design. They collected 174 sets of backfill strength parameters and employed six population optimization algorithms, including the Artificial Ecosystem-based Optimization (AEO) algorithm, Aquila Optimization (AO) algorithm, Germinal Center Optimization (GCO), Sand Cat Swarm Optimization (SCSO), Sparrow Search Algorithm (SSA), and Walrus Optimization Algorithm (WaOA), in combination with the CatBoost algorithm to conduct a prediction study of backfill strength. The study also utilized the Shapley Additive explanatory (SHAP) method to analyze the influence of different parameters on the prediction of backfill strength. The results demonstrate that when the population size was 60, the AEO-CatBoost algorithm model exhibited a favorable fitting effect (R2 = 0.947, VAF = 93.614), and the prediction error was minimal (RMSE = 0.606, MAE = 0.465), enabling the accurate and rapid prediction of the strength parameters of the backfill under different ratios and curing conditions. Additionally, an increase in curing temperature and curing time enhanced the strength of the backfill, and the influence of the waste rock–tailing ratio on the strength of the backfill was negative at a curing temperature of 50 °C, which is attributed to the change in the pore structure at the microscopic level leading to macroscopic mechanical alterations. When the curing conditions are adequate and the parameter ratios are reasonable, the smaller the porosity rate in the backfill, the greater the backfill strength will be. This study offers a reliable and accurate method for the rapid acquisition of backfill strength and provides new technical support for the development of filling mining technology."
10.1115/IMECE2023-113101,unknown,"Copyright © 2023 by ASME.Industry 4.0 is the ongoing evolution of manufacturing, characterized by implementing new technologies and methods to increase adaptability and efficiency. To realize the potential of Industry 4.0, integrating technological concepts is essential. This research combines process simulation, automation, and existing manufacturing infrastructure to develop a digital twin (DT) and implement it to drive visibility and innovation. This research seeks to optimize a live production system by developing a simulation to model a pick-and-place operation, creating a DT to reflect the real-world system environment. The simulation will allow for modifications to the process or system to better understand the impacts of changes to the operation. The provided definition of a DT outlines a clear set of criteria that must be met for a virtual model to be considered a DT. According to this definition, the creation of a virtual, kinematic replica of a physical model is essential. Connecting this kinematic model to the physical model results in the automation of the kinematic model and the creation of a DT. The discussion also identifies potential opportunities for improving the performance of a physical robot cell through the use of statistical analysis and machine learning algorithms."
10.1007/978-3-319-25010-6_13,unknown,"Modern industrial automation systems incorporate a variety of interconnected sensors and actuators that contribute to the generation of vast amounts of data. Although valuable insights for plant operators and engineers can be gained from such data sets, they often remain undiscovered due to the problem of applying machine learning algorithms in high-dimensional feature spaces. Feature selection is concerned with obtaining subsets of the original data, e.g. by eliminating highly correlated features, in order to speed up processing time and increase model performance with less inclination to over-fitting. In terms of high-dimensional data produced by automation systems, lots of dependencies between sensor measurements are already known to domain experts. By providing access to semantic data models for industrial data acquisition systems, we enable the explicit incorporation of such domain knowledge. In contrast to conventional techniques, this semantic feature selection approach can be carried out without looking at the actual data and facilitates an intuitive understanding of the learned models. In this paper we introduce two semantic-guided feature selection approaches for different data scenarios in industrial automation systems. We evaluate both approaches in a manufacturing use case and show competitive or even superior performance compared to conventional techniques."
10.1109/SMART52563.2021.9676222,unknown,"The technological evolution in the last decades has led us to the forefront of the digitization of services at every stratum of the processes and businesses. As the technology is advancing, an era of automation is witnessed in each field. Intelligent Process Automation (IPA) is amalgamation of Robotic Process Automation (RPA) with Artificial Intelligence with a view to create end-to-end processes which can think, learn, and adapt on their own. This paper aims to present a comprehensive study of the RPA tools associated to the intelligent automation using Artificial Intelligence. It also provides a brief overview of the current development in IPA market which can contribute to the implementation of the IPA in various organizations."
10.1016/j.psep.2024.04.116,unknown,"The system is driven by a biomass digester integrated with the supercritical carbon dioxide cycle for power generation and a multi-effect desalination unit for drinkable water production. At the heart of this concept is additional hydrogen injection through a proton exchange membrane electrolyzer based on photovoltaic panels. The suggested innovative model's techno-environmental, sustainability, and economic aspects are assessed and compared with a similar system without hydrogen injection. Then, a comparative multi-criteria optimization is applied to find the most optimal conditions from various facets based on the genetic algorithm with machine learning techniques. Afterward, the system's performance at different optimal conditions is analyzed and compared by evaluating the most significant techno-economic, environmental, and sustainability indicators. The parametric assessment comparing different models indicates that the proposed novel model, including increased hydrogen injection, surpasses the basic system in terms of performance efficiencies, emissions, and energy costs. In the first optimization scenario, the proposed method demonstrates robustness by achieving higher water production of 1456 kg/s, a lower total cost of 118 $/h, and a higher net power of 1.1 MW than the design condition. When considering the sustainability index, energy cost, and emission metric as the optimization objective, their values are altered from 0.81 to 0.85, 92.5 $/MWh to 89.7 $/MWh, and 64.2 kg/MWh to 53.6 kg/MWh. The results further show that when prioritizing the sustainability index, energy cost, and emission as objectives, all components perform better from the energy conversion quality aspect compared to the scenario where water production, total cost, and net power are the optimization objectives. Finally, it is observed that the combustion chamber and solar panels are the worst components from the irreversibility aspect because of the highest exergy destruction rate."
10.1007/s00158-020-02748-4,unknown,"Neural networks, and more broadly, machine learning techniques, have been recently exploited to accelerate topology optimization through data-driven training and image processing. In this paper, we demonstrate that one can directly execute topology optimization (TO) using neural networks (NN). The primary concept is to use the NN’s activation functions to represent the popular Solid Isotropic Material with Penalization (SIMP) density field. In other words, the density function is parameterized by the weights and bias associated with the NN, and spanned by NN’s activation functions; the density representation is thus independent of the finite element mesh. Then, by relying on the NN’s built-in backpropogation, and a conventional finite element solver, the density field is optimized. Methods to impose design and manufacturing constraints within the proposed framework are described and illustrated. A byproduct of representing the density field via activation functions is that it leads to a crisp and differentiable boundary. The proposed framework is simple to implement and is illustrated through 2D and 3D examples. Some of the unresolved challenges with the proposed framework are also summarized."
10.1016/j.bprint.2025.e00437,unknown,"V.Cloud computing technologies and Internet of Things systems and artificial intelligence (AI) have brought major changes to pharmaceutical 3D printing by promoting new opportunities in designing drugs and manufacturing and personalized medicine delivery. Algorithmic processing through AI improves the modeling of drugs for computation and predicts formulation stability and detects real-time defects in printed dosage forms while boosting operational efficiency. Machine learning systems help optimize printing settings to achieve consistent results and reduce material waste across production batches. The use of artificial intelligence in pharmaceutical 3D printing needs overcoming three major challenges: regulatory hurdles, standards, and data privacy concerns. To overcome these problems, regulatory authorities, pharmaceutical researchers, and technology companies must collaborate to set standards for pharmaceutical data protection as well as compliance frameworks. AI-powered software solutions employ predictive analytics to do quality control in real time, reducing the amount of manufacturing failures. This article discusses regulatory obstacles, data security issues, and standards. Furthermore, identify research gaps so that academics can continue to work on AI-based 3D printing models. The application of AI enables pharmaceutical companies to boost operational efficiency and precision capabilities as well as innovative developments that lead to advanced drug therapies adjusted for individual patients alongside contemporary production methods."
10.1109/ACCESS.2025.3534918,unknown,"The meat food manufacturing industries play a crucial role in delivering various meat products to global consumers. However, one of the significant challenges within this industry is optimizing food processing efficiency across various stages, as it directly affects both product quality and production costs. Drying is one of the crucial stages, wherein moisture is extracted from the meat to reach the desired moisture levels. This prevents spoilage and influences product quality, safety, and overall production efficiency. The drying time is variable, contingent on factors such as the type of meat, quantity, environmental factors, and the desired product characteristics. This variability contributes to the complexity and multifaceted nature of the issue. Conventional approaches for estimating drying times often depend on empirical rules or manual observations, which can be time-consuming, subjective, and susceptible to human error. Therefore, implementing an automation solution by developing a predictive model for drying times in meat manufacturing is essential for optimizing the production lifecycle. Recognizing the potential of advanced computational techniques, machine learning algorithms have demonstrated promising results across various predictive tasks in recent years. Building on this, this research paper aims to explore the utilization of machine learning methods in predicting the drying time of meat-based food products incorporating multiple factors including structure and properties of food, environmental factors, food mass, and physical parameters of food containers. Furthermore, the paper explores correlations, performs feature importance analysis, and addresses the challenges and limitations within this context."
10.2352/EI.2022.34.15.COLOR-159,unknown,"A correlation between thin-film nitrate sensor performance and sensor surface texture was hypothesized. Based on this hypothesis, we began research on the application of machine learning methods on thin-film nitrate sensor surface images to predict its performance. This technology would enable real-time optimization adjustments to be made during production to greatly increase the quality of the sensors while reducing costs associated with testing and defective sensors. Recently, we have made progress in the addition of new texture features, repeated cross-validation methods, and auto-tuning of hyperparameters."
10.36961/si33025,unknown,"Albert Bartens KG. All rights reserved.Sugar manufacturers are embracing digital trans-formation. Many have started this journey by increasing the data collected at sugar factories during sugar production. However, data do not generate value independently, and sugar manufacturers seek to apply AI to the data to improve operational decisions. This AI-based approach improves the mill’s ability to optimize operations against changing conditions and individual operator performance. It enables near real-time process optimization by bringing together disparate data sources and applying advanced optimization algorithms. With AI-enhanced deci-sion-making, each operator performs like an expert operator and helps maximize mill profitability with higher cane throughput, improved yields, and lower energy costs. In this paper we consider the optimization challenges in a sugar mill and how AI can address those challenges."
10.1016/j.petrol.2022.110352,unknown,"EUR is the utmost recoverable oil and gas volume under the current assumption of technology and economics. Many factors including geology, drilling, completion, operation, and commodity prices influence EUR, which makes the prediction a difficult task. Reservoir numerical simulation and production decline curve analysis (DCA) are two broadly accepted method to calculate EUR. However, the former requires substantial data and resources, while the latter is lack of causative mechanism to associate the fundamentals to productivity. This study proposes a machine learning (ML) procedure in EUR modeling, by which EUR is linked to fundamental variables from available data and the variation in EUR can be explained by various factors so that the results can be applied to optimize future projects. In the proposed procedure, the EUR was estimated using a probabilistic dual flow regime model and Markov Chain Monte Carlo (MCMC) simulation. The resulting EUR in each well was then modeled using a two-level stacked ensemble ML approach, while Shapley value was used to explain feature sensitivity in the trained model. In the last, the EUR is optimized by adjusting the most sensitive factors in the trained model. The trained ML model achieved high accuracy on EUR prediction, and the Shapley value analysis showed that completion length, condensate gas ratio and fracturing fluid volume are among the most important features to EUR. The EUR optimization result showed that there is large room for improvement by adjusting the key features. This proposed approach provides a new perspective to find associations between the fundamental factors and the well EUR which improves the understanding of oil and gas production in unconventional reservoirs."
10.12133/j.smartag.SA202211004,unknown,"All rights reserved.Agriculture is a basic industry deeply related to the national economy and people's livelihood, while it is also a weak industry. There are some problems with traditional agricultural risk management research methods, such as insufficient mining of nonlinear information, low accuracy and poor robustness. Artificial intelligence(AI) has powerful functions such as strong nonlinear fitting, end-to-end modeling, feature self-learning based on big data, which can solve the above problems well. The research progress of artificial intelligence technology in agricultural vulnerability assessment, agricultural risk prediction and agricultural damage assessment were first analyzed in this paper, and the following conclusions were obtained: 1. The feature importance assessment of AI in agricultural vulnerability assessment lacks scientific and effective verification indicators, and the application method makes it impossible to compare the advantages and disadvantages of multiple AI models. Therefore, it is suggested to use subjective and objective methods for evaluation; 2. In risk prediction, it is found that with the increase of prediction time, the prediction ability of machine learning model tends to decline. Overfitting is a common problem in risk prediction, and there are few researches on the mining of spatial information of graph data; 3. Complex agricultural production environment and varied application scenarios are important factors affecting the accuracy of damage assessment. Improving the feature extraction ability and robustness of deep learning models is a key and difficult issue to be overcome in future technological development. Then, in view of the performance improvement problem and small sample problem existing in the application process of AI technology, corresponding solutions were put forward. For the performance improvement problem, according to the user's familiarity with artificial intelligence, a variety of model comparison method, model group method and neural network structure optimization method can be used respectively to improve the performance of the model; For the problem of small samples, data augmentation, GAN (Generative Adversarial Network) and transfer learning can often be combined to increase the amount of input data of the model, enhance the robustness of the model, accelerate the training speed of the model and improve the accuracy of model recognition. Finally, the applications of AI in agricultural risk management were prospected: In the future, AI algorithm could be considered in the construction of agricultural vulnerability curve; In view of the relationship between upstream and downstream of agricultural industry chain and agriculture-related industries, the graph neural network can be used more in the future to further study the agricultural price risk prediction; In the modeling process of future damage assessment, more professional knowledge related to the assessment target can be introduced to enhance the feature learning of the target, and expanding the small sample data is also the key subject of future research."
10.1016/B978-0-443-15274-0.50222-5,unknown,"V.Naphtha cracking is the primary process for propylene (PL) and ethylene (EL) production and depends on the operating conditions, such as the coil outlet temperature and feedstock composition. The product yields, in turn, determine the profit of the naphtha cracking plant. Therefore, the operating conditions should be optimized to maximize plant profit. However, it is challenging to optimize the conditions using conventional simulation methods since a high-fidelity model is hard to develop owing to the nonlinearity and complexity of the cracking process. In this study, we used machine learning to optimize the operating conditions of a naphtha cracking furnace to maximize plant profit. First, a data-driven model was developed to predict the product yields for different operating conditions using a deep neural network (DNN). The model could predict the PL and EL yields with high accuracy (R2 = 0.965 and 0.900, respectively). Next, a genetic algorithm was used for optimization based on the developed DNN model. Finally, the developed model was used with real-world plant data and product prices for 2020. The plant profit under the optimized operating conditions was 30% higher than that corresponding to the original operating conditions. Thus, the proposed method is suitable for determining the optimal operating conditions of various types of plants in order to maximize profit."
10.1016/j.cirpj.2018.12.002,unknown,"The analysis performed by these tools will help operators and engineers to understand the behaviour of the manufacturing stations better and thereby take data-driven decisions to improve them. The tools use techniques borrowed from fields such as Data Analytics, BigData, Predictive Modelling, and Machine Learning. However, to be able to use these tools efficiently, data from the factory floor is required as input. This data needs to be extracted from two sources, the PLCs, and the robots. In practice, methods to extract usable data from robots are rather scarce. The present work describes an approach to capture data from robots, which can be applied to both legacy and current state-of-the-art manufacturing systems. The described approach is developed using Sequence Planner – a tool for modelling and analyzing production systems – and is currently implemented at an automotive company as a pilot project to visualize and examine the ongoing process. By exploiting the robot code structure, robot actions are converted to event streams that are abstracted into operations. We then demonstrate the applicability of the resulting operations, by visualizing the ongoing process in real-time as Gantt charts, that support the operators performing maintenance. And, the data is also analyzed off-line using process mining techniques to create a general model that describes the underlying behaviour existing in the manufacturing station. Such models are used to derive insights about relationships between different operations, and also between resources."
10.1145/3328243.3328268,unknown,"Ethical concerns with algorithms, machine learning (ML) and artificial intelligence techniques have become a part of design and research work when building interactive systems. This article proposes that designers working with algorithms can benefit from adopting ideas and practices from current discussion on human-centred or ethical design. The suggested ideas and practices build on existing work in human-computer interaction, contemporary publications by companies and research institutions and practitioner recommendations. They point to ways in which practitioners can build awareness on the complex ethical questions around ML and AI; set ethical goals along with business performance goals for their products; and make ethical design techniques part of their everyday design practice."
10.1109/AP-S/USNC-URSI47032.2022.9886315,unknown,"Ideally, metasurface designers want to create a metasurface that satisfies given application-specific criteria, which can take the form of far-field criteria such as beamwidth, side lobe level, manufacturing constraints, etc. Designing the metasurface from this set of broad criteria is very challenging without the complete knowledge of the tangential fields. Moreover, determining the required unit cells to realize the required scattering often requires numerous iterative simulations. Here, the inverse design of a metasurface that splits the input wave from a horn antenna into two asymmetric beams is tackled using a combined end-to-end approach involving optimization and machine-learning. Experimental results of a prototype of the optimized metasurface are presented that corroborate the effectiveness of the inverse design approach."
10.1016/j.coche.2025.101153,unknown,"It corresponds to a multiscale problem, from the molecule to the process that uses it to produce power, recovers it as a valuable product or from the molecules that represent the ingredients to the supply chain toward the sustainable production of consumer goods. The problem requires a systematic approach to reduce the time to market. Mathematical optimization and advanced machine learning are powerful techniques for a robust problem formulation. However, problem size and complexity call for novel procedures and algorithms are required."
10.1177/09544089231223061,unknown,"Errors in additive manufacturing are a significant obstacle to its widespread adoption in various application. The developments of 3D printed parts are prone to various types of defects, which are difficult to monitor in real-time through human vision. The use of 3D printers has increased in diverse fields, leading to a significant rise in the need of continuous monitoring during the manufacturing process. Prompt action should be taken to stop or correct errors immediately to prevent a defective part. However, continuous monitoring of 3D printer through human vision is impractical for longer tasks and cannot be accurate. Human inspection is not infallible and could introduce its own errors. Given the multitude of application, continuous defect monitoring is extremely challenging, particularly for longer tasks. Based on these constraints a suitable remote monitoring system through open-source computer vision has been proposed. Incorporating the concept of Internet of things, the video of printing process could be viewed by a user or controller from a remote location enabling to monitor the printing process. With the use of Haar classifier in the program, the printing defects that occur in the 3D printed part could be identified immediately through contours drawn over the defective part. Depending upon the severity of defect indicated, the user could take respective action to control the defect formation. With Industry 4.0 in the implementation stages, this method of video monitoring of defects in 3D printers could be an effective method for widespread use of additive manufacturing systems in industries."
10.1109/ICPCSN58827.2023.00274,unknown,"Pick and place robots are now extensively utilised in modern manufacturing facilities. The process of picking up the components or things and putting them in new locations is sped up by pick and place automation. The production rates of these processes can be raised by automating them. Decide and choose Robots handle monotonous tasks, freeing up human workers to focus on more challenging jobs. The food processing and packaging sector is expanding quickly. Manufacturers are utilising robotics to complete operations that would otherwise require dedicated physical labour to satisfy the increased demands and necessary efficiency. One of the most often used automation devices in the food packing environment is the pick and place robot. It is a disruptive brain ailment called Alzheimer's disease (AD). Since there is presently no treatment for it, early diagnosis is essential to both preventing and slowing the spread of the illness. In order to interpret AD utilising brain MRI scans and powerful deep learning models that can accurately find the areas of anomalies using medically validated bio-markers, this research conducts a comparison analysis.[16]. The process of analysing data, learning from that data, and using what has been learned to make decisions is known as machine learning. Indeed, machine learning is a subset of deep learning. Whilst it theoretically falls under the category of machine learning and operates similarly, it has various characteristics [17]. It can be a cylindrical robot that can move in all three planes of motion-horizontal, vertical, and rotational - or a spherical robot that can move in two planes of rotation and one plane of linear motion. It can also be an articulated robot or a scara robot (fixed robots with 3 vertical axes rotary arms). These robots have the ability to move objects from stationary surfaces to stationary surfaces, stationary surfaces to moving surfaces, moving surfaces to moving surfaces, and moving surfaces to moving surfaces."
10.1080/09064710.2021.2008482,unknown,"Published by Informa UK Limited, trading as Taylor & Francis Group.In recent years, greenhouse development has been innovative in agriculture based on information systems guidance with accelerated growth. The IoT provides an intelligent system and remote access technologies such as green infrastructure. The usability of information systems for effective training and producing intelligent systems and predictive models in organizational real-time based on machine learning and artificial intelligence (AI). Therefore, a Remote Sensing Assisted Control System (RSCS) has been proposed for improving greenhouse agriculture requirements. This proposed method utilizes artificial intelligence and machine learning technology for the green development potential industry's ability to manage economic resources and increase innovative agriculture product development patterns. Thus, the key preconditions for increasing healthy food choices and promoting local and global organic farmers' potential development are straightforward suggestions for developing an effective marketing strategy. The experimental results RSCS the highest precision ratio of 95.1%, the performance ratio of 96.35%, a data transmission rate of 92.3%, agriculture production ratio of 94.2%, irrigation control ratio of 94.7%, the lowest moisture content ratio of 18.7%, and CO2 emission ratio of 21.5%, compared to other methods."
10.1080/23311916.2022.2088463,unknown,"This open access article is distributed under a Creative Commons Attribution (CC-BY) 4.0 license.Sustainability issues are challenging the cement industry due to its high emission of greenhouse gas, intensive energy consumption, and depletion of resources. One of the strategies to mitigate the problem is to improve process control techniques and optimize resources. The objective of this paper is to survey the approach and evolution of statistical process control chart techniques and study their significance and limitations in the case of optimization of cement production. The main research question this study address is “What are the significances and limitations of statistical process control chart methods to the optimization of cement process?” The methodology of the study followed the literature survey with meta-analysis and focused on identifying the statistical process control chart design techniques and their application to cement industries. The result of the survey indicated that statistical and mathematical algorithms are encapsulated by advanced soft computing methods; however, still, it is the foundation for advanced process control methods. Moreover, it is found that statistical process control has a theoretical and technical gap in the application of the cement industry. The theoretical gap identified in the literature is that in the case of a complex production system the techniques recognize the occurrence of the out-of-control case in the production process but are not able to identify the cause of variation. The technical gap in the statistical process control techniques is that there are several important theoretical control chart techniques, but they are not researched well on how to apply to the real world."
10.1007/s41660-024-00405-7,unknown,"2024.Nowadays, fragrance molecules have become a focal point in formulated products, aimed at attracting customers. However, there have been notable clinical cases involving allergies caused by these fragrance molecules in various products. Thus, the purpose of this study is to design a fragrance molecule that not only offers a pleasant and long-lasting scent but is also safe for users. A computer-aided molecular design (CAMD) model is employed to achieve this. The desirable attributes of fragrance molecules are identified and then translate these attributes into their corresponding properties. Machine learning is applied to develop prediction models for odor properties, while property prediction models are used to identify for other target properties. A CAMD model is developed using LINGO which encompasses the constraints and rules generated. Fuzzy optimization involved to address the multi-objective scenario. Upon the implementation of CAMD approach, the molecules generated all met the technical requirements. The molecules generated undergo safety and health assessment to eliminate the hazard fragrance molecule. Among these molecules, 2-methoxyethyl acetate emerges as the optimal fragrance molecule. It exhibits a higher diffusion coefficient and poses minimum hazards, ensuring both a pleasing fragrance and user safety."
10.1109/TMTT.2022.3198659,unknown,"Advanced field-effect transistors (FETs), such as gate-all-around (GAA) nanowire (NW) and nanosheet (NS) devices, have been highly scaled; therefore, they are critically affected even by a microscopic fluctuation. As the GAA NS device is considered a promising candidate beyond 5-nm technology, it is essential to analyze the effects of these fluctuations on dc and analog/radio frequency (RF) characteristics for future applications. In this article, we for the first time demonstrate that the machine learning (ML)-aided numerical device simulation approach can be used to model the effects of various fluctuations on the characteristics of GAA NS FETs (NSFETs). Among various fluctuations, we mainly focus on work function fluctuation (WKF), random dopant fluctuation (RDF), and interface trap fluctuation (ITF). The independent and combined effects of these fluctuations on the characteristics of NSFETs are studied. Except for transfer and output characteristics, analog and RF parameters, such as gate capacitance, transconductance, cutoff frequency, 3-dB frequency, and transconductance efficiency, are analyzed in detail. The main aim of this work is to show the capability and generality of ML in modeling various electrical characteristics of the explored NSFETs. The results show that the ML-based technique is fast and efficient, which accelerates the overall process and gives engineering acceptable accurate results."
10.1186/s13638-019-1484-3,unknown,"The modern vehicles nowadays are managed by networked controllers. Most of the networks were designed with little concern about security which has recently motivated researchers to demonstrate various kinds of attacks against the system. In this paper, we discussed the vulnerabilities of the Controller Area Network (CAN) within in-vehicle communication protocol along with some potential attacks that could be exploited against it. Besides, we present some of the security solutions proposed in the current state of research in order to overcome the attacks. However, the main goal of this paper is to highlight a holistic approach known as intrusion detection system (IDS) which has been a significant tool in securing networks and information systems over the past decades. To the best of our knowledge, there is no recorded literature on a comprehensive overview of IDS implementation specifically in the CAN bus network system. Thus, we proposed an in-depth investigation of IDS found in the literature based on the following aspects: detection approaches, deployment strategies, attacking techniques, and finally technical challenges. In addition, we also categorized the anomaly-based IDS according to these methods, e.g., frequency-based, machine learning-based, statistical-based, and hybrid-based as part of our contributions. Correspondingly, this study will help to accelerate other researchers to pursue IDS research in the CAN bus system."
10.3390/wevj15100440,unknown,"The worldwide transition to electric vehicles (EVs) is gaining momentum, propelled by the imperative to reduce carbon emissions and foster sustainable transportation. In Malaysia, the government is facilitating this transformation through targeted initiatives aimed at promoting the use of electric vehicles (EVs) and developing the required infrastructure. This paper investigates the crucial role of artificial intelligence (AI) in developing intelligent electric vehicle (EV) charging infrastructure, specifically focusing on the context of Malaysia. The paper examines the current electric vehicle (EV) charging infrastructure in Malaysia, highlights advancements led by artificial intelligence (AI), and references both local and international case studies. Fluctuations in the Total Industry Volume (TIV) and Total Industry Production (TIP) reflect changes in market demand and production capabilities, with notable peaks in March 2023 and March 2024. The research reveals that AI technologies, such as machine learning and predictive analytics, can enhance charging efficiency, improve user experience, and support grid stability. A mathematical model for an AI-based smart charging system was developed, and the implemented system achieved 30% energy savings and a 20.38% reduction in costs compared to traditional methods. These findings underscore the system’s energy and cost efficiency. In addition, we outline the potential advantages and challenges associated with incorporating artificial intelligence (AI) into Malaysia’s electric vehicle (EV) charging infrastructure. Furthermore, we offer recommendations for researchers, industry stakeholders, and regulators. Malaysia can enhance the uptake of electric vehicles and make a positive impact on the environment by leveraging artificial intelligence (AI) to enhance its electric vehicle charging system (EVCS)."
10.5005/jp-journals-10024-3903,unknown,"AIM AND BACKGROUND: From their inception to the present, these aligners have evolved due to significant advancements in materials science and production technologies, which have improved patient outcomes and accessibility. When orthodontic aligners were first developed in the latter half of the 20th century, the majority of the methods used were labor-intensive manual processes using substandard materials. This review article offers comparative data between three-dimensional (3D) printing technologies and conventional methods, as well as insights into the developments in orthodontic aligner fabrication. MATERIALS AND METHODS: The review question was developed using the population intervention comparator outcome (PICO) criteria and preferred reporting items for systematic reviews and meta-analyses (PRISMA) guidelines. The following seven databases were searched: PubMed/MEDLINE, CINAHL, Embase, Cochrane, ProQuest, Google Scholar, and Web of Science. RESULTS: The review showed the characteristic outcomes of four studies on the treatment efficacy of 3D printing and three studies on different behaviors towards orthodontic treatment. The performance of orthodontic aligners depends on the characteristics of the materials used in their construction, and only a few materials have been evaluated. CONCLUSION: As technology developed, computer-aided design (CAD) and computer-aided manufacturing (CAM) techniques were introduced, making treatment planning more precise and predictable. CLINICAL SIGNIFICANCE: This shift not only reflects advancements in digital dentistry but also underscores a broader trend in precision medicine, where patient care is increasingly individually personalized. How to cite this article: Alhazmi AS. Advancements in Orthodontic Aligner Fabrication: A Comparative Review of 3D Printing Technologies and Traditional Methods Evaluation. J Contemp Dent Pract 2025;26(6):632-637."
10.1016/j.matdes.2021.109632,unknown,"Additionally, with the recent proliferation of additive manufacturing tools across industrial sectors, the ability to readily fabricate geometrically complex metamaterials is now possible. However, in many high-performance applications involving complex multi-physics interactions, design of novel lattice metamaterials is still difficult. Design is primarily guided by human intuition or gradient optimization for simple problems. In this work, we show how machine learning guides discovery of new unit cells that are Pareto optimal for multiple competing objectives; specifically, maximizing elastic stiffness during static loading and minimizing wave speed through the metamaterial during an impact event. Additionally, we show that our artificial intelligence approach works with relatively few (3500) simulation calls."
10.1007/978-3-031-21147-8_19,unknown,"Circular economy (CE) business models provide solutions for sustainable development goals by closing, slowing, intensifying, de-materializing, and narrowing resource loops. Addressing CE needs a strategic redefinition of the way companies are creating and capturing value, which leads in designing a new value creation system and innovative business models. For a full circular value creation, circular products should be designed and developed specifically for repair, refurbishing, and remanufacturing purposes to close the loop. Hence, companies need to radically change their business models and the way they create value towards more innovative solutions based on CE strategies. However, implementation of circular business models in business practices has not been widely utilized and requires fundamental changes within the value chain. In a successful circular value creation, a higher degree of transparency and high-quality data for the entire value chain is required for further development of the products and processes, hence enabling design optimization and management of supply chain. Recent debates show that artificial intelligence (AI) can be considered as an enabler of CE to help companies in innovating circular business models. Different applications of AI such as machine learning, automation and robotics, and machine visions have the capability of collecting, analyzing, and storing digital data. AI-enhanced products and services can tackle environmental problems through independent interactions with their surroundings and self-learning capabilities, which results in improved environmental performance characteristics. In this chapter, we identify the role of AI in circular value creation for sustainable development goals."
10.1109/TII.2023.3272692,unknown,"Industrial robots contribute to a considerable amount of energy consumption in manufacturing. However, modeling the energy consumption of industrial robots is a complex problem as it requires considering components such as the robot controller, fans for cooling, the motor, the friction of the joints, and confidential parameters, and it is difficult to consider them all in modeling. Many authors investigated the effect of operating parameters on the energy consumption of industrial robots. However, there is no prescriptive methodology to determine those parameter values because of the challenges in the modeling of industrial robots. This article investigates an industrial robot and the manufacturing process together and proposes a black-box model-based energy consumption optimization approach. Our contribution to the research is the new online and data-efficient methodology, prescriptive algorithm, and the analysis of operating parameters' effects on industrial robots' energy consumption. The proposed methodology is tested using two real FANUC industrial robots in three industrial settings."
10.1109/CASE48305.2020.9217039,unknown,"Green manufacturing is attracting more and more attention due to the intensifying environmental and resource consumption problems brought by industrial development. How to make green planning and evaluation to design activities throughout the product life cycle by using knowledge effectively is the key to studies on green manufacturing. To better acquire and apply knowledge to implement green manufacturing, a smart knowledge application method based on design matrix was proposed. The single mapping among design requirements, functional characteristics and knowledge characteristics was transformed into a two-dimensional matrix mapping by the design matrix. The mapping relationship between the design process and the required knowledge was established based on machine learning, and the knowledge required at each stage of the product life cycle was related to the design activities to assist the enterprise in implementing the green manufacturing mode. On this basis, a preliminary knowledge application prototype system was developed, and the recycling of waste circuit boards was used to illustrate the feasibility of the proposed method."
10.1109/IRASET57153.2023.10152915,unknown,"Today's global economy is experiencing a sharper slowdown than ever before. With a higher risk of deterioration or disappearance of manufacturing companies than usual. As a result, manufacturers must face this situation by adopting strong strategies, including equipment management and cost optimization in connection. This is why predictive maintenance is an important pillar in achieving these objectives. Except that predictive maintenance requires a budget and time for the proper implementation, such investment can only be accepted by investors if it is sure that the expected results will contribute effectively to the reduction of maintenance costs. To do this, it is necessary to assess the risks that could impact this project's success, mainly the data reliability and the machine learning model performance. The aptitude to predict the need for maintenance of a system in a perfect way at a specific time is one of the main challenges in this scope. This paper proposes a methodology for data management in the case of predictive maintenance project implementation. It starts by introducing the project study phase for cost & benefit evaluation based on data-driven. Then it presents the predictive concept based on data mining & machine learning tools for optimal model building, as well for the project performance follow up a monitoring approach is proposed based on the continuous improvement concept."
10.1016/j.jpowsour.2024.235130,unknown,"V.Understanding the internal stress and deformation in lithium-ion batteries (LIBs) is critical for battery design and management, especially for 46XX silicon-graphite batteries with significant swelling. X-ray computer tomography (CT) is an effective non-contact measurement for internal stress based on electrode thickness variation. However, X-rays severely attenuate, resulting in limited measurement resolution and accuracy in large-size 46XX LIBs. Meanwhile, it is difficult to establish the complex internal stress distribution within the spirally wound jelly rolls. In this study, we propose a machine learning-based approach to map the deformation of positive and negative electrodes in a 4695 LIB using CT images. We have identified two structural details. The first is a uniform protrude in the 100° direction of all electrode windings, deviating from the ideal Archimedean spiral. Secondly, both positive and negative electrode ends cause slight deformation of surrounding electrodes, leading to an increase of local stress. The deformation mapping of the jelly roll reflects the simultaneous radial expansion and lateral translation in the 100° direction after charging. The mapping of electrode stack thickness has unveiled the radial distribution of stresses along the stacking direction and the maximum stress located in the 4th region or the 16th∼20th turn. These findings offer crucial insights for optimizing the spiral structure in the manufacturing process of LIBs. In addition, this method can be extended to analyze the complex deformation of LIBs with various configurations and may hold potential for in-situ monitoring based on fast and low-resolution CT imaging."
10.24867/IJIEM-2024-3-361,unknown,"All rights reserved.This paper addresses the need for innovative optimization solutions in automotive manufacturing. Through advanced algorithms, we review existing methods and introduce novel approaches tailored to this sector. Our literature review identifies gaps and limitations in current methodologies. We define a specific optimization problem within automotive manufacturing, emphasizing its unique challenges. Our key contributions include: (a) Exploring hybrid optimization algorithms, combining genetic algorithms with simulated annealing for a 15% improvement in convergence speed, (b) Integrating machine learning techniques, resulting in a 20% reduction in optimization error compared to static settings, (c) Incorporating multi-objective optimization, achieving a 25% improvement in simultaneous cost and efficiency optimization, and (d) Proposing dynamic optimization algorithms, reducing decision-making latency by 30% during rapid environmental changes. Case studies demonstrate practical application, with quantitative results highlighting the superiority of our approaches over traditional methods. Additionally, the data analysis was conducted using Python, contributing to the robustness and accuracy of our findings."
10.1007/978-3-030-92563-5_52,unknown,"Computer simulation, visualization, and machine learning are increasingly playing key roles in the digitalization of advanced manufacturing processes. These technologies can be used to create cutting-edge physics-based and data-driven tools for real-time decision making to address critical issues related to energy efficiency, carbon footprint, and other pollutant emissions, productivity, quality, operation efficiency, maintenance, and more. They can also provide fundamental understanding and practical guidance for process design, troubleshooting, and optimization, new process development and scale up, as well as workforce development. The Center for Innovation through Visualization and Simulation (CIVS) at Purdue University Northwest, established in 2009, has used these technologies to develop and implement digitalization for Advanced Manufacturing in partnerships with steel and other industries."
10.18687/LACCEI2025.1.1.1804,unknown,"All rights reserved.The objective of the present study was to characterize the implementations of Machine Learning algorithms in predictive maintenance within the framework of Industry 4.0, with emphasis on its applicability and adaptation to the Latin American context, calculating on empirical evidence documented between 2018 and 2024, it was carried out through a narrative-analytical approach, complemented with a quantitative analysis of performance metrics, this combination allowed identifying best practices and critical success factors, as well as making objective comparisons between approaches and solutions, offering a comprehensive vision of the trends in predictive maintenance, where a gradual and adaptive approach is required, using traditional algorithms to balance complexity and viability in contexts with limited resources, observing a trend towards hybrid systems that facilitate the transition to Industry 4.0, especially for SMEs through continuous training and the development of human capital are key to ensuring the success and sustainability of these technologies."
10.1142/S021853932550010X,unknown,"The objective of this research is to improve the accessibility of ramjet engines to the aerospace industry by identifying critical elements of the system and to improve operational efficiency across the industry by optimizing endurance and performance. The compressor, gearbox, combustor, turbine, ram burner, and fuel injector are all essential components of an engine. Redundancy in compressor and turbine units is used to improve the overall performance of the system. This problem requires the use of an advanced genetic algorithm optimizer-driven design technique. This optimizer integrates system performance prediction methods to create an integrated design strategy. This study employs arbitrary repair rates, availability, and failure rates that follow an exponential distribution to establish a novel mathematical model. This model employs Markov processes and the Chapman-Kolmogorov equations to achieve generalization. Evaluating component performance involves a thorough examination of the availability values failure rates and repair rates of various subsystems in the decision matrix. It ensures continuous care of the system by making maintenance recommendations for all subsystems. Potential future research avenues may include incorporating real-time data and sophisticated machine-learning algorithms to enhance predictive maintenance processes. This study presents its findings for engine management. Innovations increase the efficiency of engines, making them applicable in real-world situations."
10.1016/j.precisioneng.2024.02.020,unknown,"The data driven industry 4.0 and increasing mass-customization of additive manufacturing products require a flexible and high-throughput integration of a 100% quality inspection. While XCT has shown to be a viable non-destructive testing and measurement technique, the long acquisition times remain a stumbling block for a cost-efficient integration in production environments. To mitigate the reduced reconstruction quality from fast acquisition protocols a new sinogram interpolation algorithm is proposed. First, the method re-samples the acquired sinogram data to a new data representation which is called a spinogram. Second, the alternative data format is used to predict the missing X-ray projections using a deep learning network. We implemented this method for real XCT scans and validated on a dataset of five laser sintered objects. When applying the proposed method before the reconstruction step, less noise is present in the reconstructed and segmented volumes. This improves the feature analysis of the measured objects while preserving a lower acquisition time, hence extending the use of XCT towards fast quality inspections."
10.1109/ACDSA65407.2025.11166515,unknown,"This paper examines the revolutionary role of Artificial Intelligence (AI) in modern film production design with specific reference to ways through which it can be employed for automating scene creation, facilitating previsualization, and simplifying digital scenography operations. A conceptual framework is outlined for automating scene construction and virtual set visualization through AI tools such as Midjourney, DALL·E, and Script Book. The system integrates script-driven scene extraction, generative visual layout, asset deployment in 3D engines, and real-time camera planning. Through qualitative analysis of case studies like Ex Machina, The Irishman, and Blade Runner 2049. The research demonstrates the potential of AI to streamline production workflows and enhance efficiency without compromising on visual realism. The paper also addresses the ethical and legal issues around deepfakes, digital avatars, and data ownership in AI pipelines. This blend of technical innovation and social responsibility provides a glimpse into the smart, immersive, and ethically conscious filmmaking of the future."
10.1109/INDIS54524.2021.00009,unknown,"Detecting performance anomalies is key to efficiently utilize network resources and improve the quality of service. Researchers proposed various approaches to identify the presence of anomalies by analyzing performance statistics using heuristic (e.g., change point detection) and Machine Learning (ML) models. Although these models yield high accuracy in the networks that they are trained for, their performance degrade severely when transferred to different network settings. This is because of the fact that existing models detect anomalies by capturing the changes in transfer throughput and observed RTT values, which are dependent to network settings. In this paper, we propose a novel feature transformation method to eliminate network dependence of ML models for anomaly diagnosis problems to enhance their performance when transferred to new networks (aka transfer learning) thereby mitigating the need to gather training data in each network separately. We validate the findings through experimental evaluations conducted on simulated and production networks and show that the proposed feature transformation improves the performance of transfer learning for anomaly diagnosis problems from less than 60% to over 90%. Finally, we evaluate the performance of the proposed solutions using various congestion control algorithm and observe that the models trained using BBR attains the best transfer learning performance compared to Cubic and HTCP."
10.1109/ICSC58660.2023.10449754,unknown,"There is a global demand for clean, safe, reliable, and stable electrical energy. This paper presents an optimal sizing of a photovoltaic generator (PVG), Wind turbines (WT), and an energy storage sources (ESS) integrated in a company using Homer software and Machine learning. The case study focuses on the Libyan Investment Authority, which is one of the sovereign and investment funds with significant financial investment assets worldwide the significant work is to find a solution to the problem of electricity supply to the Authority, which is considered completely unacceptable due to the sensitivity of the sovereign fund of the Libyan state. The objective of the study is to cover 250 kW of power demand in the company by integrating renewable energy sources, ESS, and diesel generator. Consequently, the study examines the electric, financial, and environmental aspects of the project. The total system production amounts to 2,398,024 kWh per year, resulting in a total cost of $5.69 million."
10.1016/j.nexus.2021.100011,unknown,"Among renewable energies, wind energy has become one of the most significant ones. Increasing its production and reducing energy and water costs has attracted many attentions. Moreover, due to the uncertainty of wind speed, power generation of wind farms is facing high volatility, which is affecting the electricity markets. Thus, in light of the rapid growth of wind energy technologies, new approaches based on advanced analytic are required. This paper presents a comprehensive review of artificial intelligence employed in wind energy systems, surveying the studies most applied in various applications and resulting from artificial neural networks (ANN) could be a sustainable approach instead of conventional methods in many cases. A large number of research studies associated with this topic are published since 2015, and based on the application could be categorized in five main groups: wind speed prediction, design optimization, fault detection, optimal control and maintenance planning. A statistical analysis of ANN application in these fields is carried out for the present time and future trends."
10.1038/s42256-020-0156-7,unknown,"Machine learning is a specific application of artificial intelligence that allows computers to learn and improve from data and experience via sets of algorithms, without the need for reprogramming. In the field of energy storage, machine learning has recently emerged as a promising modelling approach to determine the state of charge, state of health and remaining useful life of batteries. First, we review the two most studied types of battery models in the literature for battery state prediction: the equivalent circuit and physics-based models. Based on the current limitations of these models, we showcase the promise of various machine learning techniques for fast and accurate battery state prediction. Finally, we highlight the major challenges involved, especially in accurate modelling over length and time, performing in situ calculations and high-throughput data generation. Overall, this work provides insights into real-time, explainable machine learning for battery production, management and optimization in the future."
10.1007/s10845-022-01975-4,unknown,"Increasing digitalization enables the use of machine learning (ML) methods for analyzing and optimizing manufacturing processes. A main application of ML is the construction of quality prediction models, which can be used, among other things, for documentation purposes, as assistance systems for process operators, or for adaptive process control. The quality of such ML models typically strongly depends on the amount and the quality of data used for training. In manufacturing, the size of available datasets before start of production (SOP) is often limited. In contrast to data, expert knowledge commonly is available in manufacturing. Therefore, this study introduces a general methodology for building quality prediction models with ML methods on small datasets by integrating shape expert knowledge, that is, prior knowledge about the shape of the input–output relationship to be learned. The proposed methodology is applied to a brushing process with 125 data points for predicting the surface roughness as a function of five process variables. As opposed to conventional ML methods for small datasets, the proposed methodology produces prediction models that strictly comply with all the expert knowledge specified by the involved process specialists. In particular, the direct involvement of process experts in the training of the models leads to a very clear interpretation and, by extension, to a high acceptance of the models. While working out the shape knowledge requires some iterations in general, another clear merit of the proposed methodology is that, in contrast to most conventional ML, it involves no time-consuming and often heuristic hyperparameter tuning or model selection step."
10.1016/j.mtcomm.2022.103931,unknown,"Cost efficiency, lightweight, high toughness or a long lifespan are just a few examples. Hence, optimized materials and structures are necessary to develop and investigate. Three dimensional (3D) re-entrant auxetics combine lightweight, high strength, fracture resistance and high impact resistance, making them an ideal choice for crash absorbers and blast protection devices. An optimization work flow was implemented combining finite element (FE) simulations, neural networks and a surrogate model technique to gain the best compromise solution between the mass specific energy absorption capacity and a negative as possible Poisson's ratio. Parametrized FE simulations were used to generate a training database for the neural network, which then handles the structural optimization via a surrogate model. The resulting structure was produced using additive manufacturing and investigated under compressive loading to validate the simulations. The neural networks were able to predict the stress–strain relation closely and the simulations were a good match with the experiments."
10.1007/978-981-16-3227-3_13,unknown,"2021.Industry 4.0 represents the revolution of the fourth industry. Cyber-physical systems form the backbone of Industry 4.0. Cyber-physical systems use modern control systems with embedded software connected through IoT. Basically, cyber-physical systems build the facilities required in recent industries. Industry 4.0 is a blend of automations and data exchanges in various technologies like manufacturing industries, retail industries, and public services like hospitals and schools. With Industry 4.0, it is possible to develop smart applications to fight with the uncommon situation like COVID-19. Pandemics are the sudden attacks on public health, due to which the public services like hospitals collapse. Such situations demand the requirement of a medical facility in a nonlinear way which is hard to handle with traditional demand-supply strategy. This may lead to insufficient occupancy of services, etc. This insufficient occupancy leads to big losses in public health and lives. These scenarios can be handled by promoting the usage of advanced technology as a substitute for many services. Industry 4.0 revolutions are capable of handling such sudden situations like COVID-19 wherein social distancing plays a key role in stopping the spread of this. In a pandemic situation like COVID-19, the manpower requirement can be replaced with automated devices and cyber-physical systems, which will assist and substitute humans in providing the various services like real-time assistance, observation, medication, and sanitization. This chapter discusses the Industry 4.0 applications, methods, and case studies in various applications, which are essential to handle the sudden pandemic like COVID-19."
10.23919/CMD62064.2024.10766259,unknown,"Aviation has a difficult but imperative role in achieving decarbonization. The concept of 'More Electrical Aircraft' was first developed with the aim of rationalizing the energy aboard aircraft. Nowadays, and due to the desire to reduce aircraft weight and environmental impact even further, the main perspectives of aviation are associated with the development of hybrid or all electric propulsion systems. The emergence of these concepts requires an increase of the electrical power density available. Increasing operating currents alone is not considered viable due to the increased size and weight of metal in the conductors required to carry large currents without overheating. As such, increasing the operational voltage is the preferred alternative to develop multi-megawatt electrical systems. Delivering these high voltages in aeronautic environment introduces unique challenges when compared to ground-level systems, especially the increased risk of Partial Discharge (PD) inception within the Electrical Insulation System. In this context, and in order to meet the increased safety and reliability requirements associated to the aeronautic industry, condition monitoring is becoming a very attractive solution to perform predictive maintenance and health monitoring of electric systems. This process is widely used in ground-level applications to develop a smart maintenance plan to shut down the machinery and repair or replace a part only when needed. It relies on the monitoring of different operating parameters such as vibration, temperature, electrical signals, or acoustic emissions. Getting back to PD, numerous methods exist in the literature with the main objective of performing on-line PD recognition. These methods include statistical methods algorithms, which rely on the extraction of probabilistic moments of the signal, or well-known decomposition techniques such as Wavelet transform. Machine learning can also be a useful tool for data processing to support health monitoring. However, one may wonder whether these methods, although well-known and used for years in ground-level systems, could be robust to aviation applications. Thus, the aim of this paper is to draw a picture of the different works in progress in this field, taking into account aeronautic specificities."
