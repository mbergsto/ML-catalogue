doi,category,clean_abs
10.23940/ijpe.21.02.p7.229240,supervised,"Carbide cutting tools form an essential part of the manufacturing industry. A cutting tool, as the name suggests, is a cutting aid, generally harder than the workpiece material which is used for cutting the workpiece material and removing excess material in the form of chips. Any deviation in its condition affects the complete material removal process with respect to quality, accuracy, and durability. Thus, a condition supervision system for fault identification has turned out to be a key priority. The current era of Machine Learning (ML) stimulates the induction of classifier training for tool condition. In this paper, a study on carbide cutting tools is presented during a turning operation carried out on a simple lathe machine. The signature analysis of vibration generated due to the change in the carbide tool condition is carried out. Finally, a Boosted Trees Ensemble is deployed for training of various tool conditions."
10.5937/zasmat2303308D,supervised,"distributed under.The textile products are affected by the defects during the manufacturing processes. It is also waste of the resources used for the production and in turn it affects the business. The manual inspection in defect detections is not encouraged these days in manufacturing process. The computer vision with machine learning algorithms in automated quality control system plays an important role in detecting defects in manufacturing process as well as analyzing the quality of products. Classification of defects in knitted fabric is an active area of research around the globe. This paper presents a classification method to detect defects such as holes and thick places in knitted fabric by applying artificial neural network algorithm. The artificial neural network algorithms learn from the input data after successful training process, it predicts the nature of the unknown samples in very fast and accurate way. The proposed work has been carried out in two phases. In the first phase the images of the defective samples of two classes were collected by a high-resolution camera. The color images of the samples were converted into grey scale images. The features were extracted from each grey scale image and stored in a database. In the second phase a neural classifier was trained with back–propagation neural Network (BPNN) algorithm on the training dataset. After successful training of the neural network on train dataset, the performance of the trained neural network was evaluated on the test dataset. Different experiments were carried out by increasing the number of training data samples; it was found that the best evaluation performance was obtained as 83.3%."
10.1007/978-3-030-29859-3_43,supervised,"Steel-making process is a complex procedure involving the presence of exogenous materials which could potentially lead to non-metallic inclusions. Determining the abundance of inclusions in the earliest stage possible may help to reduce costs and avoid further post-processing manufacturing steps to alleviate undesired effects. This paper presents a data analysis and machine learning approach to analyze data related to austenitic stainless steel (Type 304L) in order to develop a decision-support tool helping to minimize the inclusion content present in the final product. Several machine learning models (generalized linear models with regularization, random forest, artificial neural networks and support vector machines) were tested in this analysis. Moreover, two different outcomes were analyzed (average and maximum abundance of inclusions per steel cast) and two different settings were considered within the analysis based on the input features used to train the models (full set of features and more relevant ones). The results showed that the average abundance of inclusions can be predicted more accurately than the maximum abundance of inclusions using linear models and the reduced set of features. A list of the more relevant features linked to the abundance of inclusions based on the data and models used in this study is additionally provided."
10.1007/978-981-15-8289-9_5,supervised,"The assessment of the product development initiative remains a complicated issue requiring additional analysis. The efficiency of the development in software depends on an appropriate estimation of the effort needed for software development and enables project managers to design software life cycle operations correctly with the efficient software cost estimating techniques. The major experimental work conducted throughout this paper is to accurately forecast the problems in developing program-related projects. The parallelization of the behavior factors is achieved using the M5P approach to maintain statistical precision. Besides, performance differences with random forest are offered with the models acquired using the M5P Method to demonstrate the efficiency attained with each method."
10.2175/193864718825159678,supervised,"The shift towards energy-efficient wastewater treatment plants (WWTPs) necessitates maximizing carbon diversion and maintaining low carbon influent. High-rate Contact Stabilization (HiCS) is a promising A-stage process for enhancing carbon capture and energy generation. This study, conducted at Blue Plains Advanced WWTP, utilizes machine learning (ML) models to predict effluent suspended solids (ESS) in HiCS. Using two years of operational data, we developed high-frequency features classification and all-features regression models. Optimized models showed improved predictive accuracy, integrating key process parameters and advanced settleability measurements, demonstrating ML’s potential for enhanced control and stabilization in dynamic wastewater treatment environments."
10.1016/j.fcr.2023.109169,supervised,"V.Context: Excessive phosphorus (P) applications to ensure enhanced crop growth and increased profitability are commonly used, leading to declined P use efficiency and high P accumulation in most cultivated soils across north-western India. However, the effects of consistently applying excessive P fertilizers on soil test P (STP) levels, P availability, and maize production outcomes are poorly understood. Objectives: The study aims to find the long-term impacts of different fertilizer P application rates on maize yield, agronomic P efficiency, optimal P rates for yield maximization, and predictive models for sustainable crop production and environmental protection across soils with different STP status. Methods: The current study collected and analysed maize plant and soil data spanning from 2011 to 2021 from an ongoing long-term field experiment conducted on three different STP status soils i.e., medium P (MPS), high P (HPS), and very high P (VHPS) soils. The experiment involves five different fertilizer P application rates No-P, 13, 26, 39, and 52 kg P ha−1. Results: The results indicated a significant increase in maize grain yield and P bioavailability with the application of 13 kg ha−1 of fertilizer P in VHPS (>50.0 kg P ha−1) and 26 kg ha−1 in both HPS (22.5–0.0 kg P ha−1) and MPS (12.5–22.5 kg P ha−1). Improved agronomic efficiency reducing P rate to half of the recommended 26 kg P ha−1 was estimated in VHPS. The economically optimal P rate (EOPR) model consistently sustains crop yield with lower P rates. Among the different machine learning algorithms, multiple linear regression (MLR) was found more reliable in predictive accuracy. The decrease in predicted grain yield and increase in predicted soil P accumulation at P rates of 26 kg P ha−1 and above in varying P status soils underscores the need for judicious P fertilization practices to avoid negative impacts on yield. Conclusions: The P application required to obtain an average maize yield of 6000 kg ha−1 with relatively high P use efficiency, fertilizer P applications of 35.2 kg ha−1 in VHPS, 37.1 kg ha−1 in HPS, and 41.1 kg ha−1 in MPS based on STP status is more economical. Smart agriculture, using machine learning algorithms helps in ensuring effective P utilization over the long term while minimizing negative ecological impacts. Implications: The sustainable growth of maize crops will necessitate a reduction in P application rates, and P optimization should need further attention to explore the microbial dissolution potential of residual P."
10.1007/s10845-023-02272-4,supervised,"Additive Manufacturing (AM) and in particular has gained significant attention due to its capability to produce complex geometries using various materials, resulting in cost and mass reduction per part. However, metal AM parts often contain internal defects inherent to the manufacturing process. Non-Destructive Testing (NDT), particularly Computed Tomography (CT), is commonly employed for defect analysis. Today adopted standard inspection techniques are costly and time-consuming, therefore an automatic approach is needed. This paper presents a novel eXplainable Artificial Intelligence (XAI) methodology for defect detection and characterization. To classify pixel data from CT images as pores or inclusions, the proposed method utilizes Support Vector Machine (SVM), a supervised machine learning algorithm, trained with an Area Under the Curve (AUC) of 0.94. Density-Based Spatial Clustering with the Application of Noise (DBSCAN) is subsequently applied to cluster the identified pixels into separate defects, and finally, a convex hull is employed to characterize the identified clusters based on their size and shape. The effectiveness of the methodology is evaluated on Ti6Al4V specimens, comparing the results obtained from manual inspection and the ML-based approach with the guidance of a domain expert. This work establishes a foundation for automated defect detection, highlighting the crucial role of XAI in ensuring trust in NDT, thereby offering new possibilities for the evaluation of AM components."
10.1007/s11227-025-07032-0,supervised,"Variational quantum algorithms (VQAs) are hybrid algorithms that combine quantum computing capabilities with classical machine learning (ML) tasks, utilizing classical optimizers to train parametrized quantum circuits. This work demonstrates their practical utility by addressing regression tasks in an industrially relevant context: modelling dendritic solidification in metals, a process crucial for determining mechanical properties in additive manufacturing. By comparing a classical surrogate model based on extreme gradient boosting with a hybrid classical-quantum VQA model, this work shows that VQAs can serve as a viable alternative for computationally expensive surrogate modelling. These findings highlight the potential of VQAs to tackle complex physical phenomena in high-cost computational scenarios, advancing their application in real-world industrial ML challenges."
10.3390/pr12091890,supervised,"Single-well productivity is a crucial metric for assessing the effectiveness of petroleum reservoir development. The accurate prediction of productivity is essential for achieving the efficient and economical development of oil–gas reservoirs. Traditional productivity prediction methods (empirical formulae and numerical simulation) are limited to specific reservoir types. There are few influencing factors, and a large number of ideal assumptions are made for the assumed conditions when predicting productivity. The application scenario is ideal. However, in tight oil reservoirs, numerous factors affect productivity, and their interactions exhibit significant complexity. Continuing to use traditional reservoir productivity prediction methods may result in significant calculation errors and lead to economic losses in oilfield development. To enhance the accuracy of tight reservoir productivity predictions and achieve economical and efficient development, this paper investigates the tight reservoir in the WZ block of the Beibuwan area, considering the impact of geological and engineering factors on productivity; the random forest tree and Spearman correlation coefficient are used to analyze the main influencing factors of productivity. The back propagation neural network optimized by particle swarm optimization was employed to develop a productivity prediction model (PSO-BP model) for offshore deep and ultra-deep tight reservoirs. The actual test well data of the oilfield are substituted into this model. The analysis results of the example application yielded an RMSE of 0.032, an MAE of 1.209, and an R2 value of 0.919. Compared with traditional productivity prediction methods, this study concludes that the model is both reasonable and practical. The calculation speed is faster and the calculation result is more accurate, which can greatly reduce productivity errors. The model constructed in this paper is well suited for predicting the productivity of tight reservoirs within the WZ block. It offers substantial guidance for predicting the productivity of similar reservoirs and supports the economical and efficient development of petroleum reservoirs."
10.1016/j.petrol.2019.106726,supervised,"V.It is imperative that wells in an oil field be located and controlled in an optimal fashion to maximize asset value while satisfying the optimization constraints which can be in the form of production limits, water cut, or well spacing. Computational optimization algorithms coupled with a reservoir simulator have become increasingly popular in determining the optimal locations of wells and the optimal controls to be imposed on them. These algorithms should be able to deal with highly non-linear objective functions, the absence of gradient information, and a limited reservoir simulation budget. In this work, we considered derivative-free and non-invasive techniques: Enhanced Success History-Based Adaptive Differential Evolution (ESHADE) strategy with linear population size reduction, which is a variant of L-SHADE (recognized as one of the state-of-the-art global stochastic optimizers for continuous variable), and a Mesh Adaptive Direct Search (MADS) local pattern search method. These two methods are hybridized to develop a hybrid framework (E-MADS) that combines the advantageous aspects of both methods in order to improve optimization efficiency. In order to further improve the efficiency of the framework, gradient boosting machine learning technique is used to generate proxy model, based on regression and classification methods, to predict the objective function and classify optimization solutions into feasibless (satisfies all prescribed constraints) and infeasible groups. This information is then used to screen out solutions that are not expected to improve the objective function. Applications of these algorithms to the joint optimization of well location and time-varying control problem, with bounds and nonlinear constraints, are presented in this work. ESHADE is shown to outperform traditional global optimization algorithms such as Particle Swarm Optimization (PSO) and a real-coded Genetic Algorithm (GA). The E-MADS hybrid is also shown to have a superior performance relative to the standalone ESHADE and MADS methods for the joint optimization problem."
10.1007/978-981-13-8668-8_7,supervised,"In the process of multi-layer and multi-bead wire and arc additive manufacturing (WAAM), the geometry of each layer has an important influence on the dimensional accuracy and surface quality of the final forming parts. In this paper, machine learning model is used to predict the geometrical morphology of multi-layer and multi-channel WAAM forming parts. A series of experiments of WAAAM under different parameters were carried out by rotating combination experiment, and the bead geometry of the forming parts were obtained by visual sensing system developed by ourselves. Aiming at the problem of less data samples which would lead to over-fitting in the process of model training, this paper introduces the XGBoost algorithm for modeling. Compared with the neural network algorithm, the regression prediction model of arc additive manufacturing morphology based on XGBoost has a higher prediction accuracy."
10.1371/journal.pone.0306987,supervised,"This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.The laboratory-scale (in-vitro) microbial fermentation based on screening of process parameters (factors) and statistical validation of parameters (responses) using regression analysis. The recent trends have shifted from full factorial design towards more complex response surface methodology designs such as Box-Behnken design, Central Composite design. Apart from the optimisation methodologies, the listed designs are not flexible enough in deducing properties of parameters in terms of class variables. Machine learning algorithms have unique visualisations for the dataset presented with appropriate learning algorithms. The classification algorithms cannot be applied on all datasets and selection of classifier is essential in this regard. To resolve this issue, factor-response relationship needs to be evaluated as dataset and subsequent preprocessing could lead to appropriate results. The aim of the current study was to investigate the data-mining accuracy on the dataset developed using in-vitro pyruvate production using organic sources for the first time. The attributes were subjected to comparative classification on various classifiers and based on accuracy, multilayer perceptron (neural network algorithm) was selected as classifier. As per the results, the model showed significant results for prediction of classes and a good fit. The learning curve developed also showed the datasets converging and were linearly separable."
10.59038/jjmie/170403,supervised,"All rights reservedBending is one of the widely used forming processes for sheet metals. However, due to the metal elasticity, the springback characteristic is unavoidable, leading to deviations from the desired final shapes and causing cumulative fitting problems in the assembly stages. Thus, precise predictions of the springback responses will enhance the sheet metal forming and the overall manufacturing processes. This is achieved by employing tree-based machine learning algorithms. These algorithms are used for their simplicity, preciseness, and consistency. Based on the tree-based algorithms, many prediction models are constructed and evaluated. First, experimental setup is established to measure the springback angles for different manufacturing conditions such as: the bending angle, the sheet metal’s width and thickness, the machine settings, etc. Then, these data sets are divided into training and testing groups for the prediction models. This division is carried randomly, where 90 % of the data sets are used for training, and 10 % are left for testing the models’ accuracy. The models are evaluated by comparing their predicted springback angles with the experimental values. The deviation errors are measured using the Mean Square Error (MSE), the Mean Absolute Error (MAE), and the Root Mean Square Error (RMSE).It isrevealed that the LightGBM prediction model is the most accurate model with 0.42 deg., 0.26 deg., and 0.52 deg. for MAE, MSE, and RMSE, respectively. The Gradient boosting comes in the second place with 0.66 deg., 0.760 deg., and 0.80 deg. for MAE, MSE, and RMSE, respectively."
10.3390/sym13060938,supervised,"Licensee MDPI, Basel, Switzerland.Numerical models for the flow of blood and other fluids can be used to design and optimize microfluidic devices computationally and thus to save time and resources needed for production, testing, and redesigning of the physical microfluidic devices. Like biological experiments, computer simulations have their limitations. Data from both the biological and the computational experiments can be processed by machine learning methods to obtain new insights which then can be used for the optimization of the microfluidic devices and also for diagnostic purposes. In this work, we propose a method for identifying red blood cells in flow by their stiffness based on their movement data processed by neural networks. We describe the performed classification experiments and evaluate their accuracy in various modifications of the neural network model. We outline other uses of the model for processing data from video recordings of blood flow. The proposed model and neural network methodology classify healthy and more rigid (diseased) red blood cells with the accuracy of about 99.5% depending on the selected dataset that represents the flow of a suspension of blood cells of various levels of stiffness."
10.1007/s00170-025-16601-9,supervised,"The production of parts with high strength and consistent quality through metal additive manufacturing is a challenging task. Machine learning methods may help optimize the production process or improve materials. In this work, convolutional neural networks (CNNs) are developed for the classification of hot work steels and for the prediction of mechanical properties of these steels from microstructure images recorded by scanning electron microscopy (SEM). A total of 18 samples of two different hot work steels fabricated by laser-based powder bed fusion (PBF-LB/M) are investigated, each with or without preheating and with one of five different post-heat treatments. The steels are standard steel H11 and a newly developed modification intended for the same application. The goal of the heat treatments and the modification of the steel is to achieve comparable crack-free properties without the need for a preheating process. The microstructure images of the 18 samples are accurately distinguished by a classification CNN with an overall accuracy of 98%. Furthermore, regression CNNs for the prediction of yield strength (YS) and ultimate tensile strength (UTS) generalize well and predict YS and UTS for new untrained samples with average relative errors of only 4.1% and 3.9%, respectively."
10.1016/j.jmapro.2024.01.072,supervised,"Predicting the dimensional accuracy of products and identifying defect parts at the early manufacturing stage is vital yet challenging. Physical simulation is commonly used for analyzing the part deformation during the casting process. However, it is usually timing consuming, thus not suitable for applications during the manufacturing process. This paper proposes a data-driven framework for estimating and screening defect products at the early stage based on ensemble learning techniques. Taking the geometrical relationship of the intermediate and the final products into consideration, a feature derivation and selection method is firstly developed. Then, an ensemble machine learning model is proposed for high prediction accuracy with the integration of multiple machine learning models. Validation experiment outcomes for the case of aircraft hollow turbo blade manufacturing indicate that the proposed prediction method can accurately predict the wall thickness of the final parts based on wax patterns and effectively identify the unqualified intermediate parts at the early stage. In this way, the production yield rate could be improved, and the cost of the production could be reduced."
10.1007/978-981-96-0763-1_7,supervised,"2025.Food and agriculture sector is witnessing several challenges with respect to production as well as meeting the growing demand for food in the country. Demand for healthier food option and traceability require continuous technological as well as supply chain innovations. New institutional arrangements like FPOs are addressing some of these challenges by way of collectivizing the activities, improving their bargaining power, providing access to markets inputs and farm outputs, and providing necessary infrastructure for value addition and primary processing at the farmers’ doorsteps. However, these FPOs also face some challenges such as lack of awareness about modern technologies, inadequate working capital, and limited access to markets. On the other hand, agri-startups are using emerging technologies to improve farm productivity and making agriculture more sustainable. Digital technologies, data analytics, AI-based predictive model, image sensing, IoT devices, sensors, satellite imagery, machine learning, blockchain, etc., are used by many of such agri-startups. However, they have constraints in making these technologies accessible to individual farmers due to their small land holding and technology affordability. A synergistic approach of “Full-Stack Farm-to-Fork Model” is suggested where agri-startups collaborate with FPOs to leverage their grassroots understanding and established networks, while FPOs get benefit from the technological advancements brought in by these new-age entrepreneurs. Such synergy would have multi-pronged benefits in the farm-to-fork value chain by reducing the transaction cost, improving the productivity, and also cutting down the carbon footprint in the value chain."
10.1021/acs.iecr.9b03702,supervised,"Copyright © 2019 American Chemical Society.Just-in-time (JIT) learning has been widely used for data-driven soft sensor modeling. However, traditional JIT soft sensors do not always function well when applied to complex industrial processes because they are only equipped with a single learning configuration. Therefore, a novel ensemble JIT (EJIT) learning-based soft sensor, referred to as triple-modal perturbation (TP)-based EJIT extreme learning machine (TP-EJITELM), is proposed. In the method, a set of diverse and accurate base JITELM models are generated by using heterogeneous similarity measures and optimizing the model structure and input variables through an evolutionary multiobjective optimization approach. Then, a selective ensemble learning strategy is used to integrate the base models. Compared with traditional JIT soft sensors, TP-EJITELM can significantly improve prediction performance because of the complementary advantages of heterogeneous similarity measures and a good tradeoff between model complexity and accuracy. The effectiveness of the proposed method is demonstrated through two industrial applications."
10.1117/12.3058653,supervised,"The increasing complexity of modern printed circuit boards (PCBs) demands the adoption of advanced 3D X-ray reconstruction techniques for precise, non-destructive assessment. Current metrological frameworks frequently fall short in addressing pivotal challenges such as the identification of micro-defects, the assurance of solder joint integrity, and the assessment of multi-layer alignment. This research introduces an innovative metrological framework specifically designed for PCB evaluation, incorporating two fundamental metrics aimed at enhancing the fidelity and reliability of reconstructions. The Circuit Trace Fidelity Index (CTFI) effectively measures the geometric accuracy of reconstructed circuit pathways by contrasting them with the empirical ground truth through the deployment of Euclidean distance, thereby promoting the precise discernment of complex configurations. The Layer Alignment Consistency Score (LACS) appraises the accuracy of inter-layer alignment in multi-layered PCBs, utilizing the standard deviation of alignment offsets normalized against an acceptable threshold derived from design tolerances, manufacturing capabilities, or functional testing. These metrics are meticulously crafted to integrate effortlessly with existing reconstruction processes, capitalizing on domain-specific expertise and machine learning methodologies to bolster robustness and applicability. With well-defined mathematical formulations and pragmatic strategies for threshold determination, this framework offers a standardized, quantitative methodology for evaluating reconstruction fidelity. By addressing the particular requirements of PCB inspection, encompassing trace geometry accuracy and inter-layer consistency, this groundbreaking metrology guarantees both structural and functional integrity while optimizing quality control protocols."
10.3390/insects15070463,supervised,"This study addresses the challenges in plant pest and disease prediction within the context of smart agriculture, highlighting the need for efficient data processing techniques. In response to the limitations of existing models, which are characterized by slow training speeds and a low prediction accuracy, we introduce an innovative prediction method that integrates gene expression programming (GEP) with support vector machines (SVM). Our approach, the gene expression programming—support vector machine (GEP-SVM) model, begins with encoding and fitness function determination, progressing through cycles of selection, crossover, mutation, and the application of a convergence criterion. This method uniquely employs individual gene values as parameters for SVM, optimizing them through a grid search technique to refine genetic parameters. We tested this model using historical data on wheat blossom midges in Shaanxi Province, spanning from 1933 to 2010, and compared its performance against traditional methods, such as GEP, SVM, naive Bayes, K-nearest neighbor, and BP neural networks. Our findings reveal that the GEP-SVM model achieves a leading back-generation accuracy rate of 90.83%, demonstrating superior generalization and fitting capabilities. These results not only enhance the computational efficiency of pest and disease prediction in agriculture but also provide a scientific foundation for future predictive endeavors, contributing significantly to the optimization of agricultural production strategies."
10.1016/j.seta.2024.103684,supervised,"A hybrid method fault prediction mechanism for wind turbines is developed using machine learning and deep learning methods. The random forest method is applied to identify features that are highly correlated with faults, and to eliminate low-correlation features to maximize prediction model efficiency. Long short-term memory (LSTM) deep learning methods are then applied to handle the time series data, analyze historical pre-failure information, use the dynamic weight loss function to address data imbalance, and finally predict the future wind turbine health status. The resulting fault prediction model produces average prediction accuracy, precision and recall rates of 99%, 70% and 77%, respectively for predictions of one to six hours ahead, indicating that the proposed model can effectively predict wind turbine failures in advance, thus providing increased time for fault response and effectively improving the wind turbine lifespan."
10.1016/j.jclepro.2023.140411,supervised,"This study introduces a novel approach that combines mine production intensity with meteorological conditions to enable accurate daily prediction of dust concentration in open-pit mines. To achieve this, the study collected meteorological factors and production intensity parameters spanning 365 days from the Haerwusu open-pit coal mine in China. To enhance the accuracy of predictions, six heuristic algorithms were employed to optimize the hyperparameters of the random forest algorithm. During the prediction process, the results of PM2.5, PM10, and TSP were compared, and the model performance with and without mine operational parameters was analyzed. The findings demonstrate significant advancements in predicting three distinct indicators through the proposed method. Specifically, the research successfully predicted mine dust concentration on a daily basis over a long-term period. The introduction of production intensity parameters ensures the accuracy and reliability of dust concentration prediction, and the availability of future meteorological factors enables a realistic prediction of dust concentration in open-pit mines. These outcomes carry substantial practical implications, including safeguarding worker health, optimizing mine operation plans, and enhancing coal production efficiency."
10.1016/j.biteb.2024.101993,supervised,"Six ML models, including support vector regression (SVR), kernel ridge regression (KRR), extreme gradient boosting (XGB), extreme learning machine (ELM), random forest (RF), and artificial neural networks (ANN), were employed to predict lipase activity in a multi-substrate system using avocado seed, coconut pulp, and palm oil mill effluent (POME) with Aspergillus niger. SVR proved the most effective (R2 = 0.9738; RMSE = 7.0089). Further optimization using manta ray foraging optimization (MFRO), particle swarm optimization (PSO), and genetic algorithm (GA) identified optimal substrate loadings, achieving a maximum lipase activity of 194.38 U/gds. The addition of a mixture of surfactants (Tween 80, Tween 20, Triton X-100) further increased lipase production to 520.95 U/gds (168.3 % increase). Global sensitivity analysis (GSA) confirmed the important roles of avocado seed, POME, and surfactants in enhancing lipase production. This approach represents a significant advancement in bioprocess scalability."
10.3390/systems13070578,supervised,"As Chinese firms play pivotal roles in global supply chains, multinational corporations face increasing pressure to ensure ESG accountability across their sourcing networks. Current ESG rating systems lack transparency in incorporating China’s unique industrial, economic, and cultural factors, creating reliability concerns for stakeholders managing supply chain sustainability risks. This study develops an explainable artificial intelligence framework using SHAP and permutation feature importance (PFI) methods to predict the ESG performance of Chinese firms. We analyze comprehensive ESG data of 1608 Chinese listed companies over 13 years (2009–2021), integrating financial and non-financial determinants traditionally examined in isolation. Empirical findings demonstrate that random forest algorithms significantly outperform multivariate linear regression in capturing nonlinear ESG relationships. Key non-financial determinants include patent portfolios, CSR training initiatives, pollutant emissions, and charitable donations, while financial factors such as current assets and gearing ratios prove influential. Sectoral analysis reveals that manufacturing firms are evaluated through pollutant emissions and technical capabilities, whereas non-manufacturing firms are assessed on business taxes and intangible assets. These insights provide essential tools for multinational corporations to anticipate supply chain sustainability conditions."
10.35940/ijeat.A1486.109119,supervised,"Gearbox is an important component used for automobiles, machine tools, industries etc. Failure of any component in gearbox will cause huge maintenance cost and production loss. Failure should be detected as early as possible in order to avoid sudden breakdown which even cause catastrophic failures. Vibration signals are used for machine condition monitoring for predictive maintenance and efficiently predicts fault in the gearbox. In this paper signals from vibration is used for diagnosis of gearbox fault. The experiment uses four different conditions of gearbox in four different load conditions. Then statistical feature extraction is done and obtained result is given to Decision Tree, Support Vector Machine (SVM), Convolutional Neural Network (CNN) and Deep Neural Network (DNN) for fault diagnosis. The efficiency of these four techniques is compared and shows that machine learning is better than deep learning in gearbox fault diagnosis."
10.1016/j.knosys.2024.112445,supervised,"V.Most methods only use normal samples to learn anomaly detection (AD) models in an unsupervised manner. However, these samples may be noisy in real-world applications, causing the models to be unable to accurately identify anomaly objects. In addition, there are a small number of anomaly samples in real industrial production that should be fully utilized to help model discrimination. Existing methods of introducing anomaly samples still have bottlenecks in model identification capabilities. In this paper, by introducing both normal and a few abnormal samples, we propose a novel semi-supervised learning method for anomaly detection, named RobustPatch, which can improve the model discriminability through a self-cross scoring mechanism and the learning of feature AutoEncoder. Our approach contains two core designs: Firstly, we propose a self-cross scoring module, calculating the weights of normal and anomaly features extracted from corresponding images using a self-scoring and cross-scoring manner, respectively. Secondly, our approach proposes a fully connected feature AutoEncoder to rate the extracted features, which is trained with the supervision of the scored weights. Extensive experiments on the MVTecAD and BTAD datasets validate the superior anomaly boundaries discriminability of our approach and superior performance in noise-polluted scenarios."
10.1016/j.promfg.2021.06.059,supervised,"Published by Elsevier B.V.In Additive Manufacturing (AM), auditing layer-by-layer images can detect infill defective attacks effectively. However, the auditing process itself can become a target of inside or outside attackers in Cyber-Physical Manufacturing System (CPMS) environments because pervasive connection through various types of computer networks in CPMS opens new doors for adversaries to compromise various components in an attack detection system. To maintain an effective attack detection system and prevent data from malicious data injection, this paper presents a Layer Image Auditing System (LIAS) secured by the Blockchain technology in CPMS. LIAS consists of a pre-processing system and a Multilayer Perceptron Neural Network (MLP). To evaluate the prediction accuracy of LIAS, a set of simulated infill images and physical images were used for training and testing. The effectiveness of the Blockchain implementation is demonstrated by presenting the comparative performance analysis of the proposed attack detection system with and without the Blockchain."
10.4108/eetpht.10.5552,supervised,"Yadav et al.INTRODUCTION: Polycystic Ovary Syndrome is a condition in which the ovaries manufacture androgen, seen in small traces, resulting in the production of cysts. Menstrual cycle abnormalities, clinical and/or biochemical hyperandrogenism, and the presence of polycystic ovaries on ultrasound should all be used to diagnose PCOS. PCOS appears to be a multifaceted illness influenced by both genetic and environmental factors and the symptoms include excessive hair on the face and body, weight gain, voice changes, skin type changes, and irregular periods. OBJECTIVES: This is the objective of this paper is to identify PCOS in its initial stage. METHODS: To address this issue the study proposes a comparison of various machine learning algorithms and optimization techniques Among which GSCV gave the best result of 94% accuracy, followed by TPOT with 91% accuracy. Additionally, we also applied Feature selection methods to eliminate zero-importance features to increase the accuracy of algorithms. RESULTS: The main results obtained in this paper This study explored various Feature selection techniques, ML and DL models. It is shown that Grid Search CV and TPOT classifier were best classifiers with 94% and 91% respectively. CONCLUSION: These are the conclusions of this paper and this study will explore various DL methodologies and try to find out best optimal results for the PCOS Detection. And also, to develop an PCOS detection application to keep track of menstrual cycles and track activities and symptoms for PCOS."
10.1007/978-3-031-74633-8_5,supervised,"To be employed in real-world applications, explainable artificial intelligence (XAI) techniques need to provide explanations that are comprehensible to experts and decision-makers with no machine learning (ML) background, thus allowing for the validation of the ML model via their domain knowledge. To this aim, XAI approaches based on feature importance and counterfactuals can be employed, although both have some limitations: the last provide only local explanations, whereas the first can be very computationally expensive. A less computationally-expensive global feature importance measure can be derived by considering the instances close to the model decision boundary and analyzing how often some minor changes in one feature’s values do affect the classification outcome. However, the validation of XAI techniques in the literature rarely employs the application domain knowledge due to the burden of formalizing it, e.g., providing some degree of expected importance for each feature. Still, given an ML model, it is difficult to determine whether an XAI technique may inject a bias in the explanation (e.g., overestimating or underestimating the importance of a feature) in the absence of such ground truth. To address this issue, we test our feature importance approach both with the UCI benchmark datasets and real-world smart manufacturing data characterized by annotations provided by domain experts about the expected importance of each feature. If compared to the state-of-the-art, the employed approach results to be reliable and convenient in terms of computation time, as well as more concordant with the expected importance provided by the domain expert."
10.1016/j.cscm.2025.e04741,supervised,"However, assessing their environmental performance often requires detailed data and time-intensive analyses. This study presents a machine learning-based methodology for the rapid estimation of the CO₂ footprint and environmental-mechanical performance (CO₂/MPa ratio) of concrete mixtures using only the proportions of their main components (i.e., ordinary portland cement (OPC), SCMs, aggregates, water, and water-reducing admixtures). The models were developed using a dataset of 246 mixtures compiled from the literature and validated against 15 experimentally tested mixtures. The results demonstrate that the Gaussian Process Regressor provides the highest predictive accuracy for both CO₂ footprint and CO₂/MPa ratio. Feature analysis revealed that OPC content has the highest impact on the CO₂ footprint, while aggregate fraction has the most significant influence on the CO₂/MPa ratio. An optimization framework was also implemented to explore the trade-offs among mix components, showing that increasing SCM content does not always lead to improved CO₂/MPa ratio, highlighting the need for balanced mixture design. The developed models offer a practical tool for supporting early-stage decision-making in construction projects by enabling rapid sustainability assessments of concrete mixtures, independent of specific SCM types, production methods, or geographical context."
10.1016/j.mfglet.2023.08.010,supervised,"0 have become increasingly established and thus a widespread technology among companies. By means of data acquisition, processes can not only be made more sustainable and resource-efficient but through emerging technologies like fault detection or predictive maintenance, a higher Overall Equipment Effectiveness (OEE) can be achieved. As a result, the availability of the machine tools remains high and process chains will not be disturbed. However, many companies still operate in brownfield production sites with legacy machines and therefore with limited opportunities for machine data access and use in an economically viable manner. As a result, many advantages that would increase the OEE of machine tools cannot be used. To present a solution for retrofitting brownfield machines, a low-effort system was developed that extracts machine control signals from different machine data sources and automatically identifies them using a multi-stage algorithm. This algorithm consists of analytical rule bases built using expert knowledge and a machine learning model for classification. The best performing models were selected as machine learning models, which are a Residual Network, a Fully Convolutional Network, a Long-Short-Term Memory, and a Random Forest. With different datasets from two machine tools, the overall model was tested and was able to correctly identify the signals present with an accuracy of 86.92 % to 98.93 % on average. Using this approach, the identified signals are assigned to an information model linking them to the respective machine tool axes. As a result, brownfield machines are also made accessible for modern technologies such as predictive maintenance or a reduction in rejects as a result of error detection."
10.1016/j.cie.2021.107601,supervised,"While traditional bottom-up cost estimation is a very time consuming and know-how intensive process, intelligent machine learning methods have the potential to significantly reduce the effort in the cost estimation process. In this paper, a literature review on intelligent cost estimation methods for parts to be procured in the manufacturing industry is carried out by text mining. Following the results of this literature review, building blocks for an intelligent cost estimation system are outlined that comprise cost estimation methods, dimensionality reduction methods, methods for multi-level cost estimation, and methods for interpreting the results of the cost analysis. Regarding cost estimation methods, Artificial Neural Networks and Support Vector Machines outperform established linear regression algorithms. Dimensionality reduction methods like Correlation Analysis or Principal Component Analysis are rarely studied. Nevertheless, they contribute a lot to the reduction of expensively provided input parameters for cost estimation. Methods for multi-level cost estimation, that support cost prediction of parts and assemblies following the construction plan of a vehicle, and methods for interpretation of intelligent cost analytics cannot be found at all in literature. Consequently, in this paper corresponding approaches are derived from the areas of Multitask Learning and Explainable Machine Learning. Finally, a combination of methods considered most suitable for predictive analytics to estimate procurement costs is presented."
10.1145/3449639.3459395,supervised,"Automated machine learning (AutoML) strives for automatically constructing and configuring compositions of machine learning algorithms, called pipelines, with the goal to optimize a suitable performance measure on a concrete learning task. So far, most AutoML tools are focused on standard problem classes, such as classification and regression. In the field of predictive maintenance, especially the estimation of remaining useful lifetime (RUL), the task of AutoML becomes more complex. In particular, a good feature representation for multivariate sensor data is essential to achieve good performance. Due to the need for methods generating feature representations, the search space of candidate pipelines enlarges. Moreover, the runtime of a single pipeline increases substantially. In this paper, we tackle these problems by partitioning the search space into two sub-spaces, one for feature extraction methods and one for regression methods, and employ cooperative coevolution for searching a good combination. Thereby, we benefit from the fact that the generated feature representations can be cached, whence the evaluation of multiple regressors based on the same feature representation speeds up, allowing the evaluation of more candidate pipelines. Experimentally, we show that our coevolutionary strategy performs superior to the baselines."
10.1007/978-3-319-07173-2_53,supervised,"In this paper, single correct and three defective states for the cold headed fasteners production technological process are detected. Computational intelligence methods are used for this purpose: single decision tree, probabilistic neural network, support vector machine, multilayer perceptron, linear discriminant analysis and K-Means clustering. The predictor variables are taken in time and frequency domain. The row data sets consist of sampled signals of the real process collected in fasteners manufacturing company. The prediction ability determined by 10-fold cross validation is investigated by means of accuracy, sensitivity and specificity. The results show the superiority of probabilistic neural network and support vector machine classifiers. The average accuracy is over 98%. © 2014 Springer International Publishing."
10.11897/SP.J.1016.2025.02207,supervised,"All rights reserved.Time series data are widely prevalent in various Internet of Things (IoT) domains, such as industrial manufacturing, smart healthcare, and intelligent transportation. These data often contain critical information such as user behavior patterns, system operating status, and future development trends. Traditionally, the raw time series data collected by numerous terminal devices are entirely transmitted to data centers, where computation-intensive data analysis and intelligent decision-making tasks are performed. However, as the volume of time series data continues to increase at an unprecedented rate, the centralized data processing paradigm brings tremendous bandwidth pressure to conventional communication systems and fails to meet the low-latency and high-reliability requirements of time-sensitive applications such as smart manufacturing and intelligent transportation. To tackle these challenges, this paper proposes a novel heterogeneous federated semantic communication system designed for time series forecasting tasks. Unlike traditional transmission methods, the proposed system leverages semantic communication principles, aiming to extract and transmit task-relevant information. This strategy significantly reduces communication overhead and achieves accurate forecasting-oriented time series transmission. One of the key contributions of this work is the design of a Multi-head Mixture Linear Attention (MMA) mechanism, which functions as the core component of the semantic encoders and decoders. MMA is tailored for the efficient extraction of semantic information in time series data. It combines the advantages of window attention and low-rank attention, enabling the modeling of both global and local temporal dependencies in a lightweight manner suitable for deployment on resource-constrained terminal devices. Another major challenge in semantic communication for time series forecasting is the scarcity of knowledge among distributed devices. Variations in computational capabilities and data distributions hinder the analysis and extraction of task-relevant semantic information on each device. To overcome this, this paper introduces a Federated Embedding (FedEmb) algorithm for effective knowledge sharing among heterogeneous devices. Through introducing common knowledge in the semantic communication system, FedEmb enables efficient training of the semantic encoders across distributed devices and facilitates collaborative inference without requiring direct access to raw data. This approach enhances model generalization and robustness in heterogeneous environments. To further enhance the overall performance of the semantic communication system, a two-stage pre-training scheme based on self-supervised learning is proposed. By sequentially performing generative pre-training on semantic encoders and channel encoders, the system can capture rich task-relevant representations and learn robust semantic features tailored to the forecasting objective. After that, the entire communication system undergoes joint optimization to ensure end-to-end performance improvement and alignment between semantic encoding and downstream forecasting tasks. Extensive simulation experiments are conducted on five real-world time series datasets to evaluate the proposed system. The results show that FedEmb outperforms four state-of-the-art heterogeneous federated learning algorithms, achieving superior knowledge sharing efficiency and significantly lower mean squared error (MSE) in time series forecasting tasks. Furthermore, compared with six advanced semantic and traditional communication systems, the proposed FedEmb-based Semantic Communication (SC-FedEmb) system exhibits enhanced robustness, reduced transmission overhead, and the highest forecasting accuracy under various real-world conditions. These findings demonstrate the effectiveness of SC-FedEmb in addressing real-time forecasting needs in heterogeneous IoT environments."
10.1007/978-981-99-1288-9_38,supervised,"Automation of the manufacturing processes especially in the rolling process of steel needs better quality assessment methods so that proper inspections are carried out before the end product is released. In order to achieve higher productivity through non-contact inspection, it is important to identify edge defects during the rolling process itself with the help of computer vision and machine learning techniques. In this work, a new approach consisting of an improved convolutional neural network (CNN) as classifier using Visual Geometry Group-19(VGG-19) algorithm as feature extractor is used to detect the edge defects under the framework of tensor flow. About 4000 images have been collected for model testing and training. By adopting the recently developed VGG-19 trained CNN network model, 3 Fully Connected layers were reduced into one flat layer and 2 Fully Connected Layers with reduced parameters. Testing accuracy of the model was 87% and the model achieved 98% training accuracy."
10.1088/1742-6596/2281/1/012021,supervised,"The wear of the turning tool has a great impact on product quality. With the development of sensor technology and increasing computing power, more and more research focuses on online monitoring and prediction of tool condition using machine learning methods. Nevertheless, most research has been conducted in laboratories, making it difficult to apply the results to the shop floor under complex production conditions. The research is based on vibration data measured in a real production environment of a turning machine. Machine learning models such as Random Forest, XGBoost, etc. were trained to predict the wear condition of the turning tool after features were extracted using digital signal processing techniques such as wavelet decomposition and empirical mode decomposition. A moving average-based method was proposed to convert the binary classification results into the probability of tool failure. On a real manufacturing data set, the online real-time monitoring is realized with an accuracy of 93.8%. It proves to be a good approach for managing spare parts in a real-time industrial environment with limited and isolated data sources."
10.32604/cmc.2025.063562,supervised,"Copyright © 2025 The Authors.The integration of IoT and Deep Learning (DL) has significantly advanced real-time health monitoring and predictive maintenance in prognostic and health management (PHM). Electrocardiograms (ECGs) are widely used for cardiovascular disease (CVD) diagnosis, but fluctuating signal patterns make classification challenging. Computer-assisted automated diagnostic tools that enhance ECG signal categorization using sophisticated algorithms and machine learning are helping healthcare practitioners manage greater patient populations. With this motivation, the study proposes a DL framework leveraging the PTB-XL ECG dataset to improve CVD diagnosis. Deep Transfer Learning (DTL) techniques extract features, followed by feature fusion to eliminate redundancy and retain the most informative features. Utilizing the African Vulture Optimization Algorithm (AVOA) for feature selection is more effective than the standard methods, as it offers an ideal balance between exploration and exploitation that results in an optimal set of features, improving classification performance while reducing redundancy. Various machine learning classifiers, including Support Vector Machine (SVM), eXtreme Gradient Boosting (XGBoost), Adaptive Boosting (AdaBoost), and Extreme Learning Machine (ELM), are used for further classification. Additionally, an ensemble model is developed to further improve accuracy. Experimental results demonstrate that the proposed model achieves the highest accuracy of 96.31%, highlighting its effectiveness in enhancing CVD diagnosis."
10.1109/ISSE49702.2020.9121044,supervised,"False calls are an undesired occurrence in manufacturing of printed circuit boards that have to be verified manually after the automated optical inspection} (AOI). In this paper, the feasibility of identifying false calls of the AOI using subsequent machine learning models is investigated. Different algorithms, data set sizes and thresholds integrated into the model are considered. Thus, depending on the use case, the accuracy of the model should be maximized without increasing the error slip. Therefore, the numerical measurement data generated by the AOI is usedfor model training, testing and validation. The investigated models use a k-nearest neighbors (knn) classifier as well as an artificial neural network (ANN). Since metrics of ML models can be strongly dependent on data quantity and quality the models are tested and compared on different data sets. While the knn-classifier achieves the best results for small data sets, its use becomes problematic for large data sets due to increasing computing time. For large data sets ANNs as well as Random Forest Classifiers surpass the performance of the knn-classifier."
10.1186/s40100-025-00380-8,supervised,"This paper explores the adoption of green production technology within the framework of Pakistan–China agricultural cooperation under the China–Pakistan Economic Corridor. The research focus is on how farmers’ green values (FGVs) and energy use reduction (EUR) affect the adoption of green production technology (AGPT), mediating through green production willingness (GPW), with environmental regulation and eco-innovation as moderators. The study conducts an analysis based on the use of structural equation modelling (SEM) and random forest regressor (RFR), wherein the drivers of sustainable agricultural practice are discussed. For this primary quantitative study, data were gathered via the survey method from 366 rural farmers, and SEM was performed to test hypotheses. SmartPLS software was used for this purpose. The results obtained show that both FGV and EUR have significant impacts on AGPT. However, ER insignificantly influences GPW. The mediation of GPW was significant in the association between FGV and AGPT (p < 0.05). However, it was insignificant in the relationship between EUR and AGPT (p > 0.05). The sequential mediation of GPW and AGPT was also found to be insignificant (p > 0.05), whereas AGPT has a significant impact on green supply chain performance (GSP). The moderation of environmental regulation was also insignificant (p > 0.05), while the moderation of eco-innovation was significant (p < 0.05). The RFR model also supported the impact of FGV and EUR on GSP. This insight indicates the critical role of environmental regulations, technological advancements, and the enhancement of supply chain performance through AGPT. This study fills an important literature gap regarding cross-national cooperation for sustainable agriculture in developing countries by integrating behavioural, regulatory, and technological perspectives."
10.1007/s00202-024-02440-6,supervised,"In recent years, the utilization of wind turbines to harness wind power has experienced significant growth, driven by technological advancements and increasing emphasis on sustainability. Developing nations, including India, are strategically implementing wind power initiatives in regions characterized by high annual average wind speeds. However, due to the inherently unpredictable nature of meteorological variables, wind energy production lacks a predictable schedule. Consequently, the energy sector faces the challenge of accurately forecasting wind velocity to effectively manage and optimize wind electricity generation. This research aims at Andhra Pradesh, India, to see whether wind energy is feasible. This paper presents a multilayer perceptron-neural network (MLP-NN) forecasting model that utilizes machine learning. The model extracts features with the Harris Hawks Optimization-K-Nearest Neighbors (HHO-KNN) technique. By employing this strategy, open-access data gathering will be used to improve wind power predictions. As the result, the proposed model attains an accuracy of 97.0996%, a precision of 99.16731%, an F1 score of 97%, and a recall of 96%. According to the results, the Prakasam district has the most potential for producing wind energy. Even though the sites are small in comparison with larger-scale projects, they have the potential to produce considerable amounts of electricity. Strategic decisions in renewable energy planning are informed by this research, emphasizing the significance of sophisticated forecasting approaches for wind energy optimization."
10.11834/jrs.20210580,supervised,"All right reserved.Sustainable development goals such as food security, high-quality habitat construction, biodiversity conservation, planetary health, and the understanding, modeling, and management of the Earth system urgently require multi-scale, long time series, high-accuracy, and consistent remote sensing observation datasets and mapping products with flexible classification systems to meet user needs. However, due to technical and cost constraints, it is difficult for conventional remote sensing satellites to provide observations with high spatial resolution, high temporal frequency, and high quality at the same time. The existing mapping and inversion schemes are mostly for a single sensor, making it difficult to fully exploit and jointly utilize the information potential of multi-source heterogeneous remote sensing big data, resulting in limited observation periods and resolutions, low spatial and temporal consistency and comparability. Therefore, new technical paradigms are urgently needed in the field of remote sensing. In this paper, based on advanced technologies, including cloud computing, artificial intelligence, virtual constellation, spatio-temporal fusion reconstruction, an intelligent mapping framework is proposed for remote sensing big data. The framework is user-driven and problem-driven, which can significantly improve the current situation that remote sensing data products can hardly meet users' diversified and high-precision surface monitoring needs in agriculture and forestry management, national monitoring, ecological environment protection, disaster prevention and mitigation, urban planning, etc. Under this framework's guidance, we built an online real-time, automated, serverless, end-to-end remote sensing big data production chain and parallel mapping system based on Amazon Web Services (AWS) high-performance, elastic, and scalable distributed computing resources. We produced the first set of 21st century daily Seamless Data Cube (SDC) and seasonal to annual land cover and land use mapping products of China. Integrating Landsat and MODIS satellite as a virtual constellation, through multi-source spatio-temporal data fusion and reconstruction technology, the daily SDC, cloud-free, high-precision reflectance product, is developed. As Analysis Ready Data (ARD), it lays the foundation for high-precision quantitative remote sensing inversion and mapping. Based on SDC, we developed the seasonal to annual mapping product with multiple multi-level land cover and land use classification systems, whose mean annual accuracy exceeds 80%. The main mapping pipeline includes migrating the all-season sample set based on stable classification theory with limited samples, optimizing and ensembling multiple classifiers by Automatic Machine Learning (AutoML) strategies, and using change detection and post-processing techniques to achieve consistency. The two sets of products demonstrate the feasibility and effectiveness of the intelligent remote sensing mapping framework proposed in this paper. We will continue to improve and develop the framework with an open and flexible concept to provide new ideas to promote remote sensing development in China."
10.1080/0951192X.2023.2204469,supervised,"As the last production link, the diesel engine assembly process (DEAP) significantly impacts the quality consistency of diesel engine products. Therefore, the quality consistency improvement of DEAP has become an urgent problem for academia and industry. The challenge is how to mine the causal relationship in DEAP and establish a reliable quality prediction model. This paper attempts to describe DEAP using a causal relationship network (CRN) and to provide an effective data-based scheme for improving quality consistency by integrating CRN with support vector regression (SVR). First, a two-step CRN learning method is proposed for describing the DEAP. In the first step, the association relationship network is developed by a hybrid direct association detection method of the maximal information coefficient and network deconvolution, which can accurately measure the data relations. In the second step, the information geometric causal inference is employed to determine the direction of the edges in the association relationship network, thus forming the CRN of DEAP. Then, an integrated CRN-SVR approach is proposed to realize the predictive modeling of the critical quality indicators in DEAP, which integrated SVR into CRN. At the same time, it also provides a feasible idea for the interpretability of existing machine learning techniques. Finally, the proposed approach is tested and verified in a real-world DEAP and the obtained RMSE is only 0.033. The results of this study provide theoretical support and technical guarantee for quality consistency improvement in DEAP."
10.15488/9681,supervised,"The shop floor is a dynamic environment, where deviations to the production plan frequently occur. While there are many tools to support production planning, production control is left unsupported in handling disruptions. The production controller evaluates the deviations and selects the most suitable countermeasures based on his experience. The transparency should be increased in order to improve the decision quality of the production controller by providing meaningful information during his decision process. In this paper, we propose a framework in which an interactive production control system supports the controller in the identification of and reaction to disturbances on the shop floor. At the same time, the system is being improved and updated by the domain knowledge of the controller. The reference architecture consists of three main parts. The first part is the process mining platform, the second part is the machine learning subsystem that consists of a part for the classification of the disturbances and one part for recommending countermeasures to identified disturbances. The third part is the interactive user interface. Integrating the user’s feedback will enable an adaptation to the constantly changing constraints of production control. As an outlook for a technical realization, the design of the user interface and the way of interaction is presented. For the evaluation of our framework, we will use simulated event data of a sample production line. The implementation and test should result in higher production performance by reducing the downtime of the production and increase in its productivity."
10.1007/978-3-031-19639-3_4,supervised,"Innovative manufacturing processes allow the integration of billions of transistors into a single chip, and the implementation of extremely dense designs, but they also come with increased variability and new reliability threats. Both, new processes and more complex designs introduce a higher degree of indeterminism which challenges logic diagnosis and defect classification. Design techniques like selective hardening, fault masking, and error masking or adaptive voltage and frequency scaling (AVFS) increase reliability, but make test, diagnosis, and defect classification even more difficult. This chapter presents machine learning techniques for distinguishing variations from reliability threats due to defects, for identifying different defect types during diagnosis, and for distinguishing transient errors covered by hardening or masking from intermittent faults."
10.1007/978-3-031-09726-3_17,supervised,"As a powerful tool for regression prediction, Incremental Extreme Learning Machine (I-ELM) has good nonlinear approximation ability, but the original model has the problem that the uneven output weights distribution affects the generalization ability of the model. This paper proposes an Incremental Extreme Learning Machine method based on Attenuated Regularization Term (ARI-ELM). The proposed ARI-ELM adds attenuation regularization term in the iterative process of output weights, reduces the output weights of the hidden node in the early stage of the iteration and ensuring that the new nodes after multiple iterations are not affected by the large regularization coefficient. Therefore, the overall output weights of the network reach a relatively small and evenly distributed state, which would reduce the complexity of the model. This paper also proves that the model still has convergence performance after adding the attenuated regularization term. Simulation results on the benchmark data set demonstrate that our proposed approach has better generalization performance than other incremental extreme learning machine variants. In addition, this paper applies the algorithm to specific weight prediction scene of intelligent manufacturing dynamic scheduling, and also gets good results."
10.1109/ICSMC.2010.5642213,supervised,"Among manufacturing companies there is a wide-spread consensus that women are better suited to perform visual quality inspection, having higher endurance and making decisious with better reproducibility. Up to now gender-differences in visual inspection decision making have not been thoroughly investigated. We propose a machine learning approach to model male and female decisions with classifiers and base the analysis of gender-differences on the identified model parameters. A study with 50 male and 50 female subjects on a visual inspection task of stylized die-cast parts revealed significant gender-differences in the miss rate (p = 0.002), while differences in overall accuracy are not significant (p = 0.34). On a more detailed level, the application of classifier models shows gender differences are most prominent in the judgment of scratch lengths (p = 0.005). Our results suggest, that gender-differences in visual inspection are significant and that classifier-based modeling is a promising approach for analysis of these tasks. ©2010 IEEE."
10.1016/j.aei.2025.103267,supervised,"Existing research improves the performance of prediction models based on point data but neglects the value of interval data and model interpretability, resulting in suboptimal predictions. Hence, this study proposes an interval-valued forecasting system for non-ferrous metal prices via interpretable two-stage ensemble learning. An interval-valued data preprocessing module is designed to improve predictive ability and enhance modeling diversity in terms of data by introducing various interval-valued mapping strategies. To enhance the modeling diversity of the predictors, a meta-predictor module that incorporates four advanced deep-learning models that produce various sub-predictors is proposed. A two-stage ensemble learning module is developed to obtain final interval-valued non-ferrous metal prices based on all sub-predictors. In the first stage, based on temporal fusion transformers, different deep-learning models are combined to reduce the bias in individual predictors. In the second stage, based on an attention mechanism, different interval-valued mapping strategies are combined to improve forecasting performance. Multiple comparative experiments and analyses are conducted using real non-ferrous metal market data. In an empirical study, the proposed system achieved the best results. Taking a copper dataset as an example, the system results for the IMAPE, IRMSE, IARV, and UI were 0.57826 %, 62.51197, 0.02147, and 0.14651, respectively. The results show that the proposed system not only outperforms both individual and advanced ensemble models in terms of accuracy and robustness but also offers valuable interpretable insights for improving interval-valued forecasting power."
10.1002/ett.3947,supervised,"Cybersecurity is the domain that ensures safeness in both individual system and overall network systems. The classification and learning approaches used in different machine learning (ML) techniques improve the protection of the cyber systems against various attacks. Techniques such as support vector machine (SVM), neural networks (NN), principle component analysis (PCA), and reinforcement learning (RL) are used against various cyber threats. Applying these techniques at the front-end services (either online or offline) makes less effect than back end process-level services of any computer system. The proposed work analyzes the benefits of implementing customized ML and deep learning (DL) techniques on the core of the operating system than application level services, which in effect increases the speed and correctness of attack detection. The core (kernel) of the operating system has the capability to extract all internal attributes of process and file systems. The kernel space security activities can be improved by proposed work where the process level attributes classified using ML and DL techniques. The cloud service helps in sharing of the kernel abilities of the system ensuring core level security. The following work uses recurrent NN (RNN), SVM, PCA, and RL for analyzing the system data collected using Process Explorer. This technique finds application in manufacturing domain where the systems are protected from the various attacks to secure the data of the manufacturing company."
10.1016/j.renene.2023.01.113,supervised,"However, modeling the fuel ethanol batch fermentation process is still a critical task. The unstructured kinetic model (UKM) is often utilized to model the process, but it encounters two problems due to the large differences in initial glucose concentrations. First, the UKM has poor predictions of the yeast growth, which is a crucial production index. Second, the kinetic parameters of the UKM are time-varying because of the changing environmental conditions. The constant manually set kinetic parameters affect the prediction accuracy. To tackle the problems, we propose a dynamic hybrid model of the fuel ethanol fermentation process. First, a biomass concentration prediction model based on extreme gradient boosting is developed. It predicts the values of biomass concentrations and mycelium growth rate as supplementary mechanism knowledge. Then, we present an artificial neural network-based model to determine the time-varying kinetic parameters. Our model can accurately predict the time series of biomass, ethanol, and glucose concentrations, with RMSEs reaching 0.3323, 1.9295, and 3.0540. Experimental results show that the dynamic hybrid model performs with satisfactory accuracy in modeling the fuel ethanol fermentation process."
10.1007/978-3-031-73617-9_26,unsupervised,"As digital data continues to grow exponentially, the reliability of Hard Disk Drives (HDDs) becomes a critical concern for ensuring data integrity and preventing unexpected system downtimes. The research dataset contains historical SMART attribute data collected from HDDs, encompassing parameters such as spin-up time, temperature reallocated sector count and other relevant metrics. The study explored usage of various exploratory data analysis (EDA) & machine learning (ML) techniques for forecasting HDD failures. EDA techniques include Synthetic Minority Over-sampling Technique (SMOTE) algorithm for balancing class representation in training set and Principal Component Analysis (PCA) for dimensionality reduction. Diverse machine learning techniques, such as Random Forest (RF), Decision Tree (DT), K-nearest Neighbors (KNN), Gaussian Naïve Bayes (GNB), Adaptive Boosting (AdaBoost), XGBoost, Gradient Boosting (GB), Linear Discriminant Analysis (LDA), Logistic Regression (LR), are employed to predict the hard drive failure. Local Interpretable Model-agnostic Explanations (LIME) is employed to identify which features have the greatest influence on a specific prediction, providing insights into the factors driving the model’s decisions. Random Forest exhibited superior performance of accuracy 99.9 and F1 score 0.98 compared to other models."
10.1016/j.compchemeng.2025.109412,unsupervised,"To optimize resource use and minimize waste, it is essential to manage these supply chains effectively, especially in the face of uncertainty. This research addresses the crucial challenge of designing a sustainable closed-loop agricultural supply chain network, with a specific focus on jujube products in the context of temperature-yield uncertainty. The model enhances economic sustainability by minimizing costs, social sustainability through job creation requirements, and environmental sustainability by implementing carbon emission caps, while taking into account decisions regarding facility locations, inter-facility flows, inventory, and shortage management. Our main contribution is a distributionally robust optimization approach that integrates a K-means clustering machine learning algorithm to generate scenarios from historical data patterns, addressing the dynamic and interrelated uncertainties in temperature-yield data. The framework incorporates closed-loop principles through thermochemical conversion processes that transform agricultural waste into value-added biochar products. A comprehensive case study of the jujube industry in South Khorasan Province, Iran, validates the model's effectiveness. Results demonstrate that moderate conservatism levels (ω between 0.8 and 1.2) achieve an 88% reduction in operational risk variability while incurring only a 3% cost increase. A comparative analysis reveals that the proposed approach achieves a 0.95 risk-adjusted performance score, outperforming traditional stochastic programming and robust optimization alternatives. This research provides agricultural supply chain managers with practical guidelines for managing temperature-yield uncertainty."
10.1007/978-981-16-1941-0_35,unsupervised,"Anomaly detection is one of the very predominant activities in manufacturing and it has many practical applications, like scrap reduction, quality testing and compliance testing. Many machine learning applications are available for anomaly detection in the literature and they are performing a decently good job. In the current study, we are describing various applications of anomaly detection in manufacturing domains, like automotive, oil and gas, pharma and consumer goods, and also some of the latest methods available in the literature to perform anomaly detection. We also highlighted some of the gaps and future scope of work in anomaly detection topics."
10.1109/DSN-S52858.2021.00027,unsupervised,"Large-scale Internet services run on a fleet of distributed servers, and the continuous availability of the hardware is key to the robustness of the services. Unplanned reboots disrupt the services running on the hardware and lower the fleet availability. Server reboots are also important signals that could indicate underlying issues such as memory leaks from the services, catastrophic hardware failures, and network or power disruptions at the datacenters.In this paper, we present an at-scale, near-realtime reboot monitoring framework built with multiple state-of-The-Art data infrastructures, as well as machine learning-based anomaly detection and automated root cause analysis across hundreds of server attribute combinations. We observed that 1% of the reboots in our hardware fleet were associated with kernel panics and out-of-memory events, and these reboots exhibit strong locality temporally and across services."
10.1002/hcs2.90,unsupervised,"Health Care Science published by John Wiley & Sons Ltd on behalf of Tsinghua University Press.Introduction: Data clustering is an important field of machine learning that has applicability in wide areas, like, business analysis, manufacturing, energy, healthcare, traveling, and logistics. A variety of clustering applications have already been developed. Data clustering approaches based on self-organizing map (SOM) generally use the map dimensions (of the grid) ranging from 2 × 2 to 8 × 8 (4–64 neurons [microclusters]) without any explicit reason for using the particular dimension, and therefore optimized results are not obtained. These algorithms use some secondary approaches to map these microclusters into the lower dimension (actual number of clusters), like, 2, 3, or 4, as the case may be, based on the optimum number of clusters in the specific data set. The secondary approach, observed in most of the works, is not SOM and is an algorithm, like, cut tree or the other. Methods: In this work, the proposed approach will give an idea of how to select the most optimal higher dimension of SOM for the given data set, and this dimension is again clustered into the lower actual dimension. Primary and secondary, both utilize the SOM to cluster the data and discover that the weight matrix of the SOM is very meaningful. The optimized two-dimensional configuration of SOM is not the same for every data set, and this work also tries to discover this configuration. Results: The adjusted randomized index obtained on the Iris, Wine, Wisconsin diagnostic breast cancer, New Thyroid, Seeds, A1, Imbalance, Dermatology, Ecoli, and Ionosphere is, respectively, 0.7173, 0.9134, 0.7543, 0.8041, 0.7781, 0.8907, 0.8755, 0.7543, 0.5013, and 0.1728, which outperforms all other results available on the web and when no reduction of attributes is done in this work. Conclusions: It is found that SOM is superior to or on par with other clustering approaches, like, k-means or the other, and could be used successfully to cluster all types of data sets. Ten benchmark data sets from diverse domains like medical, biological, and chemical are tested in this work, including the synthetic data sets."
10.1155/2022/8031024,unsupervised,"This paper analyses the automatic control effect of an electronic controller, combined with artificial intelligence technology in order to improve the automatic control of an electronic controller. In order to improve the automatic control effect of the electronic controller, a novel centralized intelligent reflective surface-assisted millimeter-wave computational imaging scheme based on pixel block division and block sparse signal recovery is proposed in this paper. Meanwhile, this paper proposes a fast block-sparse Bayesian learning algorithm. It combines the GAMP algorithm with machine learning, so it can achieve similar performance with much lower computational complexity than the traditional block sparse Bayesian learning algorithm. The simulation clustering study shows that the electronic controller automation system based on artificial intelligence technology proposed in this paper can effectively improve the control effect of the electronic controller."
10.3390/polym17141910,unsupervised,"This research article examines the CO2 laser cutting performance of Fused Filament Fabricated Acrylonitrile Styrene Acrylate (ASA) thermoplastics by analyzing the influence of plate thickness, laser power, and cutting speed on four quality characteristics: surface roughness (Ra), top kerf width (Top KW), bottom kerf width (Bottom KW), and bottom heat-affected zone (Bottom HAZ). Forty-five experiments were conducted using five thickness levels, three power levels, and three cutting speeds. To model and predict these outputs, seven machine learning approaches were employed: Autoencoder, Autoencoder–Gated Recurrent Unit, Autoencoder–Long Short-Term Memory, Random Forest, Extreme Gradient Boosting (XGBoost), Support Vector Regression, and Linear Regression. Among them, XGBoost yielded the highest accuracy across all performance metrics. Analysis of Variance results revealed that Ra is mainly affected by plate thickness, Bottom KW by cutting speed, and Bottom HAZ by power, while Top KW is influenced by all three parameters. The study proposes an effective prediction framework using multi-output modeling and hybrid deep learning, offering a data-driven foundation for process optimization. The findings are expected to support intelligent manufacturing systems for real-time quality prediction and adaptive laser post-processing of engineering-grade thermoplastics such as ASA. This integrative approach also enables a deeper understanding of nonlinear dependencies in laser–material interactions."
10.21595/vp.2019.20617,unsupervised,"A wind turbine works under variable load and environmental conditions because of which failure rate has been on the rise. Failure of a gearbox, an integral part of producing wind energy, contributes to 80 % of the total downtime for the wind turbine. For ensuring better utilization of the wind turbines, Fault prognosis and condition monitoring of bearings are of utmost importance as it helps to reduce the downtime by early detection of faults which further increases the power output. In this paper, vibration signals produced and machine learning approach to determine the Remaining Useful Life (RUL) for a degraded bearing is studied. The methodology includes statistical feature extraction analysis with regression models. Further the feature selection is done using Principal Component Analysis (PCA) technique which produces training and testing sets which acts as an input parameter for regression models such as Support Vector Regressor (SVR) and Random Forest (RF). Weibull Hazard Rate Function is used for calculating the RUL of the bearing. Results This study shows the potential application of regression model as an effective tool for degradation performance prediction of bearing."
10.1016/j.cma.2024.117372,unsupervised,"V.Recent breakthroughs in advanced manufacturing capabilities have made it possible to design and print sophisticated topologies of cellular structures using diverse engineering materials such as metals, polymers, and ceramics. In these architectured materials, it is often desirable to tailor the mechanical properties by altering the unit cell topology. This necessitates an in-depth understanding of how the topology of the unit cell structure affects the macroscopic behavior of the material in both the linear and the non-linear regimes encountered under large compression. We have developed a machine learning (ML) approach capable of accelerating the prediction of the stress–strain response of a polymer-based cellular structure under uniaxial confined compression. As part of generating the training data for ML, 60,000 mesostructures were generated using a relatively novel approach based on cellular automata, and their corresponding stress–strain responses were obtained from the finite element simulations. Principal component analysis (PCA) was used to reduce the dimensionality of the stress–strain curves. With only 20 principal components, PCA captured 99.89% of the variance in the stress–strain curves while reducing the dimensionality by 5X. ML using supervised autoencoder was able to successfully speed up the prediction of the non-linear stress–strain response of a unit cell by up to 4600X. The proposed method can serve as an efficient data generation tool and a rapid means for predicting the structure–property relationship through accelerated forward modeling of cellular materials under compaction, in cases where the macroscopic stress–strain response is governed by the unit-cell topology."
10.4018/979-8-3693-7525-9.ch003,unsupervised,"Machine learning (ML) is driving change in aerospace design and manufacturing in order to increase efficiency, safety, and innovation. Complex designs and requirements required in aerospace industry. ML can improve design quality, support design thinking by generating multiple options, and enhance predictive analytics to detect potential problems. ML makes manufacturing processes smarter by predicting demand and managing resources effectively, increasing operational efficiency and improving product quality. ML helps to prevent errors and increase safety and security through predictive maintenance, non-destructive testing, and anomaly detection. ML can handle challenges such as data collection, interpreting in a safety-critical business context. ML offers great opportunities, from AI-powered innovation and human-machine collaboration to the potential impact of quantum computing in solving complex aerospace problems. Continued advances in machine learning will help to shape the future of aerospace, making machines more efficient, safer, and more innovative."
10.1109/MLSP55844.2023.10285973,unsupervised,"Time series classification is a fundamental task in many domains such as finance, healthcare, and manufacturing. Traditional machine learning techniques are limited in their ability to deal with the temporal nature of time series data, making representation learning an effective approach. Randomized machine learning is gaining interest as many cases it can outperform deep learning. However, it often requires many features, which can be an issue with high-dimensional training data and low-sample sizes. To address this issue, we propose a novel and efficient approach that utilizes a new and fast metric to evaluate features, called the Scatter Score (SS), and a new temporal-aware down-sampling strategy, called randomized threshold exceedance rate (rTER). Our method achieves significant improvements in classification performance compared to state-of-the-art methods such as ROCKET, miniROCKET, ResNet, and InceptionTime, as demonstrated on 30 different datasets."
10.1016/j.geoen.2025.213991,unsupervised,"However, the diversity of evaluation parameters limits hydraulic fracturing optimization. Therefore, we propose an adaptive-category-gaussian-mixture-model (AC-GMM) based on a geology engineering framework, combining reservoir quality (RQ) and completion quality (CQ) to classify the composite quality index (CQI). The classification serves as the basis for an intelligent algorithm developed for fracturing design. Taking three typical wells from the Lucaogou Formation in the Junggar Basin in China as examples the following research results are summarized. First, the AC-GMM model can finely identify the fracturing grades, achieving a conformity rate of over 90 % with the field production data. Second, the paper obtains three types of fracturing grades (I, II, III) and further refines them into four grades (I, II1, II2, III), the grade I considers both high RQ and CQ, while grade II only regards the better of the double quality, and prioritizes the better CQ. Third, the intelligent algorithm groups similar qualities into the same stage, achieving up to 96 % intra-stage homogeneity, significantly enhancing hydraulic fracturing efficiency for long horizontal wells. Our work provides a data-driven framework for optimizing multi-stage fracturing designs in shale reservoirs."
10.1109/BigData55660.2022.10020836,unsupervised,"Enabled by the increasing availability of sensor data monitored from production machinery, condition monitoring and predictive maintenance methods are key pillars for an efficient and robust manufacturing production cycle in the Industrial Internet of Things. The employment of machine learning models to detect and predict deteriorating behavior by analyzing a variety of data collected across several industrial environments shows promising results in recent works, yet also often requires transferring the sensor data to centralized servers located in the cloud. Moreover, although collaborating and sharing knowledge between industry sites yields large benefits, especially in the area of condition monitoring, it is often prohibited due to data privacy issues. To tackle this situation, we propose an Autoencoder-based Federated Learning method utilizing vibration sensor data from rotating machines, that allows for a distributed training on edge devices, located on-premise and close to the monitored machines. Preserving data privacy and at the same time exonerating possibly unreliable network connections of remote sites, our approach enables knowledge transfer across organizational boundaries, without sharing the monitored data. We conducted an evaluation utilizing two real-world datasets as well as multiple testbeds and the results indicate that our method enables a competitive performance compared to previous results, while significantly reducing the resource and network utilization."
10.1007/978-981-13-2375-1_63,unsupervised,"In the background of intelligent manufacturing, fault diagnosis is more and more important. In order to reduce the time and space cost of mass multidimensional data in machine learning fault diagnosis algorithm, a fault diagnosis framework based on DEMATEL and Support Vector Machine is proposed in this paper. DEMATEL algorithm can reduce the dimensions of data and Support Vector Machine can better solve the problem of multiple classification of small sample with non-linear feature and classify the fault data after dimensionality reduction. The framework proposed in this paper improves the efficiency of fault diagnosis effectively and ensures the further development of intelligent manufacturing."
10.1109/ICPHM57936.2023.10193957,unsupervised,"The detection of anomalies in printed circuit boards (PCBs) is an important challenge in the electronics manufacturing industry. Traditional anomaly detection methods often struggle to handle imbalanced datasets, which are common in real-world PCB production. In recent years, machine learning (ML) algorithms have emerged as a promising solution to this problem. This study investigates the use of ML algorithms for anomaly detection in PCBs, with a particular focus on addressing the issue of imbalanced data. We propose a data-level technique to balance the dataset and improve the performance of the ML algorithm. Our results show that our approach outperforms traditional methods in terms of precision, recall, and F1 score. Overall, this study demonstrates the potential of ML in addressing the challenge of anomaly detection in PCBs and highlights the importance of considering imbalanced data in such applications."
10.1109/TASE.2024.3486688,unsupervised,"Industrial environments pose distinctive challenges for anomaly detection, primarily stemming from the complexities associated with high dimensionality and the dynamic nature of data patterns over time. These properties determine that the model's proper convergence on unlabeled data is unpromising, consequently leading to less efficient discrimination of anomalies in previous anomaly detection (AD) works. To address this problem, we present AnoDual, a novel, meta-learning AD framework. From the perspective of data reconstruction, we introduce the multi-memory enhanced VAE reconstructor M2ER, which learns to extract the most salient patterns in unlabeled noisy data through a self-supervised manner. This design eases impacts from potential anomalous components during data reconstruction, and enhances the discernibility of anomalies. To address performance degradation caused by the numerical deviation based AD scheme in most existing works, we design a dual-source self-supervised discriminator DSD, which examines characteristics in the domain of representations. This model actively assesses discrepancies between data pairs and representation pairs in parallel, and conducts AD on a fine-grained scale. In this way, anomalies that used to be unnoticed due to a less prominent numerical deviation can be spotted. Besides, we propose a meta-learning powered training pipeline to enable model training even when no real label is available, which is common in the industry. Extensive experiments on five large-scale real-world industrial datasets suggest that AnoDual achieves an average F1-Score with a substantial increment of 3.39 %, outperforming the latest state-of-the-art baseline. Note to Practitioners - A generative model plus a numerical threshold based detection approach currently takes a significant share in both academia and the industry. However, the performance of this workflow is not promising in actual applications, with multiple factors contributing to this situation. The proper convergence of such generative models is difficult when the training material contains noisy samples - an over-expressed generative model would result in less significant reconstruction discrepancies for anomalies that are hard to notice. In addition, selecting a numerical threshold, which is used to spot anomalies, requires multiple laborious attempts, and can hardly adapt to an ever-changing pattern in industrial environments. These circumstances make it challenging to apply prior works in practical production, which, in turn, urges the need to develop an effective methodology to address the need for industrial anomaly detection. This manuscript includes a novel, meta-learning powered framework AnoDual, which is tailored for industrial scenarios. This framework discards the conventional design of comparing the reconstruction error numerically, but introduces a solution based on the differentiation of the representations. Besides, the multi-head attention enhanced variational autoencoder also leads to a much more pronounced discrepancy for anomalous samples, which benefits their successful detection. Providing a flexible and robust way to detect anomalies on deployed IoT assets, this work can be further transformed to serve applications in many other domains."
10.1016/j.egyr.2022.10.265,unsupervised,"Methane is an energy carrier and a critical component in the total biogas generated in a digestion process, thus necessitating more attention on the fraction of methane in the biogas yield. However, most previous studies in literature had focused on the volumetric yield of methane with little or no attention given to the fractional composition of methane in the total biogas produced. The deficiency of the classical technique in controlling the process parameters for optimal yield has motivated the need for machine learning-based techniques for modelling the methane fraction of biogas in a large-scale plant. In this study, a fuzzy c-mean (FCM)-clustered adaptive neuro-fuzzy inference system (ANFIS) was developed to model the methane fraction of biogas in an industrial-scale plant. The FCM clustering technique was preferred owing to its computational speed boost capability. The model was simulated using the control parameters of the algorithms while the optimal model was selected after testing their performance using relevant statistical metrics. The best model was obtained with ANFIS-FCM model with 8 clusters giving Root Mean Square Error (RMSE), Mean Absolute Deviation (MAD), Average Absolute Percentage Relative Error (AAPRE), Relative Mean Bias Error (rMBE) and correlation coefficient (R2) values of 3.156, 2.236, 3.015, 0.306, 0.978 respectively at the training phase and 4.936, 3.245, 3.456. 0.306, 0.956 respectively at the testing phase. The statistical metrics values obtained implied that FCM-ANFIS is a satisfactory model to predict methane fraction successfully."
10.2118/190128-ms,unsupervised,"History matching is performed to obtain reservoir models that reproduce the historical production data while adhering to available prior geologic knowledge and observed static data. In automated history matching workflows, prior models of reservoir properties are continuously updated to match the incoming production history. A challenging problem is to ensure that after applying updates to prior models, the resulting history matched models remain geologically consistent. This is particularly challenging in formations with complex connectivity patterns, e.g., fluvial meandering and curvilinear channels, where preserving the distinct shape and continuity of the underlying geologic features is non-trivial. In this work, we introduce a novel machine learning approach with the aim of preserving the main connectivity patterns of the prior reservoir models during history matching of complex geologic formations. We formulate the history matching problem by defining a feasible set of connectivity patterns that are described by a large number of model realizations. The feasible set encompasses the range of connectivity patterns of the expected geologic objects in the prescribed conceptual model by geologists. A supervised machine learning algorithm is then introduced to learn a mapping operator between any given model and its closest model in the feasible set. For this purpose, a learning dataset, i.e., a set of feature/label pairs, is constructed from the representative samples of the feasible set. The k-Nearest Neighbor (k-NN) classification algorithm is then applied to relate the local connectivity patterns in the feasible set that are closest to the patterns in a proposed model outside the feasible set. The learned mapping operator is invoked during history matching, where the misfit between model-predicted and observed historical production data is minimized while honoring the connectivity in the prior feasible set. The history matching is performed using a two-step alternating directions optimization algorithm, in which the first step implements a gradient-based continuous minimization procedure to decrease the data mismatch objective function while the second step maps the obtained solution from the first step onto the prior feasible set. History matching case studies in channelized reservoirs demonstrate that the proposed supervised learning approach can learn the complex geologic patterns in the feasible set and use them during history matching to preserve the feasible connectivity patterns. The results suggest that the proposed classification and clustering approach can facilitate patter-based history matching problems by learning geologic features from prior models and using them to impose geologic feasibility."
10.1109/IAI63275.2024.10730246,unsupervised,"Industrial and environmental challenges faced in injection moulding processes push manufacturing companies to embrace smart manufacturing and adopt machine learning to deal with anomaly detection. Challenges arisen from imbalanced dataset gives rise to the development of our novel hybrid classification method. A novel hybrid classification method for anomaly detection in injection moulding is proposed in this paper. The proposed method involves feature selection with K-Means Clustering to remove noise data prior to Multi-Layer Perceptron. Feature selection helps to reduce the high-dimension of the dataset. K-Means Clustering helps to remove noise data that will have similar patterns with data of another class label. Multi-Layer Perceptron is used to verify the training accuracy and to build train model. Real industrial dataset of injection moulding process from a local manufacturing company is used to demonstrate the effectiveness of the method in this paper. The proposed hybrid method outperforms other classical models such as Multi-Layer Perceptron (MLP), Decision Tree (DT) and CNN (Convolutional Neural Network). It successfully increases the failure detect rate and reduces false reject rate up to 90%."
10.1007/978-3-031-36024-4_40,unsupervised,"Mixed integer programming (MIP) is an extremely versatile subclass of mathematical optimization problems. Applications of MIP are ubiquitous in our world today, ranging from scheduling to network design to production planning. The standard approach in state-of-the-art commercial solvers is called branch-and-cut. The selection of these cuts is an integral part of the branch-and-cut process as high-quality cuts can greatly increase solving efficiency. Currently, cut selection is decided by heuristics that both require expert knowledge and lack generalizability. In this paper, we propose an efficient and highly generalizable cut selection scheme based on semi-supervised learning. First, we design a cut evaluation metric that labels cuts based on whether they are efficient or not. Then, we train a deep learning classification model with unsupervised pre-training as a ranking function for cuts. In our evaluation, the proposed model outperforms standard heuristics and is comparable to existing machine learning approaches. Furthermore, the model is shown to be generalizable over both problem size and problem class."
10.1117/12.2680317,unsupervised,"All rights reserved.An integrated system for processing sensor data has been developed based on novel variational autoencoder (VAE) algorithms with explainability that significantly eases analysis of sensor data. By continuously updating a generative model of the data, the system assists users with minimal artificial intelligence (AI) training or experience to perform data analysis. The system performs an extensive range of integrated machine learning (ML) tasks: anomaly detection, active learning, model-drift detection, synthetic data generation, semi-supervised classification, and counterfactual explanation generation. When the system is provided a data schema (map of Booleans, integers, reals, categories, time series, etc.) and data set, it automatically forms a preliminary generative model of the data. The construction of the system is modular, so new data types can be added as necessary. Counterfactually explainable anomaly detection is immediately performed via sparse gradient search. This informs the user how to interactively remove or repair bad records and/or begin labeling records of interest. The addition of labels to the data allows multi-class, semi-supervised, counterfactually explainable classification via the support vector machine embedded hyperplane algorithm (SVM-EH). Once some labels are added, active learning is used to assist further labeling by suggesting data elements that are highly likely to improve classification accuracy, significantly accelerating the labeling process by trading human effort for computational cycles. In production, the system detects when its training is becoming stale and requests retraining. Classification accuracy is demonstrated to be comparable to other deep learning systems on benchmark data sets."
10.1177/16878140211009015,unsupervised,"For automated robotic manufacturing, a key aspect of monitoring is the identification and segmentation of core actuation processes captured in sensor logs. Once segmented, the behavior of an industrial system during a particular actuation can be tracked to detect signs of degradation. This study presents a technique for performing such an analysis through a combination of machine learning techniques designed to work with an acoustic monitoring system. A spectrogram-based convolutional neural network (CNN) is first trained to identify and segment primary motion classes from acoustic data. Unsupervised clustering and feature-space analysis are then employed to further separate the data into motion sub-classes beyond the capabilities of the CNN. This approach was evaluated on acoustic recordings of a Selective Compliance Assembly Robot Arm (SCARA) system. The developed CNN performed primary robotic motion segmentation with a maximum actuation identification accuracy of 87% when compared to validation data. The unsupervised clustering process had mixed success in distinguishing more fine-grained motion sub-classes due to strong variances in signal energy for some sub-classes. Further refinement is required for improved segmentation accuracy as well as automatic feature generation. The application of this process for life-cycle system monitoring is discussed as well."
10.1080/0951192X.2023.2177747,unsupervised,"The emergence of the Internet of Things (IoT), cloud computing, cyber-physical systems, system integration, big data, and data analytics for Industry 4.0 have transformed the world of traditional manufacturing into an era of smart manufacturing (SM). Smart manufacturing’s central focus is to process real-time IoT data and leverage advanced analytical approaches to detect abnormal behaviors. Social smart manufacturing applies analytics tools to empower decision makers and minimize duplication by executing the repetitive data processing work more consistently and precisely than can be done by a human operator. In smart manufacturing, the majority of industrial data is imbalanced. However, most traditional machine learning algorithms tend to be biased toward the majority class and under-represent the minority class. This research proposes a model selection architecture to automate the procedure of preprocessing input data and selecting the best combination of algorithms for anomaly detection. This design will play an essential role in producing high-quality products and improving quality control and business processes in diverse applications including predictive maintenance and fault detection. The framework is transferrable to any smart manufacturing task in the supervised learning domain."
10.4271/2021-01-0366,unsupervised,"All Rights Reserved.The detection and evaluation of damage in composite materials components is one of the main concerns for automotive engineers. It is acknowledged that defects appeared in the manufacturing stage or due to the impact and/or fatigue loads can develop along the vehicle riding. To avoid an unexpected failure of structural components, engineers ask for cheap methodologies assessing the health state of composite parts by means of continuous monitoring. Non Destructive Technique (NDT) for the damage assessment of composite structures are nowadays common and accurate, but an on-line monitoring requires properties as low cost, small size and low power that do not belong to common NDT. The presence of a damage in composite materials, either due to fatigue cycling or low-energy impact, leads to progressive degradation of elastic moduli and strengths. Since there is a well-known relationship between the elastic modulus reduction and the amount of damage, the stiffness degradation can be used for the scope of detecting the position and the amount of damage that has taken place. Relying on these concepts, a novel strain-based damage sensing procedure is here proposed, that can identify damages in composite structures by processing strain measures from a distributed sensors network. To achieve this result a combined Machine Learning pipeline, composed by Principal Component Analysis (PCA) and One Class Support Vector Machine (OC-SVM) is proposed. First, PCA learns a linear transformation on the undamaged measurements to reduce the data dimensionality; secondly, OC-SVM trained to detect anomalies in the projected components. A cross-validation procedure is used to find the optimal pipeline configuration. The methodology is virtually tested on a carbon fiber suspension. The results suggest dropping the first components of the PCA to feed the classifier. In addition, results show the capability of the algorithm to detect anomalies in the component strain response."
10.1109/ACCESS.2021.3097116,unsupervised,"Nowadays, the anomaly detection of aluminum electrolysis cell is a big problem in the aluminum electrolysis industry. The problem of unbalanced time series samples is common in industrial applications. The number of samples under normal conditions is much larger than that under abnormal conditions. In the electrolytic aluminum industry, this problem is even more serious, it is very difficult to find abnormal samples in industrial production because experts do not have a clear criterion to judge abnormalities. In traditional machine learning algorithms, such as support vector machine (SVM) and convolutional neural network (CNN), it is difficult to obtain high classification accuracy on the problem of class imbalance, and these methods tend to be more biased towards positive samples. In recent years, generative adversarial network (GAN) has become more and more popular in the field of anomaly detection. However, these methods need to find the best mapping from the actual space to the latent space in the anomaly detection stage, and the optimization process may bring new errors and take a long time. In this article, we use the ability of GAN to model complex high-dimensional image distribution, and propose a self-adaption AAE-GAN network based on adaptive changes of input samples. This time series anomaly detection method converts multi-dimensional time series data into a two-dimensional matrix, and only normal samples are needed in the training process, which effectively solves the above problems. The method we proposed is to use encoder and decoder to constitute a generator and a discriminator. During the training process, the generator and the discriminator are trained jointly and confrontationally, so that the mapping ability of the encoder can be fully reflected. In the anomaly detection stage, we determine whether the sample is abnormal according to the size of the reconstruction difference. Experimental results show that the detection accuracy and speed of this method are very high."
10.1109/ICOIN53446.2022.9687205,unsupervised,"Anomaly detection has been recognized as an important research area in many industries such as Information Technology, manufacturing, finance, etc. Recently, diverse research for anomaly detection has been conducted utilizing current deep learning methods including machine learning algorithms. However, multivariate time-series anomaly detection can be challenging problems because of the imbalance of anomaly data and the complexity of multivariate. In this paper, we propose a SeqVAE-CNN model based on deep learning using an unsupervised approach. Our model combines Variational Autoencoder (VAE) with Convolutional Neural Networks (CNN) as utilizing Seq2Seq structure to capture temporal correlations and spatial features in multivariate time-series. To demonstrate the performance of our approaches, we evaluate our model on 8 datasets from various domains. The experimental results demonstrate that our model has better performance of anomaly detection than other models by recording the highest AUROC and F1 scores on six of the eight datasets."
10.1109/TSM.2017.2753251,unsupervised,"In this paper, we focus on yield analysis task where engineers identify the cause of failure from wafer failure map patterns and manufacturing histories. We organize yield analysis task into the following three stages, namely, failure map pattern monitoring, failure cause identification, and failure recurrence monitoring, and incorporate machine learning and data mining technologies into each stage to support engineers' work. The important point is that big data analysis enables comprehensive and long-term monitoring automation. We make use of fast and scalable methods of clustering and pattern mining and realize daily comprehensive monitoring with massive manufacturing data. We also apply deep learning, which has been an innovative core technology of machine learning in recent years, to classification of wafer failure map patterns, and explore its performance in detail. Finally, these machine learning and data mining techniques are integrated into an automated monitoring system with interfaces familiar to engineers to attain large yield enhancement."
10.1145/3195555.3195568,unsupervised,"Process models are an important tool for software engineers to produce reliable software within schedule and budget. Especially technically challenging domains like machine learning need a supportive process model to guide the developers and stakeholders during the development process. One major problem type of machine learning is anomaly detection. Its goal is to identify anomalous data points (outlier) between the normal data instances. Anomaly detection has a wide scope of applications in industrial and scientific areas. Detecting intruders in computer networks, distinguishing between cancerous and healthy tissue in medical images, cleaning data from disturbing outliers for further evaluation and many more. The cross-industry standard process for data mining (CRISP-DM) has been developed to support developers with all kinds of data mining applications. It describes a generic model of six phases that covers the whole development cycle. The generality of the CRISP-DM model is as much a strength as it is a weakness, since the particularities of different problem types like anomaly detection can not be addressed without making the model overly complex. There is a need for a more practical, specialised process model for anomaly detection applications. We demonstrate this issue and outline an approach towards a practical process model tailored to the development of anomaly detection systems."
10.3390/cryst14060501,unsupervised,"Crystallization plays a crucial role in defining the quality and functionality of products across various industries, including pharmaceutical, food and beverage, and chemical manufacturing. The process’s efficiency and outcome are significantly influenced by solute–solvent interactions, which determine the crystalline product’s purity, size, and morphology. These attributes, in turn, impact the product’s efficacy, safety, and consumer acceptance. Traditional methods of optimizing crystallization conditions are often empirical, time-consuming, and less adaptable to complex chemical systems. This research addresses these challenges by leveraging machine learning techniques to predict and optimize solute–solvent interactions, thereby enhancing crystallization outcomes. This review provides a novel approach to understanding and controlling crystallization processes by integrating supervised, unsupervised, and reinforcement learning models. Machine learning not only improves product the quality and manufacturing efficiency but also contributes to more sustainable industrial practices by minimizing waste and energy consumption."
10.1007/978-3-031-47715-7_34,unsupervised,"Wireless Sensor Networks (WSNs) have become increasingly valuable in various civil/military applications like industrial process control, civil engineering applications such as buildings’ structural strength monitoring, environmental monitoring, border intrusion, IoT (Internet of Things), and healthcare. However, the sensed data generated by WSNs is often noisy and unreliable, making it a challenge to detect and diagnose anomalies. Machine learning (ML) techniques have been widely used to address this problem by detecting and identifying unusual patterns in the sensed data. This survey paper provides an overview of the state-of-the-art applications of ML techniques for data anomaly detection in WSN domains. We first introduce the characteristics of WSNs and the challenges of anomaly detection in WSNs. Then, we review various ML techniques such as supervised, unsupervised, and semi-supervised learning that have been applied to WSN data anomaly detection. We also compare different ML-based approaches and their performance evaluation metrics. Finally, we discuss open research challenges and future directions for applying ML techniques in WSNs sensed data anomaly detection."
10.1016/j.ultras.2021.106550,unsupervised,"V.This paper aims at dealing with the dilemma of examining the existence of a defect in ultrasonic detection of coarse grain materials. In such cases, defect echoes can be drowned in a strong noise background resulting from intricate coarse grain scattering, that is, grain noise. To this end, we develop an innovative signal reconstruction methodology from polluted measurements which combines basic statistical analysis with a series of machine learning algorithms. The proposed methodology analyzes abundant information from numerous raw signals to distinguish the desired signal from grain noise, avoiding the limitation of information provided only by a single signal. The technique is achieved by collecting similar signals together through a clustering algorithm and subsequently inputting these similar signals to a denoising autoencoder to suppress the grain noise. It is successfully employed to ultrasonic signals obtained from an as-cast stainless steel specimen with coarse equiaxed grains, a stainless steel specimen with relatively homogeneous dendrite fabricated by additive manufacturing and a stainless steel weld with heterogeneous columnar grains having variation of grain sizes in various locations. The influence of material microstructure and probe frequency on denoising performance is investigated in detail. Based on this, the proposed methodology is applied to defect detection. Desired A-scan results and B-scan imaging are achieved by the proposed method, where defects are well revealed. The experimental results demonstrate the developed methodology has stable excellent performance and superior denoising capabilities for defect detection with respect to conventional techniques, especially in the case where the noise is almost the same as the desired signal."
10.1007/s11356-025-35914-6,unsupervised,"Urban reservoirs are frequently exposed to impacts from high population density, polluting activities, and the absence of environmental control measures and monitoring. In this study, we investigated the use of satellite imagery to assess restoration measures and support decision-making in a hypereutrophic urban reservoir. Since 2016, Lake Pampulha (Brazil) has undergone restoration measures, including the application of Phoslock®, to mitigate its poor water quality conditions. Satellite images from Landsat-8 (L8) and Sentinel-2 (S2) and historical monitoring data were used to estimate total suspended matter (TSM), chlorophyll-a (Chla), and Secchi disk depth (SDD). We explored both established models from existing literature and novel alternatives, the latter employing machine learning approaches. Model performance was assessed through the coefficient of determination (R2) during calibration and using the root mean square error (RMSE) and its normalization by the observed mean (nRMSE) during validation. Random forest regressor presented superior performance for the three water quality parameters and both satellites. The performance metrics for Landsat-8 were TSM (n=44) R2 of 0.62; Chla (n=48) R2 of 0.74; and SDD (n=23) R2 of 0.67. For Sentinel-2, TSM (n=53) R2 of 0.72; Chla (n=54) R2 of 0.64; SDD (n=33) R2 of 0.89. The selected models were then applied to cloud-free images from 2013 to 2022 to provide modeled TSM, Chla, and SDD values. These were used for spatiotemporal analysis, encompassing cluster analysis, sample comparisons, and trend analysis. Three distinct regions within Lake Pampulha were identified, with the upstream region displaying poorer conditions for TSM, Chla, and SDD. Restoration measures have contributed positively to improving water quality in Lake Pampulha; however, rainy periods pose a challenge due to water quality deterioration associated with urban runoff. Remote sensing has proven to be a robust tool for assisting managers in assessing recovery measures in urban lakes."
10.1145/3613424.3614281,unsupervised,"Thanks to the mature manufacturing techniques, flash-based solid-state drives (SSDs) are highly customizable for applications today, which brings opportunities to further improve their storage performance and resource utilization. However, the SSD efficiency is usually determined by many hardware parameters, making it hard for developers to manually tune them and determine the optimized SSD hardware configurations. In this paper, we present an automated learning-based SSD hardware configuration framework, named AutoBlox, that utilizes both supervised and unsupervised machine learning (ML) techniques to drive the tuning of hardware configurations for SSDs. AutoBlox automatically extracts the unique access patterns of a new workload using its block I/O traces, maps the workload to previous workloads for utilizing the learned experiences, and recommends an optimized SSD configuration based on the validated storage performance. AutoBlox accelerates the development of new SSD devices by automating the hardware parameter configurations and reducing the manual efforts. We develop AutoBlox with simple yet effective learning algorithms that can run efficiently on multi-core CPUs. Given a target storage workload, our evaluation shows that AutoBlox can deliver an optimized SSD configuration that can improve the performance of the target workload by 1.30 × on average, compared to commodity SSDs, while satisfying specified constraints such as SSD capacity, device interfaces, and power budget. And this configuration will maximize the performance improvement for both target workloads and non-target workloads."
10.1007/s00170-021-07364-0,unsupervised,", part of Springer Nature.There is an urgent demand for free-form products in industry at the present time because of their superior appearance and the wide variety of functions they perform. Five-axis high-speed CNC machining technology has developed to satisfy this demand, but further improvement in surface quality metric inspection technology is the big challenge it now faces. In this study, the effects of jerk on the performance of five-axis synchronous high-speed CNC ball nose end mills on a freeform turbine mold were investigated. The relationships of characteristics of the images of 14 jerk-cluster finished workpieces with different jerk setting values were established, allowing surface texture features to be analyzed and surface roughness predicted. In addition, machine learning methods were integrated with the surface feature analysis to construct a virtual machining module that acts as a performance prediction system, merging the virtual machine tool functions, surface texture processor, and AI roughness prediction processor. Using the geometric information of the workpiece, cutting parameters and machine tool parameters as inputs, product performance metrics combining surface roughness and machining time can be predicted as outputs of the system. The integrated system provides users with a way to evaluate manufacturing performance before performing actual operations and to reduce test time for cutting parameter development. The model is suitable for complex surface finishes as well as for the production of small batches with high parametric variance. In addition, the partial set of image processing and roughness prediction modules can be used alone as an effective intelligent surface quality inspection system."
10.1016/j.jclepro.2025.145851,unsupervised,"River basins, where industrial activity often spans administrative boundaries, provide a distinctive setting for examining these externalities amid growing pressures for decarbonization. Focusing on the Dongting Lake Basin from 2012 to 2022, this study investigated the spatiotemporal coupling between the agglomeration of seven types of manufacturing industries and carbon emissions. The Extreme Gradient Boosting model was used to evaluate the intensity of agglomeration externalities across different forms. SHAP values quantified the contributions and interactions of key drivers, while the Geoshapley model captured the moderating effects of spatial factors. Results show that IA does not inherently reduce CO2 emissions; rather, the clustering of resource-intensive industries significantly exacerbates them. However, spatial spillovers, environmental regulations, and inter-industry coordination help mitigate these adverse effects. The impact of agglomeration externalities varies across the basin: upstream areas are dominated by resource-intensive industries, whereas downstream regions increasingly depend on technology- and labor-intensive sectors. These findings support the Porter Hypothesis and highlight the need for basin-specific, heterogeneity-sensitive environmental policies to optimize both economic and environmental outcomes."
10.1007/978-981-97-9559-8_19,unsupervised,"2025.Deploying structural control devices based on machine learning is a significant advancement for infrastructure management. Such systems, capable of combining IoT and artificial intelligence, make it possible to detect and deal with various structural incidents on time. Machine learning plays an important role, as it analyzes data from sensors placed on the structure, such as vibration, acceleration, and temperature. Its ability to continuously learn over time from the data allows the device to identify faults increasingly effectively. This enables effective predictive maintenance, which reduces costs and increases safety. Several data analysis tools exploit various machine learning techniques. Starting with data from accelerometers, the study compares different unsupervised methods and their effectiveness."
10.1038/s41529-025-00635-1,unsupervised,"Corrosion poses a substantial economic burden, and machine learning is increasingly being explored for its potential in staging, predictive maintenance, and data-driven decision making. This study presents an unsupervised automated corrosion staging method based on image processing and machine learning using optical microscopy (OM) images. It detects and computes (i) the local porosity in a neighborhood of 5 μm Ã- 5 μm at pore locations, and (ii) the deposit thickness in (μm). The local porosity and deposit thickness were used to estimate the chloride concentration factor, associated pH, and the corrosion stage. The approach was tested on 48 ex-service OM images of under-deposit corrosion (UDC). A thickness-based approach yielded an accuracy of ~73% in classifying the corrosion stage in UDC compared to previous time-consuming approaches. This is a significant step in automating the evaluation of the corrosion stage, enabling scalable data-driven corrosion assessment across critical infrastructures."
10.1145/3708821.3733874,unsupervised,"Hardware Trojans (HTs) are malicious circuits covertly embedded in hardware, similar to software backdoors, that can cause malfunctions or leak confidential information when activated. Detecting and localizing these HTs is critical, especially in sensitive systems like weaponry, where they pose significant security threats. Traditional detection methods often rely on side-channel analysis, which requires specialized equipment and expertise, making them costly and limited to post-manufacturing stages. Localization is crucial because merely detecting an HT does not allow for effective neutralization. Pinpointing the exact location helps in assessing the impact, facilitating targeted removal, and avoiding costly hardware redesigns. In critical applications like military systems, this minimizes the risk of security breaches that could compromise the entire system. This paper proposes a novel method for HT detection and localization using a Graph Autoencoder (GAE). Unlike existing techniques, our approach utilizes the structural information in Data Flow Graphs (DFGs) to identify HTs without the need for labeled datasets or manual feature engineering. By training solely on the Golden Model (GM) of the hardware design, the GAE captures the circuit's normal structural patterns. Our method analyzes the reconstruction error of each node in the GAE to not only detect the presence of HTs but also accurately pinpoint their insertion points within the hardware design. Experimental results show that our method outperforms existing approaches across various benchmarks, achieving high detection accuracy. It also offers practical advantages by avoiding the need for additional equipment or HT data during training, making it a feasible solution for early HT detection and mitigation in hardware systems."
10.2118/214459-MS,unsupervised,"Copyright © 2023, Society of Petroleum Engineers.Artificial Intelligence (AI) has significant potential to optimize practices, processes, and energy consumption along with maximizing yield, quality, and uptime. This has substantial impact on putting organizations on the path to net-zero, as such optimizations can reduce greenhouse gas emissions by 20% with minimal capital investments. This comprehensive study presents proven industrial case studies that delivered economically strong strategies coupled with sustainability practice and providing strategic insights to identify, manage and/or attenuate the associated impacts. Environomics presented in this study is a novel framework which deals with unifying economic strategies with sustainability practices (through artificial intelligence) for optimal business performance in terms of finances but also environmental impact. This is achieved through a track, trace, and optimize approach for resources (particularly emissions, energy, water, waste, materials, and safety) This was achieved through a combination of AI methods such as unsupervised machine learning, multivariate optimization, and the implementation of similarity measures. A few of the inputs included well data (including production data, drilling data, completion data etc.), logistics/supply chain data (scheduling data, production inventory, mobilization data etc.), safety data (near-miss, observations, hazards, disciplines and insights etc.) with associated costs and emission data. Multiple industrial case studies are presented where sustainability metrics are identified through validated AI models to optimize productivity while reducing emissions and inventory. For instance, well profiling can be used to identify historical parameters that have maximized production potential while optimizing for aspects such as cost or emissions. Furthermore, we can identify the optimal completion parameters for a new well which satisfies carbon targets, use well profiles to build an optimized drilling schedule that meets budget or production criteria while still achieving production targets and optimizing drilling rig routes. Thus, the approach can quickly (within run time) solve interrelated environomic challenges in the reservoir studies space and the field development space. Further case studies indicate that the supply chain can have immense optimization impact on scope 3 aspects with results indicating 30-50% asset utilization improvement with respect to fleets (Vessel, Truck, Rigs). With respect to materials, a 10-20% reduction of material inventory levels all improved through AI. As the workforce are also part of the environment it has been observed that identifying unsafe behaviors within a large operation, also leads to enhanced sustainability behaviors. The models indicate potential of overall emission reduction ranging from 12-20%. This led to the comprehensive framework presented in this study to support sustainable practices that are also economically feasible and deployable. The real-time sustainability metrics generated has immense values in terms of decision-making processes and scenario generation in a fraction of the time that is required using traditional approaches. In addition to assessing the scope of impact, a novel multidisciplinary study and framework is presented to analyze environomic strategies to propose a market-oriented approach through the application of artificial intelligence. Furthermore, industrial, and academic case studies have been evaluated to identify, predict, and optimize the crucial parameters within such workflows that are effective in reducing resources utilized and associated emissions."
10.1016/j.indcrop.2025.121110,unsupervised,"It is effective to fuse multi-source remote sensing data to predict crop yields, but difficult to reveal the effects of physiological processes on yield estimation models, and challenging to guide crop field production and management. In this study, an innovative framework was introduced to construct plant height (PH) and leaf chlorophyll content (LCC) inversion models for UAV LiDAR and multispectral data through different strategies. PH and LCC, two key growth features affecting cotton yield, were evaluated using multiple linear regression (MLR), partial least squares regression (PLSR), and extreme gradient boosting (XGBoost) algorithms for single-feature and multi-feature fusion, respectively. The multi-feature fusion model based on the XGBoost algorithm was significantly better than the single-feature model (R²=0.744). Further optimization of the multi-feature fusion model revealed that multi-temporal growth features as input variables significantly improved the accuracy of the multi-feature fusion model compared with that based on single-temporal (R²=0.802). Shapley additive explanations (SHAP) analysis revealed the key contribution of LCC to yield formation at the flowering and boll development stage in different cotton varieties. Cluster analysis confirmed that the dynamic trends of PH and LCC were closely related to yield, indicating that PH and LCC could be used as a bridge between remote sensing data and yield. This study highlights the value of UAV-based multi-dimensional and multi-temporal data fusion of growth features in yield estimation models, enabling a deeper understanding of yield formation mechanisms and providing novel methodological tools for phenomics research and precision agriculture management."
10.1007/978-981-99-5974-7_1,unsupervised,"With the advent of 5G globally, large volumes of data are available in digital form across multiple sectors. Sales, production, marketing, medical, manufacturing, and many more sectors dish out voluminous data that are used for decision-making by policymakers. In real time, many attributes are irreverent and not so significant which leads to the concept of dimensionality reduction of the data obtained. Linear Discriminant Analysis (LDA) and Principal Component Analysis (PCA) are the possible dimensionality reduction methods on popular machine learning algorithms. Missing value ratio, low variance filter, ensemble trees, etc., are various techniques for feature selection in this context. Agent-based algorithm is proposed for feature and instance dimensions’ data reduction. The obtained results are evident that the experiments perform well when datasets are huge. Dimensionality reduction may be irrelevant for smaller datasets. PCA provides better performance results over LDA. Further, it is found that the performance of the method developed using a reduced dataset is favorable over other techniques."
10.1109/CCGridW65158.2025.00045,unsupervised,"Cloud analytics extends the capabilities of identifying patterns, making predictions, and obtaining business intelligence (BI) insights, enabling organisations to work with massive amounts of complex business data using algorithms and cloud technologies. This type of analysis often involves artificial intelligence (AI), in the form of machine learning (ML) or deep learning (DL) models. Although concerns have been raised about the environmental impact of artificial intelligence and cloud computing, it is widely recognised that these technologies have the potential to support greater sustainability in several fields, including construction, transportation, healthcare, manufacturing, agriculture and water. This work extends our software framework for Ubiquitous Computing as a Service. The framework uses containerisation, low-code platforms, modularity, parallel computing, MQTT, and API to support the creation, configuration, operation, and modification of remote software. In this work, some degree of integration with cloud analytics is added, making it possible to create and populate AWS Redshift tables, train clustering models, and use such models, from containerised software components created and managed through the framework. All software artefacts produced in this work are available on GitHub, including a Postman collection of API requests for demo purposes."
10.1016/j.cie.2025.111453,unsupervised,"Probe cards, composed of printed circuit boards (PCBs), serve as the interface between fabricated wafers and probing equipment. As IC feature sizes shrink, maintaining data integrity during wafer probing becomes increasingly challenging. However, full inspection of all signal channels on probe card PCBs is often impractical due to time and cost constraints. As a result, selective channel inspection is commonly employed in practice. Focusing on realistic needs, this study proposes the UNISON decision framework to support effective inspection of PCB channels. The framework further enables the prediction of unmeasured channels, ensuring inspection quality and enhancing information coverage for advanced quality control. In particular, the framework integrates a Denoising Variational Autoencoder (DVAE)-based forecasting model for unmeasured channels and a simulation module to explore trade-offs between prediction accuracy and inspection time. An empirical study was conducted at a leading semiconductor testing company to validate the framework. The proposed DVAE-based imputation method was benchmarked against eight baseline approaches: four statistical methods (mean imputation, linear interpolation, multivariate linear regression, and MICE) and four machine learning models (K-Nearest Neighbors, Random Forest, MissForest, and XGBoost). Across all evaluation metrics—Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Euclidean distance—the proposed method consistently outperformed the baselines. These results demonstrate the practical viability and robustness of the developed framework in improving decision quality for selective PCB channel inspection in smart semiconductor manufacturing."
10.1080/01431161.2019.1706112,unsupervised,"Rice is the most important food crop in the world, which is meaningful to ensure the quality and quantity of rice production. During the plantation process, weeds are the key factor to influence the rice yields. In recent years, the chemical control becomes the most widely used means to control the weed infestation because of its advantage in pesticide effects and efficiency. However, excessive use of herbicides has caused negative effects on the rice quality as well as the environment. An accurate weed cover map can provide support information for specific site weed management (SSWM) applications, which may well address the problem of traditional chemical controls. In this work, the unmanned aerial vehicle (UAV) imagery was captured on four different dates over two different rice fields. Object-based image analysis (OBIA) and deep learning approaches were applied to the weed mapping task of the UAV imagery. For the OBIA methods, the multiresolution segmentation and an improved k-means method were applied to segment the imagery into different objects; the colour and texture features were extracted and concatenated into a feature vector; back propagation (BP) neural network, support vector machine (SVM) and random forest were used for classification. After careful hyperparameter optimization and model selection, it was proven that the OBIA method achieved the accuracy of 66.6% mean intersection over union (MIU) on the testing set, and the inference speed is 2343.5 ms for an image sample. For the deep learning approach, the fully convolutional network (FCN) was applied for the pixel-wise classification task; transfer learning was used, and four pretrained convolutional neural networks (AlexNet, VGGNet, GoogLeNet, and ResNet) were transferred to our dataset via fine-tuning technique. Traditional skip architecture and fully connected conditional random fields (CRF) were used to improve the spatial details of FCN; after that, this work proposed to use a partially connected CRF as post processing, which may significantly accelerate the inference speed of fully connected CRF. Besides one single improvement method, hybrid improvement methods were applied and tested. Experimental results showed that the VGGNet-based FCN achieved the highest accuracy; for the improvement methods, the skip architecture and newly proposed partially connected CRF effectively improved the accuracy, and the hybrid improvement method (skip architecture and partially connected CRF) further improved the performance. The hybrid improvement method achieved 80.2% MIU on the testing set, and the inference speed for an image sample is 326.8 ms. The experimental results of this work demonstrated that the UAV remote-sensing utilizing deep learning method can provide reliable support information for SSWM applications in rice fields."
10.1109/BigData.2017.8258085,unsupervised,"Self-Organizing Networks (SON) is an automation technology making the planning, deployment, operation, optimization, and healing of networks simpler and faster. Legacy SON is targeted at network automation and network optimization through certain optimization rules and policies which are globally applied in networks. However, scalable and targeted optimization is not considered yet in 3GPP. Furthermore, SON is driven by performance optimization rather than ultimately improving user Quality of Experience (QoE). The impact of application characteristics on network performance and further on QoE are also not considered in 3GPP SON. This paper presents an application characteristics-driven SON system (APP-SON) to optimize 4G/5G network performance and user Quality of Experience. APP-SON leverages a scalable big data platform for targeted optimization through profiling cell application characteristics in an incremental manner in temporal space. A Hungarian Algorithm Assisted Clustering (HAAC) algorithm and a deep learning-assisted regression algorithm are developed to profile the cell application characteristics and find the targeted KPIs to be optimized for each cell. A similarity-based, parametertuning algorithm is developed to tune the corresponding engineering parameters to optimize the targeted KPIs which further improve QoE. Experimental results demonstrate that the APP-SON system can precisely profile cell traffic and application characteristics to find the targeted KPIs for optimization for each cell. APP-SON can also automatically tune the corresponding engineering parameters to improve the corresponding KPIs, ultimately improving QoE. APP-SON has been successfully implemented in production and applied in a tier-1 operator's 4G network and as a universal SON solution it will be smoothly transitioned and applied in 5G networks for this operator."
10.2118/225238-MS,unsupervised,"Copyright 2025, Society of Petroleum Engineers.This paper outlines an innovative project being deployed in ADNOC. Neuron 5 Project empowers ADNOC in making faster and more effective decisions, leading to safer, more efficient, and profitable operations. It tackles the challenge of monitoring the health of thousands of pieces of critical equipment essential for production. Neuron 5 leverages on digital technologies and artificial intelligence to generate value through End-to-End performance prediction and aggregation of data into proactive autonomous actions. This Project is transforming the industry by delivering a centralized corporate solution enabling autonomous operations and enhanced asset reliability and integrity. The use of artificial intelligence and deep machine learning, combined with first principal models disrupts the nature of operations to achieve optimal production throughput. It autonomously predicts deterioration in critical equipment and reacts upon it. Neuron 5 also predicts anomalies and initiates proactive actions to prevent unexpected failures or shutdowns. It ensures equipment integrity and safety by leveraging anomaly detection, diagnostics and forecasting, performance monitoring as well as production, energy and emission optimization. The deployment of Neuron 5 is phased out with a planned total deployment in 2027 aiming to cover 50,000 assets. However, from the deployment in ADNOC Onshore and ADNOC Gas, which covered 1,200 assets under Phase 1, various tangible results were observed. Neuron 5 enabled autonomous production optimization which resulted in elimination of unplanned shutdowns by 50%, controlled energy and power efficiency, controlled emissions along with Assets Digital Twins. The deployment led to anomaly detection, enhanced performance of equipment with an increase in efficiency and value creation. The project provides diagnostics analysis and forecasting plans in addition to the benefits below: • Performance monitoring • Production, Energy and Emission Optimization • Standardized Asset Hierarchy • Contextualized Visualization Platform • Action Management & Knowledge Repository Neuron 5 is a transformative project that is creating disruptive change in the industry. It resulted in many tangible benefits and reduced the shutdown time by 50%. It delivers a centralized corporate solution enabling autonomous operations and enhanced asset reliability and integrity. Neuron 5 leveraging artificial intelligence and deep machine learning to empower facilities with artificial consciousness in order to autonomously aggregate data into proactive actions."
10.1016/j.phytochem.2017.05.003,unsupervised,"Despite the popularity of hawthorn as a dietary supplement, relatively little is known about the comparative phytochemistry of different hawthorn species, and in particular North American hawthorns. The combination of NMR spectrometry with chemometric analyses offers an innovative approach to differentiating hawthorn species and exploring the phytochemistry. Two European and two North American species, harvested from a farm trial in late summer 2008, were analyzed by standard 1D 1H and J-resolved (JRES) experiments. The data were preprocessed and modelled by principal component analysis (PCA). A supervised model was then generated by partial least squares-discriminant analysis (PLS-DA) for classification and evaluated by cross validation. Supervised random forests models were constructed from the dataset to explore the potential of machine learning for identification of unique patterns across species. 1D 1H NMR data yielded increased differentiation over the JRES data. The random forests results correlated with PLS-DA results and outperformed PLS-DA in classification accuracy. In all of these analyses differentiation of the Crataegus spp. was best achieved by focusing on the NMR spectral region that contains signals unique to plant phenolic compounds. Identification of potentially significant metabolites for differentiation between species was approached using univariate techniques including significance analysis of microarrays and Kruskall-Wallis tests."
10.1109/BigData.2015.7363874,unsupervised,"Data is increasingly affecting the automotive industry, from vehicle development, to manufacturing and service processes, to online services centered around the connected vehicle. Connected, mobile and Internet of Things devices and machines generate immense amounts of sensor data. The ability to process and analyze this data to extract insights and knowledge that enable intelligent services, new ways to understand business problems, improvements of processes and decisions, is a critical capability. Hadoop is a scalable platform for compute and storage and emerged as de-facto standard for Big Data processing at Internet companies and in the scientific community. However, there is a lack of understanding of how and for what use cases these new Hadoop capabilities can be efficiently used to augment automotive applications and systems. This paper surveys use cases and applications for deploying Hadoop in the automotive industry. Over the years a rich ecosystem emerged around Hadoop comprising tools for parallel, in-memory and stream processing (most notable MapReduce and Spark), SQL and NOSQL engines (Hive, HBase), and machine learning (Mahout, MLlib). It is critical to develop an understanding of automotive applications and their characteristics and requirements for data discovery, integration, exploration and analytics. We then map these requirements to a confined technical architecture consisting of core Hadoop services and libraries for data ingest, processing and analytics. The objective of this paper is to address questions, such as: What applications and datasets are suitable for Hadoop? How can a diverse set of frameworks and tools be managed on multi-tenant Hadoop cluster? How do these tools integrate with existing relational data management systems? How can enterprise security requirements be addressed? What are the performance characteristics of these tools for real-world automotive applications? To address the last question, we utilize a standard benchmark (TPCx-HS), and two application benchmarks (SQL and machine learning) that operate on a dataset of multiple Terabytes and billions of rows."
10.1145/3592149.3592161,unsupervised,"O-RAN is radically shifting how cellular networks are designed, deployed and optimized through network programmability, disaggregation, and virtualization. Specifically, RAN Intelligent Controllers (RICs) can orchestrate and optimize the Radio Access Network (RAN) operations, allowing fine-grained control over the network. RICs provide new approaches and solutions for classical use cases such as on-demand traffic steering, anomaly detection, and Quality of Service (QoS) management, with an optimization that can target single User Equipments (UEs), slices, cells, or entire base stations. Such control can leverage data-driven approaches, which rely on the O-RAN open interfaces to combine large-scale collection of RAN Key Performance Measurements (KPMs) and state-of-The-Art Machine Learning (ML) routines executed in the RICs. While this comes with the potential to enable intelligent, programmable RANs, there are still significant challenges to be faced, primarily related to data collection at scale, development and testing of custom control logic for the RICs, and availability of Open RAN simulation and experimental tools for the research and development communities. To address this, we introduce ns-O-RAN, a software integration between a real-world near-real-Time RIC and an ns-3 simulated RAN which provides a platform for researchers and telco operators to build, test and integrate xApps. ns-O-RAN extends a popular Open RAN experimental framework (OpenRAN Gym) with simulation capabilities that enable the generation of realistic datasets without the need for experimental infrastructure. We implement it as a new open-source ns-3 module that uses the E2 interface to connect different simulated 5G base stations with the RIC, enabling the exchange of E2 messages and RAN KPMs to be consumed by standard xApps. Furthermore, we test ns-O-RAN with the O-RAN Software Community (OSC) and OpenRAN Gym RICs, simplifying the onboarding from a test environment to production with real telecom hardware controlled without major reconfigurations required. ns-O-RAN is open source and publicly available, together with quick-start tutorials and documentation."
10.3390/su16093552,unsupervised,"Background: This paper examines scientific papers in the field of digital twins to explore the different areas of application in supply chains. Methods: Using a machine learning-based topic modeling approach, this study aims to provide insights into the key areas of supply chain management that benefit from digital twin capabilities. Results: The research findings highlight key priorities in the areas of infrastructure, construction, business, technology, manufacturing, blockchain, and agriculture, providing a comprehensive perspective. Conclusions: Our research findings confirm several recommendations. First, the machine learning-based model identifies new areas that are not addressed in the human review results. Second, while the human review results put more emphasis on practicality, such as management activities, processes, and methods, the machine learning results pay more attention to macro perspectives, such as infrastructure, technology, and business. Third, the machine learning-based model is able to extract more granular information; for example, it identifies core technologies beyond digital twins, including AI/reinforcement learning, picking robots, cybersecurity, 5G networks, the physical internet, additive manufacturing, and cloud manufacturing."
10.22399/ijcesen.1099,reinforcement,"The rapid advancements in Industry 4.0 and smart manufacturing systems have necessitated the integration of Artificial Intelligence (AI) and Digital Twin Technology (DTT) to enhance operational efficiency and predictive maintenance strategies. This study proposes an AI-driven predictive maintenance framework that leverages Digital Twin Technology to enable real-time monitoring, fault diagnosis, and failure prediction in industrial environments. The framework integrates machine learning (ML) models, deep learning techniques, and edge computing to analyze sensor data, detect anomalies, and optimize maintenance schedules. A reinforcement learning-based decision model is employed to dynamically adjust maintenance strategies, reducing downtime and extending equipment lifespan. Additionally, physics-informed AI models are incorporated into the digital twin architecture to simulate operational behaviours and predict potential failures with high accuracy. The proposed system is validated through a case study in a smart manufacturing plant, demonstrating a 35% improvement in predictive accuracy, 40% reduction in unplanned downtimes, and 25% optimization in maintenance costs compared to traditional predictive maintenance approaches. The findings indicate that the integration of AI and DTT significantly enhances the reliability and efficiency of cyber-physical manufacturing systems (CPMS), paving the way for more autonomous and intelligent industrial operations."
10.1080/00207543.2021.1973138,reinforcement,"Published by Informa UK Limited, trading as Taylor & Francis Group.Shortening product development cycles and fully customisable products pose major challenges for production systems. These not only have to cope with an increased product diversity but also enable high throughputs and provide a high adaptability and robustness to process variations and unforeseen incidents. To overcome these challenges, deep Reinforcement Learning (RL) has been increasingly applied for the optimisation of production systems. Unlike other machine learning methods, deep RL operates on recently collected sensor-data in direct interaction with its environment and enables real-time responses to system changes. Although deep RL is already being deployed in production systems, a systematic review of the results has not yet been established. The main contribution of this paper is to provide researchers and practitioners an overview of applications and to motivate further implementations and research of deep RL supported production systems. Findings reveal that deep RL is applied in a variety of production domains, contributing to data-driven and flexible processes. In most applications, conventional methods were outperformed and implementation efforts or dependence on human experience were reduced. Nevertheless, future research must focus more on transferring the findings to real-world systems to analyse safety aspects and demonstrate reliability under prevailing conditions."
10.1016/j.procir.2020.02.157,reinforcement,"Published by Elsevier B.V.Faced with rapidly changing technologies, diminishing product life cycles and heightened global competition, product portfolio managers across all industries encounter increasing challenges within portfolio design processes. Aligning the product portfolio with corporate strategies is central to sustain long-term company success. However, regarding volatile environments, this is becoming increasingly challenging. In the last decades, product portfolio decisions were based on subjective experience, but this is no longer sufficient. Nowadays, as portfolio complexity grows constantly, data-based decision support procedures are needed to enable effective decisions in product portfolio management. Regarding the field of portfolio management, only little research has been conducted on the usage of data-based analytical methods. Additionally, the alignment of product portfolios with corporate strategies is still largely unexplored and, in this context, the application of analytical methods has been largely omitted until now. This paper proposes a methodology that uses neural networks with supervised learning to model correlations among product portfolio control parameters and corporate goal indicators. Based on this, reinforcement learning is applied to derive goal-conform recommendations for product portfolio managers. For both supervised and reinforcement learning, the presented methodology includes generic steps for implementation. Moreover, for both machine learning methods, requirements regarding necessary product portfolio data are elaborated. The methodology is validated using a case study."
10.1080/17480930.2024.2362579,reinforcement,"Nowadays, open-pit mining is the large-scale extraction of valuable ore materials from the surface with the use of modern mining equipment. If not operated properly, various unexpected events, such as equipment breakdown, slope collapse, hazardous gas emission and land pollution, would occur. With the rapid development of computer technology and big-data science, emerging applications of machine learning could significantly improve mining predictability, feasibility, efficiency and sustainability. However, there is still a lack of up-to-date systematic literature reviews on applications of machine learning to open-pit mining. To address this issue, this study reviews over 200 relevant papers mainly published in the last five years. In this review, we initially conduct a descriptive statistical analysis of these papers according to different phases in open-pit mining. Consequently, we classify their research findings into four main categories: exploration, exploitation, production and reclamation. In addition, each main category is further divided into some sub-categories, namely, feasibility evaluation and mine design planning in exploration; mine block sequencing in exploitation; drilling, blasting, haulage and processing in production; waste control and environmental protection in reclamation. Based on such a bi-level classification, we systematically summarise promising machine learning techniques (i.e. reinforcement learning and deep reinforcement learning) and potential research opportunities (e.g. integration of machine learning and simulation for mining equipment scheduling) in real-world implementations for the mining industry."
10.1016/j.vaccine.2025.127607,reinforcement,"However, data on the regulatory factors needed for sustainable vaccine manufacturing have been sparse, including in resource-limited settings. This study aims to identify the regulatory factors for sustainable vaccine manufacturing in Asia and the Pacific. Methods: The five countries selected for this study are Bangladesh, India, Indonesia, Republic of Korea and Singapore, which are member countries of the Asian Development Bank (ADB) with different states of vaccine manufacturing and regulatory capacities. The study comprises a scoping review and semi-structured interviews with key informants from the industry, government policy making authorities and regulatory agencies across these five countries. The scoping review retrieved 71 scientific publications comprising published literature from Pubmed, Embase and grey literature, and the semi-structured interviews included a total of 39 interviews with policymakers (n = 7), regulators (n = 7) and vaccine industry (developers/manufacturers) (n = 25). Content analysis was performed using a positivist, predominantly deductive approach, analysing the regulatory challenges, opportunities and recommendations across the vaccine life cycle. Findings: The key regulatory factors for sustainable vaccine manufacturing identified include collaboration, regulatory capacity building, regulatory alignment, strengthened regulatory systems and regulatory agility. Interpretation: These results provide relevant and important evidence to inform regulatory policy as countries globally seek to establish regional vaccine production capabilities for vaccine security. Funding: Asian Development Bank (ADB)."
10.1007/978-3-030-24854-3_13,reinforcement,"We investigate the use of deep reinforcement learning to optimize business processes in a business support system. The focus of this paper is to investigate how a reinforcement learning algorithm named Q-Learning, using deep learning, can be configured in order to support optimization of business processes in an environment which includes some degree of uncertainty. We make the investigation possible by implementing a software agent with the help of a deep learning tool set. The study shows that reinforcement learning is a useful technique for business process optimization but more guidance regarding parameter setting is needed in this area."
10.1109/ICMNWC63764.2024.10872082,reinforcement,"The increasing complexity and interconnectedness of Internet of Things (IoT) software systems necessitate the development of intelligent solutions for predictive maintenance and security. Conventional techniques often fail to provide real-time insights and proactive responses due to the diverse and dynamic nature of IoT environments. To address these challenges, cognitive technologies offer promising avenues for enhancing the operational efficiency and security of IoT networks. This paper introduces Cognitive Twins, an AI-driven framework designed to optimize predictive maintenance and strengthen security in IoT software systems. Cognitive Twins leverage advanced machine learning models and real-time data streams to create dynamic digital replicas of IoT devices and software components. The framework employs a combination of deep learning-based anomaly detection, reinforcement learning for proactive maintenance scheduling, and natural language processing (NLP) for automated security log analysis. By continuously learning from device interactions and evolving threat patterns, Cognitive Twins predict potential failures and detect security threats before they occur, enabling real-time decision-making and automated responses. Cognitive Twins were evaluated on a large-scale IoT network, consisting of 500 nodes across multiple application domains. The framework achieved a predictive maintenance accuracy of 96.8%, reducing downtime by 35% compared to traditional models. In security applications, Cognitive Twins identified cyber threats with a detection rate of 98.3%, lowering the false positive rate to 1.5%."
10.1016/j.eiar.2023.107332,reinforcement,"Africa is largely confronted with varying issue of socioeconomic and insecurity, which is now increasingly linked with the mounting pressure on the continent's natural capital as glaring in the Sahel and Norther regions. As such, this study further probed the drivers of ecological footprint (EFP) by utilizing panel dataset of 39 African countries over the 1996 to 2018. Considering that several suspected drivers or covariates (which include the economy sectoral aspects, globalization aspects, governance and institutional aspects, energy types, and other socioeconomic aspects) of EFP were considered in the model, the feasibility of multicollinearity and other econometric drawbacks were accounted for by employing a two-step strategy. First, we used the least absolute shrinkage and selection operators (LASSOs) machine learning algorithms to predict the most important drivers of EFP. Second, we employed the Partialing-out LASSO instrumental variable regression (POIVLR) and Bayesian Model Averaging (BMA) techniques to obtain the variables marginal effects. The result found a more parsimonious regularization within the Adaptive LASSO (λ=0.0012), thus selecting 19 regressors out of the 26 covariates. Furthermore, the study found that Adaptive LASSO selection should be employed for inference since it performed better than the rest of the LASSOs and Elasticnet. As for the marginal effect of EFP, the partialing-out LASSO instrumental-variables regression (POIVLR) technique largely established expected impact of the selected covariates on EFP in Africa except for the impact of GDP and its square that shows negative and positive inference respectively. Combining these results and the sensitivity analysis, this study is poised to offer useful policy guide to environmentalist and decision-makers across Africa."
10.1109/ASIANCON62057.2024.10837862,reinforcement,"In the industrial sector, unplanned equipment failures can lead to significant financial losses, safety hazards, and operational inefficiencies. Traditional maintenance strategies, such as reactive maintenance (repair after failure) and preventive maintenance (scheduled maintenance), often prove inadequate in addressing these issues. This not only minimizes downtime but also optimizes maintenance resources and extends the lifespan of equipment. Machine learning models used in Predictive maintenance (PdM) are designed to analyze large volumes of data generated by industrial equipment. Reinforcement learning optimizes maintenance schedules by learning from interactions with the environment, balancing the trade-off between maintenance costs and equipment reliability. Black-box models, such as deep learning, often provide high accuracy but lack transparency. Explainable AI (XAI) techniques are being developed to make these models more interpretable, enabling users to gain insights into the decision-making process and build confidence in the predictions. The deployment of ML models in industrial environments also requires seamless integration with existing systems. This involves addressing issues related to real-time data processing, scalability, and model retraining. Edge computing and cloud-based solutions are being explored to handle large-scale data processing and storage, while online learning techniques allow models to adapt to new data continuously. This paper presents several case studies from industries such as manufacturing, energy, transportation, and healthcare, illustrating the successful application of ML in PdM. In manufacturing, ML models have been used to predict failures in machinery such as turbines, compressors, and conveyor belts, leading to significant reductions in downtime and maintenance costs. The energy sector has employed ML for the maintenance of critical infrastructure, including power grids and wind turbines, enhancing operational efficiency and reliability."
10.1504/IJISE.2008.017555,reinforcement,"Heterarchic manufacturing control system offer a significant potential in terms of capacity, adaptation, self-organisation and real time control for dynamic manufacturing system. In this paper, we present our steps to work out a manufacturing control system where the decisions taken by the system are the result of an agents group work, these agents ensure a continuous improvement of these performance, thanks to the reinforcement learning technique which was introduced to them. This technique of learning makes it possible for the agents to learn the best behaviour in their various roles (answer the requests (risks), self-organisation, plan, etc.) without attenuating the system real time quality. We also introduce a new type of agents called 'observant agent', which has the responsibility to supervise the evolution of the system's total performance. A computer implementation and experimentation of this model are provided in this paper to demonstrate the contribution of our approach. © 2008, Inderscience Publishers."
10.1002/admt.202301286,reinforcement,"Additive manufacturing (AM) is rapidly revolutionizing modern manufacturing with recent progress in advanced printing methods and improved properties of printed materials. However, traditional AM methods are limited by their input-oriented nature, which demands tedious trial-and-error tuning of printing parameters to achieve desired output properties. Here, an output-oriented artificial intelligence-integrated AM (AIAM) method is reported that enables an user to specify desired output properties while the printer autonomously discovers the optimal input printing parameters by integrating hybrid machine learning models and in situ measurements. Based on a predictive mapping between the input printing parameters and the output properties of interests established with <20 experiments designed by active learning, inverse design tasks are performed to intelligently generate the printing parameter settings that lead to desired outcomes using reinforcement learning. This method is demonstrated by autonomous aerosol jet printing (AJP) of conductive polymer films and achieving user-defined electrical resistances with an ultralow error of 3.7%. The AIAM method, with its output-oriented nature, holds the potential to significantly improve the autonomy, predictability, efficiency, and accessibility of the AM processes, which will unlock new possibilities in the autonomous and intelligent printing of a broad range of functional materials and devices."
10.1109/TITS.2022.3183215,reinforcement,"This paper provides a novel intelligent scheduling strategy for a real-world transportation dynamic scheduling case from an engine workshop of general motor company (GMEW), which is a key production line throughout the manufacturing process. In order to reduce the carbon emission in the scheduling process and make up for ignoring the energy consumption of each part in the scheduling when optimizing the carbon emission of the workshop and the factory. This paper first formulates a fuzzy random chance-constrained programming model of inverse scheduling problem (ISP) with energy consumption. A multi-strategy parallel genetic algorithm based on machine learning (RL-MSPGA) is proposed, which uses machine learning to improve the genetic algorithm. First, the parallel idea is developed to accelerate the process of evolution of genetic algorithm, and the initial population is divided into clusters by $k$ -means clustering algorithm. Second, similar individuals are evenly distributed to different sub-populations to ensure the diversity and uniformity of sub-populations. Third, in the process of evolution, the sub-populations communicate with each other, and extend the excellent individuals to replace the poor ones in other populations, so as to improve the overall quality of the population. Fourth, the self-learning of the crossover probability is realized by the self-learning of the self-sensing environment, which makes the crossover probability adapt to the evolutionary process according to experience. Finally, the real instance is used to validate the different algorithms. It can effectively adjust the completion time and the proportion of energy consumption, thus providing the possibility for the production of energy-saving enterprises. This implies that the suggested model is reasonable and the provided algorithm can effectively solve the inverse shop scheduling problem."
10.22260/ISARC2025/0017,reinforcement,"All rights reserved.In construction automation, several tasks such as surface finishing, material transport, and inspections typically rely on labor-intensive manual methods, which are inefficient, susceptible to human error, and expose workers to hazardous conditions. Drones have emerged as a solution to automate these processes, but maintaining precise navigation and stable attitude control in dynamic construction environments remains challenging. This paper presents a multi-sensor fusion and control framework to enhance UAV performance in dynamic and complex construction environments. The framework integrates multidimensional data from diverse sensing modalities, including geometric, visual, and inertial information, to achieve robust situational awareness and adaptive control. A Simultaneous Localization and Mapping (SLAM) model fuses multi-modal sensor inputs, including LiDAR point clouds, camera visual features, and inertial measurements, to generate precise environmental maps and perform accurate localization. The SLAM framework employs advanced loop closure techniques to minimize trajectory drift and optimize navigation paths in real-time. Additionally, flight stability under external disturbances is managed by a Deep Reinforcement Learning (DRL) algorithm, which models the UAV’s control system as a Markov Decision Process (MDP). The DRL agent dynamically adjusts the UAV’s flight parameters, such as thrust, roll, pitch, and yaw, based on real-time feedback from fused sensor data. The control strategy leverages a stability-based reward function to minimize deviations in position and orientation, ensuring rapid recovery from external disturbances. Simulation tests conducted in a Robotic Operation System and Gazebo simulation environment demonstrated mapping accuracy of 95.4%, localization errors under 2 cm, and rapid recovery from disturbances within 0.8 seconds."
10.1016/B978-0-444-64241-7.50008-2,reinforcement,"V.This paper provides a brief introduction to Reinforcement Learning (RL) technology, summarizes recent developments in this area, and discusses their potential implications for the field of process control. The paper begins with a brief introduction to RL, a machine learning technology that allows an agent to learn, through trial and error, the best way to accomplish a task. We then highlight two new developments in RL that have led to the recent wave of applications and media interest. A comparison of the key features of RL and Model Predictive Control (MPC) is then presented in order to clarify their similarities and differences. This is followed by an assessment of five ways that RL technology can potentially be used in process control applications. A final section summarizes our conclusions and lists directions for future RL research that may improve its relevance for process control applications."
10.3390/w16243693,reinforcement,"In the context of growing concerns over food security and climate change, research on sustainable agricultural development increasingly emphasizes the interconnections within agricultural systems. This study developed a regionally integrated optimization and prediction agricultural model to systematically analyze the impacts of climate change on agricultural systems and their feedback mechanisms from a water-energy-food-carbon (WEFC) nexus perspective. Applied to the Pearl River Basin, the model evaluates future trends in grain yield, water use, energy consumption, and carbon emissions under various climate scenarios throughout this century. The results indicate that rising temperatures significantly reduce crop yields, particularly in the western basin, increasing the environmental footprint per unit of grain produced. However, the CO2 fertilization effect substantially offsets these negative impacts. Under the SSP585 scenario, CO2 concentrations rising from 599.77 ppm to 1135.21 ppm by the century’s end led to a shift in crop yield trends from negative (Z = −7.03) to positive (Z = 11.01). This also reduces water, energy, and carbon footprints by 12.82%, 10.62%, and 10.59%, respectively. These findings highlight the critical importance of adaptive management strategies, including precision irrigation, optimized fertilizer use, and climate-resilient practices, to ensure sustainable agricultural production. Despite these insights, the model has limitations. Future research should incorporate uncertainty analysis, diverse adaptation pathways, and advanced technologies such as machine learning and remote sensing to improve predictive accuracy and applicability. This study offers valuable guidance for mitigating the adverse impacts of climate change on the WEFC nexus, supporting sustainable agricultural practices and science-based policy development."
10.1007/978-3-031-57785-7_11,reinforcement,"This paper introduces and illustrates a process for stakeholder-driven innovation in a highly contested domain: using artificial intelligence (AI) algorithms for social service delivery in national welfare systems. AI technologies are increasingly being applied because they are assumed to lead to efficiency gains. However, the use of AI is being challenged for its fairness. Existing biases and discrimination in service delivery appear to be perpetuated and cemented as a result of basing the AI on machine learning of past data. Fairness, however, is a dynamic cultural concept: its meaning in terms of values and beliefs, its implications for technology design, and the desired techno-futures need to be societally negotiated with all stakeholders, especially vulnerable groups suffering from current practices. The challenge is to provide contextualized, value-sensitive and participatory AI that is responsive to societal needs and change. The ‘AI for Assessment’ (AI FORA) project combines empirical research on AI-based social service delivery with gamification at community-based multi-stakeholder workshops and a series of case-specific agent-based models for assessing the status quo of AI-based distribution fairness in different countries, for simulating desired policy scenarios, and for generating an approach to ‘Better AI’. The paper is structured as follows: after introducing the participatory approach of AI FORA with its motivation and overall elements, the paper focuses on gamification and simulation as central components of the modelling strategy. Case-specific game design and ABMs are described and illustrated using the example of the AI FORA Spanish case study."
10.1088/2057-1976/ac396c,reinforcement,"A 3-D dosimeter fills the need for treatment plan and delivery verification required by every modern radiation-therapy method used today. This report summarizes a proof-of-concept study to develop a water-equivalent solid 3-D dosimeter that is based on novel radiation-hard scintillating material. The active material of the prototype dosimeter is a blend of radiation-hard peroxide-cured polysiloxane plastic doped with scintillating agent P-Terphenyl and wavelength-shifter BisMSB. The prototype detector was tested with 6 MV and 10 MV x-ray beams at Ohio State University's Comprehensive Cancer Center. A 3-D dose distribution was successfully reconstructed by a neural network specifically trained for this prototype. This report summarizes the material production procedure, the material's water equivalency investigation, the design of the prototype dosimeter and its beam tests, as well as the details of the utilized machine learning approach and the reconstructed 3-D dose distributions."
10.33313/512/B1102,reinforcement,"All rights reserved.The energy policy requirements help to make industrial production more sustainable and environmentally friendly, reduce energy consumption and lower the overall costs for businesses. There is a great need for action to increase energy efficiency in production in press hardening processes through efficient technologies along entire process chains. In such production processes and process chains, data accumulates from a wide variety of sources, including machine controls, sensors, material data and simulation data from process design. The logical next step is to utilize this data along with machine learning and optimization methods to control the process and pursuing objectives like optimal quality, minimal energy, or fast cycle times. This is where the proposed method of this work comes in. The main contribution of this work is a methodology to schematically describe and handle process optimizations model-based. In addition, this method is demonstrated on a hot forming process using hybrid (simulation and experimental) data. It is shown that the process can be optimized regarding its energy consumption while complying with additional technical and quality boundary conditions."
10.1007/s12525-020-00439-y,reinforcement,"The adoption of artificial intelligence (AI) and service robots in the tourism industry for frontline service automation is generating a growing interest. Although there is a fairly large body of literature about this research field, the impacts on the service encounter need to be further investigated. The paper presents an action research project that led to employ the humanoid robot “Pepper”, equipped with a supervised machine-learning AI system, at the reception of an Italian hotel to provide information to clients. This allowed to explore the role played by this agent and the effects on the changing role taken by frontline employees (FLE) and customers. Findings show that this technology can act as an augmentation force and that FLEs’ role can evolve mainly into that of enabler - of the customers and of technology -, innovator and coordinator, while customers may take above all the role of enabler of the technology. The study also contributes to introduce the new role of “AI supervisor” among FLEs."
10.1016/j.optlastec.2024.111096,reinforcement,"However, predicting the optimal process scheme using machine learning models is still challenging owing to the need for a large amount of training experimental data with high costs in DED-LB. In view of this, a physical simulation (PS)-machine learning (ML) model using a relatively small accurate data set of 31 simulation data for optimal process schemes is proposed in DED-LB process in this study. Firstly, a powder-scale high precision phenomenon model incorporating the mass transfer, phase transformations and heat transfer and using Lagrangian particle model to add mass is developed to depict the DED-LB process. Then, a Gaussian process regression (GPR) agent model is established to rapidly and accurately predict the geometry and dilution rate of deposition tracks under different manufacturing parameters based on the high precision simulation results. Finally, a PS-ML model for process parameter optimization is developed using the particle swarm algorithm (PSO), and the optimized parameters are experimentally validated. The results show that the developed powder-scale model and GPR model results are consistent with the Inconel 718 alloy experimental results. The proposed PS-ML model can increase the accuracy of the ML models even with a small simulation data set. None of PS-ML model optimization results has a relative error of more than 3% to the experimental results, and the dilution rate is reduced by up to 61.66% compared to the experimental design parameters without optimization. The proposed physical simulation-machine learning model in this study enables inexpensive and accurate optimization of DED-LB process parameters."
10.1016/j.rineng.2025.104089,reinforcement,"It is produced by foaming molten glass, resulting in a cellular structure that enhances its insulation and impact-resistant properties. Due to its sustainability and durability, FG is increasingly used in the construction, automotive, and packaging sectors. In this context, the current study proposes a novel approach by developing a thoughtful system for assessing performance and intelligent design utilizing ML models such as Gradient Boosting (GB), Random Forest (RF), Gaussian Process Regression (GPR), and Linear Regression (LR) to predict porosity and compressive strength (CS) of FG. The dataset comprises 214 data points, encompassing input variables such as glass particle diameter, foam agent content, heating rate, holding time, sintering temperature, and dry density, with output parameters of porosity and CS. Data preprocessing involved Pearson correlation analysis to address multicollinearity and reveal nonlinear relationships among variables. Model performance was evaluated through R-values, mean absolute error, and root mean square error metrics, demonstrating that the GPR model achieved superior prediction accuracy with R-values of 0.91 and 0.82 for porosity and CS, respectively. The GB model followed closely, while the RF and LR models showed lower accuracy. Partial dependence plots and global feature importance analyses highlighted density and foam agent content as critical factors influencing FG properties. By achieving the most precise predictions with minimal error distributions, the GPR model offers actionable insights into FG design. These findings enable the optimization of FG production by providing reliable tools for predicting and controlling porosity and CS, reducing material waste, enhancing product quality, and streamlining manufacturing processes. This study demonstrates the potential of advanced ML techniques to bridge the gap between predictive modeling and practical applications in the digital design of FG."
10.1007/978-981-96-7505-0_18,reinforcement,"2026.The overnight growth of OFD service businesses, due to technological advancement and a change in consumer behavior, has made reviews furnished by customers imperative for improvement in service quality, demand forecasting, and customer satisfaction. The vast amount of unstructured data makes the conventional method too ineffective. The following review thus provides valuable insights from diverse studies that are being done to apply deep learning, reinforcement learning, and ensemble learning in analyzing customer reviews of food delivery platforms. It goes on to provide ways through sentiment analysis, demand forecasting, dynamic recommendations of orders, and personalized marketing that these studies have proven how machine learning can make a difference in operatively effectively producing efficiency. It also provides an overview of the challenges in terms of data imbalance, scalability, and sustainability concerns, thus showing perspectives for further research in developing OFD platforms’ capabilities for optimized and personalized services that take into account environmental and social impacts."
10.1016/j.ijhydene.2023.06.138,reinforcement,"Finding strategies to reduce CO2 output from energy systems that rely on chemical processes is one of the biggest problems in this area. In order to address this challenge, researchers are looking into creative solutions, such as carbon capture and storage and developing alternative energy systems with low carbon footprints. For this, the present work introduces a creative integration of molten carbonate and solid oxide fuel cells to maximize efficiency while reducing energy costs. This system also has a recovery unit to reuse the generated CO2 as the gasification agent for reduced environmental impact. Besides, the surplus heat is exploited through the vanadium chloride cycle for clean hydrogen production. A techno-economic, sustainability, and exergo-environmental assessment is carried out to evaluate the system's feasibility from all facets. According to the parametric results, there is a conflictive trend among performance indicators by changing the fuel utilization factor and compressor pressure ratio. Therefore, a comparative analysis of various multi-objective optimization scenarios is performed to find the best condition from various perspectives. According to the findings, compared to the system without a recovery unit, the proposed model produces optimal hydrogen of 1.3 kg/s with a very low environmental effect and power costs of 5.3 kg/GWh and 19.4 $/MWh. The results further reveal that when power is considered an additional optimization goal, it increases up to 494.95 MWh, resulting in the lowest environmental effect and the cost of 4.4 kg/GWh and 16.3 $/MWh, respectively. The scatter distribution of the key variables ultimately reveals that, while the current density should be maintained at its highest level, the optimal points of utilization factor are distributed throughout the entire domain."
10.1016/j.arthro.2024.09.013,reinforcement,"Unfortunately, there is a shortage of literature addressing important considerations beyond these experimental and entertaining uses. Indeed, a trend for redundancy has emerged where most of the literature has applied ChatGPT to the same tasks while simply swapping the subject matter, resulting in a failure to expand the impact and reach of this potentially transformational artificial intelligence (AI) solution. Instead, research addressing pressing health care challenges and a renewed focus on novel use cases will allow for more meaningful research initiatives, product development, and tangible changes at both the system and point-of-care levels. Current target areas of interest in medicine that remain obstacles to patient care include prior authorization, administrative burden, documentation generation, medical triage and diagnosis, and patient communication efficiency. To advance this area of research toward such meaningful applications, a structured framework is necessary. Such frameworks should include problem identification; definition of key performance indicators; multidisciplinary and multi-institutional collaboration of those with domain expertise, including AI engineers and information technology specialists; policy and strategy development driven by executive-level personnel; institutional financial support and investment from key stakeholders for AI infrastructure and maintenance; and critical assessment of AI performance, bias, and equity."
10.18280/jesa.570425,reinforcement,"Copyright: ©2024 The authors.Automatic fault detection and machine diagnosis play a crucial role in preventive maintenance. This study highlights the importance of fault diagnosis in machinery and emphasizes the benefits of preventive and predictive maintenance strategies. The overviews machine and deep learning techniques, and feature extraction methods for automatic fault diagnosis in rolling bearings. The study discusses the challenges machine and deep learning approaches face, including their limited adaptability to different operational conditions and environmental variations. It also suggests reinforcement learning as a potential automatic rolling bearing fault detection solution. The study differentiates between various reinforcement learning methods, including model-based and model-free approaches, and underscores the advantages of deep reinforcement learning. Furthermore, it evaluates several studies that utilized reinforcement learning for feature optimization, parameter optimization, and addressing class imbalance in rolling bearing fault diagnosis. Lastly, the paper summarizes key findings and proposes future research directions, including integrating reinforcement learning with other machine or deep learning methods and developing new algorithms better suited for large datasets and real-time applications."
10.3390/app13084808,reinforcement,"The ability to supply increasingly individualized market demand in a short period of time while maintaining costs to a bare minimum might be considered a vital factor for industrialized countries’ competitive revival. Despite significant advances in the field of Industry 4.0, there is still an open gap in the literature regarding advanced methodologies for production planning and control. Among different production and control approaches, hybrid architectures are gaining huge interest in the literature. For such architectures to operate at their best, reliable models for performance prediction of the supervised production system are required. In an effort to advance the development of hybrid architecture, this paper develops a model able to predict the performance of the controlled system when it is structured as a controlled work-in-progress (CONWIP) flow-shop with generalized stochastic processing times. To achieve this, we employed a simulation tool using both discrete-event and agent-based simulation techniques, which was then utilized to generate data for training a deep learning neural network. This network was proposed for estimating the throughput of a balanced system, together with a normalization method to generalize the approach. The results showed that the developed estimation tool outperforms the best-known approximated mathematical models while allowing one-shot training of the network. Finally, the paper develops preliminary insights about generalized performance estimation for unbalanced lines."
10.14419/fs83b471,reinforcement,"Kathiravan et al.Additive Manufacturing (AM) has transformed modern production by enabling the fabrication of complex geometries with enhanced material efficiency. However, traditional 3D printing techniques often face challenges such as incomplete fusion, material inconsistencies, and thermal warping, which affect overall quality and productivity. This study introduces an intelligent 3D printing framework that integrates Artificial Intelligence (AI) to enable real-time monitoring, defect detection, and adaptive process control, thereby addressing these limitations. The proposed system utilizes Convolutional Neural Networks (CNNs) for computer vision-based quality inspection, enabling the detection of structural anomalies during the printing process. Reinforcement Learning (RL) is employed for dynamic adjustment of parameters like nozzle temperature, deposition speed, and material feed rate in response to real-time feedback, significantly reducing defect occurrence. Adaptive machine learning algorithms like Random Forests and Gradient Boosting also facilitate process optimization and predictive maintenance. Stereolithography (SLA), Selective Laser Sintering (SLS) and Fused Deposition Modeling (FDM) are among the AM platforms that use this AI-AI-enhanced closed-loop control approach. Material use, energy efficiency, production time, print quality and defect mitigation have all significantly improved, as confirmed by experimental validation. With its ability to guarantee accuracy and dependability in contemporary 3D printing processes, the framework shows great promise for developing industrial and biomedical applications."
10.1063/5.0296437,reinforcement,"The likelihood of errors will rise in an intelligent manufacturing system as the quantity and operational complexities of the machines grow, potentially resulting in significant financial losses. The issues with traditional passive or regular servicing techniques for fault-solving are their high resource consumption and limited performance. Furthermore, many conventional maintenance techniques only use a single model, making it difficult to handle all of the smart manufacturing system's prognosis maintenance and upkeep responsibilities at once. Predictive maintenance (PdM) tactics and sophisticated methods of machine learning have become more important in the context of Industry 4.0, as a means of improving the dependability and efficiency of mechanical components. To maximize mechanical system efficiency, this study investigates the beneficial combination of Deep Reinforcement Learning (DRL) with PdM methods. DRL is a well-known technique for handling complicated decision-making assignments through constantly changing interactions. It is used to optimize maintenance times, reduce unanticipated failures, and learn and forecast system states automatically. To provide an adaptable management plan, the proposed structure integrates DRL with conventional PdM techniques, making use of historical information and continuous system observation. The combined technique has the potential to have a revolutionary influence on manufacturing processes since experimental findings show that it performs much better in terms of predicted precision and system efficiency than traditional PdM approaches. The results highlight the need to combine DRL with maintenance planning to accomplish mechanical system administration that is more astute and flexible."
10.1016/j.mineng.2025.109677,reinforcement,"Due to the complexity of its production processes, as well as the nonlinear and dynamic characteristics of smelting, data collection systems are employed to record data during the pyrometallurgical production process to monitor real-time changes in equipment and process parameters. These systems generate vast amounts of data, which cannot be effectively analyzed through current manual processing methods involving human observer. Artificial intelligence (AI) algorithms are a data-driven technology that have demonstrated unprecedented performance in data analysis. Although AI has been applied in various fields such as healthcare, finance, and education, its use in the pyrometallurgical industry remains underexplored. This paper advocates for the necessity and potential value of AI in the pyrometallurgy by analyzing the advantages and disadvantages of AI algorithms as well as the challenges in pyrometallurgical production. It also aims to review the research progress over the past five years from both theoretical and industrial application perspectives. First, we present a classification of AI algorithms used in pyrometallurgy, covering machine learning (ML), deep learning (DL), and reinforcement learning (RL). Then, the specific applications of AI in the pyrometallurgical field are reviewed, with a focus on variable prediction, process optimization, anomaly monitoring and production planning and scheduling. Finally, we discuss the challenges and future prospects. This work combines the advancements of AI algorithms with the practical needs of pyrometallurgical production, providing a reference for researchers developing more advanced AI algorithms, while also offering support to metallurgical engineers in exploring more efficient solutions."
10.1007/978-3-540-45185-3_11,reinforcement,"Scheduling problems, e.g., a job-shop scheduling, are classical NP- hard problems. In the paper a two-level adaptation method is proposed to solve the scheduling problem in a dynamically changing and uncertain environment. It is applied to the heterarchical multi-agent architecture developed by Valckenaers et al. Their work is improved by applying machine learning techniques, such as: neurodynamic programming (reinforcement learning + neural networks) and simulated annealing. The paper focuses on manufacturing control, however, a lot of these ideas can be applied to other kinds of decisionmaking, as well."
10.1016/j.eiar.2025.108076,reinforcement,"Assessing green development is critical for global sustainability progress, yet existing approaches often use fixed indicators that overlook regional variations and complexities. To address this, we developed a context-specific indicator system integrated with interpretable machine learning (ML) models to balance adaptability and efficiency. Validated using 2016–2020 data from 130 Yangtze River Economic Belt cities. The results reveals notable improvements in the overall green development since 2016, with variations across city types. Random forest models exhibited high prediction accuracy (R2 = 0.75–0.91, MSE = 1.91–5.77), with SHapley Additive exPlanations (SHAP) analysis highlighting rural income (|SHAP| = 1.65), tertiary industry ratio (|SHAP| = 1.48), grassland coverage (|SHAP| = 1.38), protection areas (|SHAP| = 0.81), and waste utilization (|SHAP| = 0.80) as pivotal drivers. The policy implications include inclusive development, innovation-driven industrial transformation, circular economy adoption, and ecological conservation. While temporal-spatial limitations exist, this study confirms ML's potential for complex sustainability assessment, offering decision-makers a data-driven toolkit to enhance regional intervention efficiency and effectiveness."
10.1109/ICAICCIT64383.2024.10912401,reinforcement,"Factory layout planning (FLP) is one of the most significant decisions that have to be taken by an organization while establishing and designing a manufacturing unit. Traditional approaches to FLP, which rely on manual and computational methods, struggle to cope with the increasing complexity of modern manufacturing systems, characterized by diverse product types, shorter life cycles, and smaller batch sizes. Objective: To address these challenges, this paper seeks to utilized Reinforcement Learning (RL) to facilitate the automation of factory layout optimization by looking at material flow, transportation time, and productivity rates. Provide a case study based on RL for Factory layout. Methods: A novel RL-based framework is developed, where an RL agent dynamically allocates functional units within a grid-based factory layout. The framework is compared with both manual and conventional computer-aided approaches. In addition to RL, machine learning (ML) techniques such as supervised and unsupervised learning are also evaluated for layout optimization. Results: RL has a superior performance to the traditional model; the results depict a massive improvement in transport duration and enhanced workflow. This flexibility is inherent in RL to solve complex FLP without having to rely extensively on analytic models that may not be feasible when the problem space changes often. Conclusion: This research demonstrates that RL is a powerful tool for optimizing factory layouts, capable of dynamically responding to system changes and leading to continuous improvements in operational performance."
10.1007/s40998-025-00807-4,reinforcement,"Integrating machine learning (ML) into Hybrid Renewable Energy Systems (HRES) promises to boost energy efficiency and grid stability in decentralized smart grids. Techniques like predictive analytics and reinforcement learning optimize resource allocation and real-time decision-making, yet challenges such as data quality, integration complexity, and high costs impede broad adoption. This review explores ML’s role in optimizing HRES for decentralized grids, pinpointing key obstacles and proposing solutions through interdisciplinary collaboration; spanning engineering, data science, and policy—and targeted policy measures. A systematic literature review analyzed studies and case reports from 2010 to 2023, focusing on ML applications like demand forecasting, energy management, and predictive maintenance in HRES, with metrics like energy efficiency and grid stability evaluated across diverse case studies. ML-driven optimization yielded notable gains, including a 20% reduction in energy wastage and a 15–25% boost in grid stability, as evidenced by Stanford University’s solar campus and the UK National Grid, enhancing energy flows and decision-making in decentralized systems. ML holds immense potential for HRES optimization, but practical deployment hinges on overcoming data and integration barriers. Collaboration between engineers, data scientists, and policymakers can refine ML models, while policies like tax incentives for digital infrastructure and standardized data protocols can address real-world challenges—such as inconsistent datasets and scalability—fostering sustainable, resilient energy systems. Future research should prioritize robust ML models and practical implementation frameworks."
10.11834/jig.190446,reinforcement,"All right reserved.Computer vision plays an important role in detection, recognition, and location analysis in intelligent manufacturing, especially in industry inspection. It has made great contributions to improve the inspection rate, the accuracy of industrial inspection, and the degree of intelligent automation. However, the popularity of computer vision technology is insufficient in intelligent manufacturing because of its several technical application difficulties. Dealing with these problems has become a top priority in the popularization of computer vision in intelligent manufacturing. The three key application bottlenecks are the illumination impacts, sample data that cannot support deep learning, and prior knowledge that cannot support evolutionary algorithms. These bottlenecks make computer vision in intelligent manufacturing inefficient and cannot be applied in several fields. Therefore, these bottlenecks need to be systematically analyzed and resolved. We first summarized the concepts of intelligent manufacturing and computer vision. Then, the development of computer vision in intelligent manufacturing and the demand of intelligent manufacturing for computer vision technology were presented. We elaborated that computer vision could increase the inspection accuracy and rate and provide many details that cannot be found by human beings by comparing it with traditional methods. On the basis of the development status and needs of computer vision in intelligent manufacturing inspection, we proposed three critical bottlenecks in computer vision applications, namely, 1) In the actual industrial situation, uneven illumination is easily obtained because the environment is complex, and the light source is simple. Thus, The problem where the image quality is immensely impacted by illumination should be explored. 2) Obtaining uniform sample data of more than 10 000 levels in the actual industry is difficult. The problem where the sample data cannot support computer vision detection task based on deep learning should be given great importance. 3) Computer judgment cannot achieve the accuracy of professional judgment. Rational addition of human prior knowledge into evolutionary algorithms to reduce the difficulty of deep learning algorithms should be deeply analyzed. Then, we focused on summarizing and analyzing the status, source, and existing solutions of the three problems in sequence. Several widely-accepted or effective methods were analyzed and compared in the sections. We conducted make a feasibility analysis through the qualitative analysis of data and principles to prove that they can be used in intelligent manufacturing. A thorough analysis indicates that: illumination can be solved through some algorithms used in image acquisition; the sample data that cannot support deep learning can be solved using a small sample data processing algorithm and a sample quantity distribution balance method; for prior knowledge that cannot support evolutionary algorithms can be solved through machine learning and reinforcement learning. The methods in the above solutions are numerous and different. Each of them has its own advantages and disadvantages and needs to be researched and improved in specific applications in intelligent manufacturing. This overview summarizes the bottlenecks of computer vision applications in intelligent manufacturing, analyzes the corresponding solutions, and provides specific example methods. The application feasibility of these methods in intelligent manufacturing is also analyzed. The methods described in this paper can be applied to intelligent manufacturing. We propose new ideas for solving bottleneck problems. This paper provides certain reference values for readers and scholars using computer vision in intelligent manufacturing."
10.1016/j.ifacol.2021.08.290,reinforcement,"This is an open access article under the CC BY-NC-ND license ( process optimization and control often require satisfaction of constraints for safe operation. Reinforcement learning (RL) has been shown to be a powerful control technique that can handle nonlinear stochastic optimal control problems. Despite this promise, RL has yet to see significant translation to industrial practice due to its inability to satisfy state constraints. This work aims to address this challenge. We propose an “oracle”-assisted constrained Q-learning algorithm that guarantees the satisfaction of joint chance constraints with high probability, which is required for safety critical tasks. To that end, constraint tightening (backoffs) are introduced, which are adjusted using Broyden's method, hence making the backoffs self-tuned. This results in a general methodology that can be integrated into approximate dynamic programming-based algorithms to guarantee constraint satisfaction with high probability. Finally, a case study is presented to compare the performance of the proposed approach with that of model predictive control (MPC). The superior performance of the proposed algorithm, in terms of constraint handling, signifies a step toward the use of RL in real world optimization and control of systems, where constraints are critical in ensuring safety."
10.1109/ICoDSA62899.2024.10652065,reinforcement,"In the oil and gas industry, pipelines are used as a form of transportation for production. However, pipelines are often difficult to maintain and are prone to problems such as corrosion, leaks, and rust. Therefore, it is important to have a way or system that can automatically detect anomalies in order to maintain proper production processes. In this research, the focus is on the accuracy comparison between the K-Nearest Neighbor algorithm, and Support Vector Machine in detecting anomalies in gas transmission operational data. The goal of performing this comparison analysis is to offer trustworthy suggestions for detecting anomalies correctly so that it can lead to proactive maintenance strategies. Both models were able to detect almost all instances of extreme deviations as anomalies, with the one using all features having detected more instances that are way off the norm. A novel approach incorporating voting ensemble learning is introduced in which these algorithms are combined with a voting classifier to form a reinforcement learning framework. The resulting model was able to improve the precision of input model but made a decline to its recall. These findings contribute to the improvement of production processes in the oil and gas industry, providing valuable insight for decision-makers to implement more effective and robust anomaly detection systems."
10.1002/ett.3947,reinforcement,"Cybersecurity is the domain that ensures safeness in both individual system and overall network systems. The classification and learning approaches used in different machine learning (ML) techniques improve the protection of the cyber systems against various attacks. Techniques such as support vector machine (SVM), neural networks (NN), principle component analysis (PCA), and reinforcement learning (RL) are used against various cyber threats. Applying these techniques at the front-end services (either online or offline) makes less effect than back end process-level services of any computer system. The proposed work analyzes the benefits of implementing customized ML and deep learning (DL) techniques on the core of the operating system than application level services, which in effect increases the speed and correctness of attack detection. The core (kernel) of the operating system has the capability to extract all internal attributes of process and file systems. The kernel space security activities can be improved by proposed work where the process level attributes classified using ML and DL techniques. The cloud service helps in sharing of the kernel abilities of the system ensuring core level security. The following work uses recurrent NN (RNN), SVM, PCA, and RL for analyzing the system data collected using Process Explorer. This technique finds application in manufacturing domain where the systems are protected from the various attacks to secure the data of the manufacturing company."
10.1080/17517575.2021.1941275,reinforcement,"This paper considers Enterprise Information Systems functional architecture and carries out review of AI applications integrated in Customer Relationship Management, Supply Chain Management, Inventory and logistics, Production Planning and Scheduling, Finance and accounting, Product Lifecycle Management and Human Resources, with special attention to the manufacturing enterprises. Enhanced capabilities are identified and proposed as AI services. AI-enablement implements improved decision-making or automation by using Machine Learning models or logic-based systems. It is a process of the enterprise transformation leading to the convergence of the four major disruptive technologies, namely Industrial Internet of Things, Agent-based Distributed Systems, Cloud Computing and Artificial Intelligence."
10.2118/225364-MS,reinforcement,"Copyright 2025, Society of Petroleum Engineers.In the digital transformation of the petroleum industry, reservoir dynamic optimization confronts dual challenges: the complexity of multi-physics coupled modeling and the demand for real-time decision-making. Traditional numerical simulation methods are constrained by high computational costs, reliance on static historical data, and expert-driven experience, which limits their ability to address the dynamic evolution of reservoir properties and nonlinear interactions in heterogeneous fluids. To tackle these issues, this study introduces a physics-informed machine learning proxy model framework. By integrating deep autoencoders with neural ordinary differential equations (Neural ODEs), it constructs a high-fidelity, low-computational-cost dynamic prediction model. The framework employs deep autoencoders to nonlinearly compress high-dimensional 3D reservoir dynamic data and integrates static variables and control parameters using Neural ODEs to describe state changes. This approach significantly reduces data dimensions and enables fast prediction. Experiments conducted using the SPE9 benchmark 3D reservoir model demonstrate that the proxy model reduces the original physical field data dimensions by approximately 66.7%, validating its efficiency and reliability in dimensionality reduction and dynamic forecasting. The efficient and high-precision proxy model provides an ideal environment for reinforcement learning. Through the cooperative design of the agent action space and the reward mechanism, the closed-loop optimization of the digital twin architecture is innovatively realized, and the production parameters can be adjusted in seconds in real time. This study breaks through the timeliness bottleneck of traditional numerical simulation, and proposes an intelligent decision-making model that integrates data-driven and physical models, providing innovative solutions for intelligent reservoir development and oilfield intelligent transformation."
10.1007/978-3-030-35930-0,reinforcement,"This book presents a step by step Asset Health Management Optimization Approach Using Internet of Things (IoT). The authors provide a comprehensive study which includes the descriptive, diagnostic, predictive, and prescriptive analysis in detail. The presentation focuses on the challenges of the parameter selection, statistical data analysis, predictive algorithms, big data storage and selection, data pattern recognition, machine learning techniques, asset failure distribution estimation, reliability and availability enhancement, condition based maintenance policy, failure detection, data driven optimization algorithm, and a multi-objective optimization approach, all of which can significantly enhance the reliability and availability of the system.This book presents a step by step Asset Health Management Optimization Approach Using Internet of Things (IoT). The authors provide a comprehensive study which includes the descriptive, diagnostic, predictive, and prescriptive analysis in detail. The presentation focuses on the challenges of the parameter selection, statistical data analysis, predictive algorithms, big data storage and selection, data pattern recognition, machine learning techniques, asset failure distribution estimation, reliability and availability enhancement, condition based maintenance policy, failure detection, data driven optimization algorithm, and a multi-objective optimization approach, all of which can significantly enhance the reliability and availability of the system."
10.1016/j.cherd.2021.08.013,reinforcement,"Artificial neural networks are the most preferred techniques over other ML algorithms because of their generalization capabilities. Demands for ML techniques in the energy sectors will increase considerably in the coming years, since there is a growing demand of academic programmes related to artificial intelligence in science, math, and engineering. Data generation, management, and safety are expected to play a key role for the successful implementation of ML algorithms that can be shared by major stakeholders in the energy sector, thereby promoting the development of ambitious energy management projects. New algorithms for producing reliable data and the addition of other sources of information (e.g., novel sensors) will enhance flow of information between ML and systems. It is expected that unsupervised and reinforcement learning will take a central role in the energy sector, but this will depend on the expansion of other major fields in data science such as big data analytics. Massive implementations, specialized algorithms, and new technologies like 5G will promote the development of sustainable applications of ML in non-industrial applications for energy management."
10.1109/SSCI51031.2022.10022151,reinforcement,"Today we are seeing a significant need for efficient control of operating cycles to deliver improvements in services provided by Internet of Things (IoT) devices embedded with environmental monitoring. To design an algorithm which provides sufficient duty-cycle control, we can apply machine learning approaches. The present study investigates the reinforcement learning (RL) algorithm family, especially Q-learning (QL) and Double Q-learning (DQL) algorithms and their suitability for devices deployed in a range of locations. We present a comprehensive analysis of the implemented RL approaches for regulating data-driven self-learning (DDSL) controllers. We tested QL and DQL algorithms on various datasets and evaluated their performance with a statistical analysis. The results indicated that the QL and the DQL approaches were highly dependent on the nature of the environmental parameters which the DDSL controller detected and recorded."
10.1016/j.chemolab.2018.03.010,reinforcement,"V.Batch processes have attracted extensive attention as a crucial manufacturing way in modern industries. Although they are well equipped with control devices, batch processes may operate at a non-optimal status because of process disturbances, equipment aging, feedstock variations, etc. As a result, the quality indices or economic benefits may be undesirable using the pre-defined normal operation conditions. And this phenomenon is called non-optimality here. Therefore, it is indispensable to timely remedy the process to its optimal status without accurate models or amounts of data. To solve this problem, this study proposes an intelligent non-optimality self-recovery method based on reinforcement learning. First, the causal variables that lead to the non-optimality are identified by developing a status-degraded Fisher discriminant analysis with consideration of sparsity. Second, on the basis of self-learning mechanism, an intelligent self-recovery method is proposed using the reinforcement learning to automatically adjust the set-points of the causal controlled variables. The self-recovery action is taken iteratively through the Actor-Critic structure with two neural networks. In this way, effective actions are taken to remedy the process to its expected status which only require small data. Finally, the efficacy of the proposed method is illustrated by both numerical case and a typical batch-type manufacturing process, i.e., the injection molding process."
10.1088/1755-1315/1389/1/012013,reinforcement,"Artificial intelligence (AI), machine learning (ML), and deep learning (DL) are technologies that have recently transformed many industries. The construction industry has traditionally been a laggard industry in terms of digital-technology adoption. When leading firms in this industry have experimented with these technologies, many of these experiments have met resistance. In this paper we take an institutional lens to study why and particular social structures appears to have contributed to the resistance and paucity of success stories. Within institutional research, we focus on research with traces to cognitive science and psychology. We have carried out a qualitative embedded multiple-case study on resistance to new technologies and how to overcome such resistance. The study involves four use cases in the Finnish construction industry: (1) automation of a material-product subcontractor's production planning; (2) business-model innovation by contractor on how to best work across multiple construction sites at once; (3) machine learning and automation of documentation by a software firm; and (4) promotion of a vision of information sharing across organizations by the above software firm. Based on within and cross-case analyses, preliminary empirical findings are that AI, ML and DL have in the Finnish construction industry challenged institutionalized forms of organizing and workflow established long since in the industry and, until about the time of this piece of research, taken for granted. Resistance was nonetheless beginning to be overcome at the time of writing this piece of research with small-group interaction across firms - such as those in this study - - in the industry ecosystem. Human-human mediation and face-to-face encounters were building trust in and across the organizations. The implication for practice and policy is that business transformation will not quickly and autonomously transform into ""impersonal""or machine-machine exchange but, before that, requires human-human mediation. ""In the long-term, AI and analytics have boundless potential use cases in E&C [i.e. engineering and construction]. Machine learning is gaining some momentum as an overarching use case (that is, one applicable to the entire construction life cycle, from preconstruction through O&M 8i.e. operations and management), particularly in reality capture (for example, in conjunction with computer vision) as well as for comparison of in situ field conditions with plans (for example, supporting twin models). Indeed, by applying machine learning to an ongoing project, schedules could be optimized to sequence tasks and hit target deadlines, and divergences from blueprints could be caught closer to real time and corrected using a variety of predetermined potential scenarios.""[1]"
10.1016/j.artmed.2021.102062,reinforcement,"V.Suboptimal health related behaviors and habits; and resulting chronic diseases are responsible for majority of deaths globally. Studies show that providing personalized support to patients yield improved results by preventing and/or timely treatment of these problems. Digital, just-in-time and adaptive interventions are mobile phone-based notifications that are being utilized to support people wherever and whenever necessary in coping with their health problems. In this research, we propose a reinforcement learning-based mechanism to personalize interventions in terms of timing, frequency and preferred type(s). We simultaneously employ two reinforcement learning models, namely intervention-selection and opportune-moment-identification; capturing and exploiting changes in people's long-term and momentary contexts respectively. While the intervention-selection model adapts the intervention delivery with respect to type and frequency, the opportune-moment-identification model tries to find the most opportune moments to deliver interventions throughout a day. We propose two accelerator techniques over the standard reinforcement learning algorithms to boost learning performance. First, we propose a customized version of eligibility traces for rewarding past actions throughout an agent's trajectory. Second, we utilize the transfer learning method to reuse knowledge across multiple learning environments. We validate the proposed approach in a simulated experiment where we simulate four personas differing in their daily activities, preferences on specific intervention types and attitudes towards the targeted behavior. Our experiments show that the proposed approach yields better results compared to the standard reinforcement learning algorithms and successfully capture the simulated variations associated with the personas."
10.1109/IAICT59002.2023.10205949,reinforcement,"Digital Twin (DT) is an emerging paradigm that enables a virtual model to effectively represent a physical process. In this paper, we present the adoption of the DT scheme by an offset printing company towards industrial optimization. The considered DT model is a virtual representation that serves as the digital copy of the physical printing process within an industrial unit. A virtual model for selecting the optimal machine line was developed to ensure cost-efficient printing. The machine line selection process was modeled as a decision process and then analyzed through simulations in a safe and cost-efficient digital environment, provided by the DT. Moreover, Machine Learning (ML) models were exploited to extract knowledge for the machine selection task, taking full advantage of the DT experiment. Based on real data and selection policies of a printing enterprise, the results revealed an improvement during the selection process, followed by a 5% cost reduction on the examined dataset."
10.2118/196003-ms,reinforcement,"Such an extensive data input poses a challenging task to decide on the optimal strategy of manipulating the inflow control valve (ICV) settings over time for best performance. This study investigated the use of machine learning to analyze and predict well performance given different ICV settings to ultimately maximize the well output. A commercial reservoir simulator was used to generate two synthetic reservoir models: homogeneous (Case A) and heterogenous (Case B). These synthetic data were used to train, validate, and test machine learning models. The reservoir cases were generated based on a segmented, trilateral producer completed with three ICV devices installed at tie-in segments. The data used were measurements of wellhead and downhole flow rates across ICV segments over a period of 4,000 days. A total of 1,330 experiments were conducted with an eight-day timestep, generating a total of 667,660 sample data points for each of Case A and Case B. Fully connected neural networks were used to fit the data while model generalizability was enhanced using regularization techniques, namely L2 regularization and early stopping. Both random sampling and Latin Hypercube Sampling (LHS) methods were evaluated in constructing the training, validation, and testing splits. Trained with different sample sizes drawn from the 1,330 simulated data histories for the two reservoir models, the proposed neural network showed excellent results. Given only ten simulated choices of ICV settings for training, the network proved capable of predicting oil and water production profiles at surface for both homogeneous and heterogeneous reservoir models with over 0.95 coefficient of determination (R2) when evaluated at unseen, test ICV settings. Extending the problem to downhole flow performance prediction, about 40 training simulated settings were necessary to achieve 0.95 R2. We observed that LHS was superior to random sampling in both R2 average and confidence interval. We also found that increasing the training and validation sample sizes increased the test R2 when testing against unseen cases. Study results suggest the applicability of machine reinforcement learning to estimate the well output at different ICV settings, where the neural network model depends fully on the real-time well feedback and production measurements. By using a machine learning approach during the operation of a well with multiple ICV settings, it would be feasible to estimate the lateral-by-lateral output at unseen scenarios. Hence, it becomes possible to maximize the well output by using an optimization algorithm to determine the optimal ICV settings."
10.1016/j.frl.2024.106362,reinforcement,"In the era of the current scientific and technological revolution and industrial transformation, digital technology innovation serves as a critical driver for the high-quality development of manufacturing enterprises. The dual attributes of ESG (Environmental, Social, and Governance) ratings, encompassing ""internal governance"" and ""external support,"" play a pivotal role in propelling digital technology innovation within these enterprises. This study utilizes a dual machine learning approach to empirically investigate the influence of ESG ratings on the digital technology innovation of manufacturing enterprises and explores the underlying mechanisms. Findings indicate that ESG ratings significantly boost digital technology innovation by alleviating financial market constraints, enhancing customer stability in the product market, elevating human resource levels, and increasing innovation awareness and efficiency. These improvements occur through the mechanisms of ""external support"" and ""internal governance."" Moreover, the study reveals that ESG ratings substantially enhance digital technology innovation in state-owned and high-tech manufacturing enterprises, in contrast to their limited impact on non-state-owned and non-high-tech counterparts. Conclusively, the paper proposes policy recommendations focused on heightening enterprise and societal awareness of ESG importance, intensifying supervision and enforcement, and refining the ESG rating system."
10.1016/j.procir.2021.05.020,reinforcement,"V.. All rights reserved.Digital Twins have been described as beneficial in many areas, such as virtual commissioning, fault prediction or reconfiguration planning. Equipping Digital Twins with artificial intelligence functionalities can greatly expand those beneficial applications or open up altogether new areas of application, among them cross-phase industrial transfer learning. In the context of machine learning, transfer learning represents a set of approaches that enhance learning new tasks based upon previously acquired knowledge. Here, knowledge is transferred from one lifecycle phase to another in order to reduce the amount of data or time needed to train a machine learning algorithm. Looking at common challenges in developing and deploying industrial machinery with deep learning functionalities, embracing this concept would offer several advantages: Using an intelligent Digital Twin, learning algorithms can be designed, configured and tested in the design phase before the physical system exists and real data can be collected. Once real data becomes available, the algorithms must merely be fine-tuned, significantly speeding up commissioning and reducing the probability of costly modifications. Furthermore, using the Digital Twin's simulation capabilities virtually injecting rare faults in order to train an algorithm's response or using reinforcement learning, e.g. to teach a robot, become practically feasible. This article presents several cross-phase industrial transfer learning use cases utilizing intelligent Digital Twins. A real cyber physical production system consisting of an automated welding machine and an automated guided vehicle equipped with a robot arm is used to illustrate the respective benefits."
10.1016/j.ijggc.2021.103480,reinforcement,"This study develops a machine-learning-based workflow to co-optimize the hydrocarbon recovery, CO2 sequestration volume and project net present value (NPV) simultaneously. Considering the trade-off relationships among the objective functions, support vector regression with Gaussian kernel (Gaussian- SVR) proxies are coupled with multi-objective particle swarm optimization (PSO) protocol and generate Pareto optimal solutions. Taking advantage of the high computational efficacy of the proxy model, economic uncertainties introduced by tax credits, capital costs and oil price are investigated by this study. The results indicate that the tax incentive policy (Section 45Q) plays a vital role in enhancing the economic returns of CO2-EOR projects, especially under the depression of crude oil market. The proposed workflow has been successfully implemented to optimize a water alternative CO2 (CO2-WAG) injection project in a depleted oil sand in the US. The optimization results yield an incremental oil production of 15.8 MM STB and 1.37 MM metric tons of CO2 storage in a 20-year development strategy, with the highest project NPV to be 205.6 MM US dollars."
10.3390/pharmaceutics17101331,unknown,"Background: Degenerative, metabolic and oncologic diseases are scarcely amenable to the complete reconstruction of tissue structure and functionalities using common therapeutic modalities. On the nanoscale, extracellular vesicles (EVs) and nanoparticles (NPs) have emerged as attractive candidates in regenerative and personalised medicine. However, EV transfection is hindered by its heterogeneity and low yield, while NPs suffer from cytotoxicity, immunogenicity, and long-term safety issues. Scope of Review: This review synthesises data from over 180 studies as part of a narrative synthesis, critically evaluating the disease-specific utility, mechanistic insights, and translational obstacles. The focus is laid on comparative cytotoxicity profiles, the capacities of hybrid EV–NP systems to circumvent mutual shortcomings, and the increasing impact of artificial intelligence (AI) on predictive modelling, as well as toxicity appraisal and manufacturing. Key Insights: EVs have inherent biocompatibility, immune evasive and organotropic signalling functions; NPs present structural flexibility, adjustable physicochemical properties, and industrial scalability. Common molecular pathways for NP toxicity, such as ROS production, MAPK and JAK/STAT activation, autophagy, and apoptosis, are significant biomarkers for regulatory platforms. Nanotechnological and biomimetic nanocarriers incorporate biological tropism with engineering control to enhance therapeutic efficacy, as well as their translational potential. AI approaches can support rational drug design, promote reproducibility across laboratories, and meet safe-by-design requirements. Conclusions: The intersection of EVs, NPs and AI signifies a turning point in regenerative nanomedicine. To advance this field, there is a need for convergence on experimental protocols, the adoption of mechanistic biomarkers, and regulatory alignment to ensure reproducibility and clinical competence. If realised, these endeavours will not only transition nanoscale medicament design from experimental constructs into reliable and patient-specific tools for clinical trials, but we also have the strong expectation that they could revolutionise future treatments of challenging human disorders."
10.1016/j.mattod.2024.08.013,unknown,"Its remarkable advantages of inherent self-powering, and ease of manufacture, combined with flexible electronics technologies, pave the way for the trillion-node IoT mission. Integration of machine learning into triboelectric sensing systems enables effective learning from sensory data and enhances task execution with increased intelligence. This comprehensive review explores the latest scientific and technological advancements in triboelectric sensors, providing insightful analyses in materials, physics, design principles, manufacturing strategies, monomodal and multimodal sensors, von Neumann architecture-based AI systems, and human-like neuromorphic systems. The discussion also covers diverse technological applications, including biomedicine, robotics, prosthetics, human–machine interfaces, AR/metaverse, smart homes, intelligent sports, and intelligent transportation. The narrative concludes by addressing existing challenges, contemplating potential applications, and outlining prospects in this burgeoning field. Covering from fundamental device physics, and AI integration strategies, to system applications, this review aims to illuminate the burgeoning field of triboelectric sensors, inspiring further innovation in self-powered AI-integrated systems and advanced applications, accelerating the paradigm shift toward the era of self-powered artificial intelligence of things."
10.1784/insi.2025.67.10.620,unknown,"All rights reserved.In this paper, a novel multi-criterion analysis (MCA)-based fuzzy logic (FL) model is proposed to determine the overall health index (OHI) for transformers specifically operating in cold climatic regions. The model incorporates MCA, FL and various diagnostic parameters associated with cold climatic issues such as low temperatures, pour point, kinematic viscosity, water content (WC), cold start issues, oil age, etc. The proposed model is validated using data corresponding to 200 similar in-service transformers installed in different cold climatic regions in India. Furthermore, a comparative analysis is conducted between the outputs of the proposed model and the decisions taken by the transformer diagnostic experts in the field. Evaluation reveals that 91% of the results match. Decision-making using the conventional method is limited to very few diagnostic test outcomes, whereas the proposed diagnostic model assesses the same based on a large number of significant test parameters relevant to cold environments to enable a more comprehensive health assessment. As a result, the proposed model produces an accurate and reliable output. The integration of MCA addresses the rule-overload problem inherent in conventional fuzzy logic systems, enabling a more structured and reliable decision-making process. Moreover, the model is computationally efficient, easily implementable and specifically tailored to the unique challenges faced by transformers in cold climates, making it a valuable tool for utilities and maintenance engineers."
10.1109/ICSC57768.2022.9993860,unknown,"The handling of flexible components, such as rubber sealings or cables, is an essential part of industrial manufacturing. Automating such processes through robotics is still a major challenge. Machine learning-based training of robots in combination with simulation has led to promising results in other areas of robotics. This approach can potentially be applied to assembly tasks as well. However, current simulation tools for robotics generally do not have capabilities for simulating flexible bodies. In this work, an approach for modeling such flexible bodies is proposed, which can be implemented with most common robotic simulation programs. Using the example of a rubber O-ring sealing, this approach was tested in such program and the results were compared with a professional multi-body physics engine. Realistic behavior of the O-ring was achieved with relatively low computation times."
10.1109/JPROC.2021.3054628,unknown,"One of the key targets of Industry 4.0 and digital production, in general, is the support of faster, cleaner, and increasingly customizable manufacturing processes. Additive manufacturing (AM) is a natural fit in this context, as it offers the possibility to produce complex parts without the design constraints of traditional manufacturing routes, typically reducing both material waste and time to market. Nonetheless, the lack of repeatability of the manufacturing process, which typically translates into a lack of reproducibility and reliability of the quality of the final products compared to traditional subtractive technologies, is currently one of the major barriers to the widespread adoption of AM in mass production. To overcome this limitation, there are growing efforts in recent years toward better integration of advanced information technologies into AM, exploiting the layer-by-layer nature of the build. The consequence of these efforts is twofold: 1) the integration of advanced sensing technologies into the AM systems, making possible the in situ monitoring of huge amounts of data at multiple time scales and resolutions and 2) the ever-increasing role of data-driven approaches [especially machine learning (ML)] in the analysis of such data to provide real-time quality monitoring and process optimization. This article introduces and reviews the key technological developments of this phenomenon, with a special focus on metal powder bed fusion (PBF) technologies that are attracting the highest attention by the industrial AM community. After introducing the main manufacturing quality issues and needs that have to be developed and optimized, we provide a wide overview of the latest progress of in situ monitoring and control in metal PBF, with special regards to sensing technologies and ML approaches. Finally, we identify the open challenges and future research directions in this field."
10.1007/978-981-99-7445-0_7,unknown,"2024.With the advent of Industry 4.0, more emphasis is currently being placed on the adoption of digital technologies in all areas. The current study investigates the effect of Lean-Green-Six Sigma practices on organizational performances (i.e. Operational and Financial) in relation to developing nations. A cross-sectional data set was gathered from 120 Indian manufacturing companies, and machine learning techniques were used for data analysis and result interpretation. This study gives an enhanced comprehension of ML advances in embracing Lean-Green-Six Sigma rehearses. The results show that Lean-Green-Six Sigma rehearses emphatically influence the operational and financial performance of the organizations as the adjusted R square value of 70.6 and 68.2% with P values (≤ 0.05) satisfy the hypothesis. The results likewise offer a strategy structure for supervisors, policymakers, and makers to advance Lean-Green-Six Sigma rehearses in organizations. Although a few late studies have attempted to research the force of LGSS rehearses on maintainability execution, be that as it may, not many examinations have dissected the impact of LGSS through the reception of the ML approach with regard to arising economies."
10.1117/12.2501427,unknown,"Design weak points that have narrow process window and limits wafer yield, or hotspots, continue to be a major issue in semiconductor photolithography. Resolution enhancement techniques (RET) such as advanced optical proximity correction (OPC) techniques and source mask optimization (SMO) are employed to mitigate these issues. During yield ramp for a given technology node, full-chip lithography simulation, pattern-matching and machine learning are adopted to detect and remedy the weak points from the original design [1], [2]. This is typically an iterative process by which these points are identified in short-loop lithography testing. Design retarget and/or OPC modifications are made to enhance process window until the yield goal is met. This is a high cost and time consuming process that results in a slow yield ramp for existing production nodes and increased time to market (TTM) for new node introduction. Local hotspot correction through mask and wafer harmonization is a method to enhance wafer yield with low cost and short cycle time compared to the iterative method. In this paper, a fast and low cost approach to hotspot correction is introduced. Hotspots were detected on wafer after OPC and characterized by using advanced mask characterization and optimization (AMCO) techniques. Lithographic simulations and AIMS measurement were used to verify the hotspot correction method. Finally, the validity of this new approach was evaluated by process window analysis and circuit probe yield test at wafer."
10.1109/ACCAI58221.2023.10199335,unknown,"Since the evaluation of textile fabric quality is crucial to the success of every textile business, the need for computer-based intelligent visual inspection systems is on the rise. There has been a lot of interest in the study of fabric defect identification as of late due to the increasing labor costs and the increased use of automation in the textile sector. We suggested a structure based on machine learning to identify flaws in fabrics automatically. In this study, we offer an automated AI-based fabric defect identification system that makes use of deep neural network models that have already been trained. The networks are trained using pre-processed, improved versions of the fabric pictures obtained using standard image processing methods. In order to train and categorize various fabric flaws, the LightGBM is combined with a pretrained network, AlexNet. We have also examined how well our categorization model works with varying values of the experimental variables. At long last, a thorough comparison of various methods has been provided."
10.1016/j.energy.2022.125857,unknown,"In this study, the operation characteristics of a 3 kW ORC with automatic control system applied to a chemical plant, as well as the performance prediction and optimization using machine learning methodology, are addressed. The dynamic behaviors for startup, operating and stop stages are discussed. The BP-ORC neural network model is established based on 3400 sets of experimental data, while the prediction accuracy is analyzed based on the errors of the training and test samples. The effects of six operation parameters on system performance are examined, while the bi-objective optimization for maximum thermal efficiency and maximum net output work is investigated. Results indicate that the component response times for startup stage and stop stage are 90s and 300s, respectively. Increasing the mass flow rate, decreasing the expander outlet temperature and increasing the expander inlet temperature ensure a higher net output work, while increasing the expander inlet temperature, decreasing the expander outlet temperature and increasing pump outlet pressure enable a higher thermal efficiency. The optimum net output work and thermal efficiency from Pareto-optimal solution are 2.87 kW and 8.855%, respectively."
10.1007/s00170-024-14403-z,unknown,"Steel, as a crucial material extensively used in various fields, has a critical impact on the determination of the stability and reliability of engineering structures. Nevertheless, because of inevitable factors in manufacturing, transportation, and other processes, steel may exhibit various surface defects during production and handling. To address these defects, the investigation puts forward a resilient machine-learning method for steel surface defect detection based on lightweight convolution. First, to reduce redundant features, complexity, and computational cost, the Spatial and Channel Reconstruction Convolution (ScConv) module is added before the Spatial Pyramid Pooling-Fast (SPPF) within the YOLOv8n’s backbone network. Second, in the Neck layer, lightweight convolution GSConv is used to replace the convolutional modules, and the efficient cross-stage partial network (CSP) module, VoV-GSCSP is substituted for the C2f module to alleviate the model burden while maintaining accuracy. Then, to focus on important information related to the current task, the Coordinate Attention module is added to the Neck layer. Finally, the activation function of YOLOv8n has been swapped for the Leaky Rectified Linear Unit (LeakyReLU) to effectively address issues such as gradient vanishing and overfitting. The method achieved a mean Average Precision (mAP) of 77.7% on the NEU-DET dataset, which is an improvement of 4.7% over the original YOLOv8n. Additionally, the frames per second (FPS) reached 17.36 f/s, representing a 5.79 f/s increase compared to the original YOLOv8n. On the GC10-DET dataset, mAP improves by 5.5%, with a FPS of 15.63 f/s. A plethora of experimentation on both datasets illustrates the method’s robustness, meeting the precision criteria for detecting metal defects."
10.1016/j.microc.2024.110350,unknown,"V.Since pH can alter the biological functions, level of nutrients, wound healing process, and the behavior of chemicals, various healthcare and food industries are showing increased interest in manufacturing low-cost optical pH sensors for meat spoilage detection and wound health monitoring. To meet this demand, we have developed a simple and low-cost machine learning-enabled microneedle-based colorimetric pH sensing patch that can be used for food quality and wound health monitoring applications. The 3D–printed ultrasharp open side channel microneedle array facilitated the autonomous fluid extraction and transportation via surface tension for colorimetric pH sensing. Further, to predict the exact pH value against the obtained color on the pH-test strip, a machine learning model was prepared using experimentally collected different color images obtained from a known pH solution. Furthermore, to make the device user-friendly for older individuals and color-blind individuals, a simple and smartphone-enabled web application was prepared using the developed machine learning model. The proof-of-concept study of the developed patch was demonstrated by determining the pH of real meat samples before and after spoilage and detecting pH in two different skin-mimicking in vitro models (phantom gel and parafilm tape) using a smartphone. The analytical results demonstrated that the developed machine learning-enabled microneedle-based colorimetric pH sensing patch has excellent potential for wound health and food safety applications."
10.1088/2632-2153/ad5fde,unknown,"Published by IOP Publishing Ltd.In this study, we introduce a novel de Bruijn graph (dBG) based framework for feature engineering in biological sequential data such as proteins. This framework simplifies feature extraction by dynamically generating high-quality, interpretable features for traditional AI (TAI) algorithms. Our framework accounts for amino acid substitutions by efficiently adjusting the edge weights in the dBG using a secondary trie structure. We extract motifs from the dBG by traversing the heavy edges, and then incorporate alignment algorithms like BLAST and Smith-Waterman to generate features for TAI algorithms. Empirical validation on TIMP (tissue inhibitors of matrix metalloproteinase) data demonstrates significant accuracy improvements over a robust baseline, state-of-the-art PLM models, and those from the popular GLAM2 tool. Furthermore, our framework successfully identified Glycine and Arginine-rich motifs with high coverage, highlighting it is potential in general pattern discovery."
10.3390/jfb16020053,unknown,"Laser powder bed fusion (LPBF) has emerged as a transformative additive manufacturing technique for fabricating architected cellular metallic structures, offering tailored properties for diverse biomedical applications. These structures are particularly well-suited for bone implants, scaffolds, and other load-bearing medical devices due to their ability to achieve lightweight designs, enhanced mechanical properties, and customized geometries. However, the complex interactions between LPBF process parameters and the resulting structural and mechanical properties pose significant challenges in achieving the precision and reliability required for clinical applications. This review provides a comprehensive analysis of the effects of LPBF process parameters, including laser power, scanning speed, and layer thickness, on key attributes such as dimensional accuracy, density, surface roughness, and microstructure. Their influence on the mechanical performance, including strength, fatigue resistance, and functional properties, is critically examined, with specific attention to biomedical relevance. The impact of lattice design factors, such as topology, unit cell size, and orientation, is also discussed, underscoring their role in optimizing biocompatibility and structural integrity for medical applications. Challenges such as surface defects, geometric inaccuracies, and microstructural inconsistencies are highlighted as key barriers to the broader adoption of LPBF in biomedical fields. Future perspectives focus on advancing LPBF technologies through process optimization and integration with advanced computational tools, such as machine learning, to enable efficient manufacturing of complex, patient-specific architectures. By addressing these challenges, LPBF has the potential to revolutionize the development of next-generation biomaterials, tailored to meet evolving clinical needs and improve patient outcomes."
10.1115/IPC2018-78081,unknown,"Copyright © 2018 ASMEIn-line inspection (ILI) data is commonly used in corrosion growth models (CGMs) to predict the corrosion growth in energy pipelines. A hierarchical stochastic corrosion growth model is considered in this paper which considers the variations in the corrosion growth, both spatially and temporally, the inherent measurement error of the ILI tools as well as the model uncertainties. These uncertainties are represented as unknown model variables and are often inferred using a Bayesian method [1], [2] and samples of the unknown parameters' posterior probability density functions (PDFs) are obtained using Markov Chain Monte Carlo (MCMC) sampling techniques [3]. ILIs can result in massive data sets. In order for MCMC-based inference techniques to yield reasonably accurate results, many samples (approaching infinity) are required. This fact in addition to the massive data sets exponentially increases the scale of the inference problem from an attainable solution to a potentially impossible one that is limited by today's computing power. For this reason, MCMC-based inference techniques can become inefficient in the cases where ILI datasets are large. The objective is to propose variational inference (VI) as an alternative to MCMC to determine a Bayesian solution for the unknown parameters in complex stochastic CGMs. VI produces approximations of the posterior PDFs by treating the inference as an optimization problem. Variational inference emerged from machine learning for Bayesian inference of large data sets; therefore, it is an appropriate tool to use in the analysis of mass pipeline inspection data[4]-[7]. This paper introduces VI to solve the inference problem and provide a solution for a hierarchical stochastic CGM to describe the defect-specific corrosion growth experienced in pipelines based on excessively large ILI datasets. To gauge the accuracy of the VI implementation in the model, the results are compared to a set of values generated using a stochastic gamma process that represents the corrosion growth process experienced by the pipe."
10.1007/s10845-022-02014-y,unknown,"Work-related musculoskeletal disorders are a very impactful problem, both socially and economically, in the manufacturing sector. To control their effect, standardised methods and technologies for ergonomic assessment have been developed. The main technologies used are inertial sensors and vision-based systems. The former are accurate and reliable, but invasive and not affordable for many companies. The latter use machine learning algorithms to detect human pose and assess ergonomic risks. In this paper, using data collecting by reproducing the working environment in LUBE, the major Italian kitchen manufacturer, we propose SPECTRE (Sensor-independent Parallel dEep ConvoluTional leaRning nEtwork): a fully sensor-independent learning model based on convolutional networks to classify postures in the workplace. This system assesses ergonomic risks in major body segments through Deep Learning with a minimal impact. SPECTRE’s performance is evaluated using established metrics for imbalanced data (precision, recall, F1-score and area under the precision-recall curve). Overall, SPECTRE shows good performance and, thanks to an agnostic explainable machine learning method, is able to extrapolate which patterns are significant in the input."
10.1177/2472555217752091,unknown,"DNA-encoded libraries (DELs) have emerged as an efficient and cost-effective drug discovery tool for the exploration and screening of very large chemical space using small-molecule collections of unprecedented size. Herein, we report an integrated automation and informatics system designed to enhance the quality, efficiency, and throughput of the production and affinity selection of these libraries. The platform is governed by software developed according to a database-centric architecture to ensure data consistency, integrity, and availability. Through its versatile protocol management functionalities, this application captures the wide diversity of experimental processes involved with DEL technology, keeps track of working protocols in the database, and uses them to command robotic liquid handlers for the synthesis of libraries. This approach provides full traceability of building-blocks and DNA tags in each split-and-pool cycle. Affinity selection experiments and high-throughput sequencing reads are also captured in the database, and the results are automatically deconvoluted and visualized in customizable representations. Researchers can compare results of different experiments and use machine learning methods to discover patterns in data. As of this writing, the platform has been validated through the generation and affinity selection of various libraries, and it has become the cornerstone of the DEL production effort at Lilly."
10.1109/ICMLC48188.2019.8949234,unknown,"This research is based on fuzzy comprehensive evaluation, and lists the fuzzy rule table for designers to control a scooter, in order to affect smoothness in the product design process of electric scooters for the elderly. Step 1: Use questionnaire survey method to understand the factors considered by the designer in designing the electric scooter for the elderly. Step 2: Establish hierarchical analysis and consider the factor weight set in electric scooter design. Step 3: Establish fuzzy hierarchical analysis, and sum up the evaluation result set, as based on the designer's experience. Step 4: Comprehensively consider the influence of all factors and obtain the judgment result. Step 5: List fuzzy rules as an application method to improve the traditional design of electric scooters for the elderly. This study found that the travel speed showed the greatest influence 24.98% on the set of factors affecting smoothness."
10.1109/ICAC54203.2021.9671186,unknown,"To feed this population, food production should be increased by at least 70%. Developing nations have a vast potential to increase the amount of food produced by doubling the current production. However, the traditional methods of farming are making agriculture unviable and inefficient. The increasing food production needs to be met by double the current level of farming. The conventional of farming is making industry uncompetitive and inefficient. This paper aims to analyze the various factors that affect the implementation of autonomous machinery in agriculture. The development of autonomous machinery for agriculture has emerged as vital step towards achieving this goal. Now a day's farmers are planning their cultivation by finding proper weather and geographical condition on their own experience, but they are failing to cultivate profitable crop and unaware of the diseases that will affect their crops, sometimes these diseases may affect their whole crops and let the farmers to sink in zero profit. Despite these issues plays a major role, there are some other problems also have an impact like, lack of irrigation plans and question of how and where to sell their cultivated crops. By considering these major threats we have planned to propose a solution to some of the selected issues. This can be achieved by applying machine learning algorithm, Image processing and IOT systems. By using our platform farmers will get a chance to plan their yield in a profitable way by using our optimized weather and geographical data."
10.1016/j.ijhydene.2025.04.378,unknown,"The tendency to damage of hydrogen to steel increases the possibility of flammable and explosive gas entering underground engineering significantly. A leakage monitoring method for buried hydrogen-doped natural gas pipeline based on vibration signals with machine learning is proposed. Firstly, the distributed vibration sensor captures the multisource vibration signals propagating in the soil. An optimal combination of wavelet basis functions, decomposition level, and threshold parameters is selected carefully for signal denoising and accurate extraction of leakage-generated signals. Then the characteristics extracted in different frequency bands are investigated with other influencing factors, including the hydrogen-doping ratio, which affects the propagation speed of the pressure wave. The unique characteristics of vibration signal generated by pipeline leakage are extracted. On this basis, combined with the high efficiency of machine learning recognition model, a leakage monitoring model for buried hydrogen-doped natural gas pipeline is established, which achieves a 2.01 % false alarm rate at a maximum positioning distance of 70 cm. It has been successfully applied to the leak detection and location of buried hydrogen-doped natural gas pipelines, which can significantly improve the safety and reliability of underground pipeline system engineering."
10.1109/TASE.2022.3174228,unknown,"In additive manufacturing (AM), final product geometries are often deformed or distorted. The deviations of three-dimensional (3D) shapes from their intended designs can be represented as 2D surfaces in a R3 space, which constitutes a complicated set of data for learning and predicting geometric quality. Patterns of deviation surfaces vary with shape geometries, sizes/volumes, materials, and AM processes. Our previous work has established an engineering-informed convolution framework to learn shape deviation from a small set of training products built with the same material and process. It incorporates the characteristics of the layer-wise shape forming process through a convolution formulation and the size factor for a category of smooth 3D shapes such as domes or cylinders. This study extends this fabrication-aware learning framework to a larger class of products including both smooth and non-smooth surfaces (polyhedral shapes). The key idea of learning heterogeneous deviation surface data under a unified model is to establish the association between the deviation profiles of smooth base shapes and those of non-smooth polyhedral shapes. The association, which is characterized by a novel 3D cookie-cutter function, views polyhedral shapes as being carved out from smooth base shapes. In essence, the AM process of building non-smooth shapes is mathematically decomposed into two steps: additively fabricate smooth base shapes using a convolution learning framework, and then subtract extra materials using a cookie-cutter function. The proposed joint learning framework of shape deviation data reflects this decomposition by adopting a sequential model estimation procedure. The model learning procedure first establishes the convolution model to capture the effects of layer-wise fabrication and sizes, and then estimates the 3D cookie-cutter function to realize geometric differences between smooth and non-smooth shapes. A new Gaussian process model is proposed to consider the spatial correlation among neighboring regions within a 3D shape and across different shapes. The case study demonstrates the feasibility and prospects of prescriptive learning of complex 3D shape deviations in AM and extension to broader engineering surface data. Note to Practitioners - Engineering processes such as 3D printing generate complex shape data in the form of 3D point clouds. Qualification and verification of 3D shapes involves modeling and learning of heterogeneous shape deviation data that are affected by both product geometries and process physics. This study develops an engineering-informed, small-sample machine learning methodology to learn and predict deviations of smooth and non-smooth 3D shapes in a unified modeling framework. The fabrication of a non-smooth 3D shape is mathematically decomposed into the smooth base shape formation and shape difference realization. Both process knowledge and shape geometries are captured in the learning framework. It provides a new data analytical tool for shape engineering in additive manufacturing and beyond."
10.1007/978-3-031-73344-4_53,unknown,"The current emergence of new digital technologies is opening up new prospects for industry, making production more efficient, safer, more flexible and more reliable than ever. Building on initiatives already carried out in various sectors, the application of these technologies to the operation of vitrification processes could make it possible to improve knowledge of processes, optimize their operation, train operators, help with predictive maintenance and assist with process control. The SOSIE project is a collaborative innovative project, which aims at providing an initial proof of concept for the implementation of digital technologies integrating Virtual Reality, Augmented Reality, and Artificial Intelligence. This paper presents the first developments realized in the project, where three kinds of digital twins have been developed on two complementary vitrification processes: first, the “visual” digital twin, based on an immersive and interactive application from reverse-built 3D models, secondly, the “augmented” digital twin, which connects the visual twin to the supervisory PLC and provides real-time feedback of supervisory information;, and thirdly, the “intelligent” digital twin, exploiting databases from operations to train Machine-Learning algorithms and helping predict breakdowns and process drifts."
10.1016/j.procir.2022.05.020,unknown,"Published by Elsevier B.V.In modern industries, there is a significant repository of sensor data, which contains a large amount of information. Unfortunately, this rich source of information is undervalued and underutilized, and its full potential is not fully exploited by modern day manufacturers. In the Industry 4.0 era, exploiting these powerful datasets is becoming critical for manufacturers' survival and competitiveness in the age of artificial intelligence. Cooperative and mutual efforts between academia and the industrial sector to take advantage of these rich datasets have the potential to reap extraordinary benefits for business, the economy and society. Applying the latest artificial intelligence methods could increase production efficiencies and reduce environmental impacts. In view of the availability of large amounts of sensor data and its lack of full utilization, this research proposes an artificial intelligence solution that combines data envelopment analysis (DEA), machine learning-based simulation and genetic algorithms to optimize the efficiency of production systems through recommendations of the optimal model settings. First, DEA is used to identify the efficient and inefficient states of a production system, this information is input to the second step to build a machine learning model that makes predictions through simulations and production efficiency scenarios. Then, a genetic algorithm proposes an optimal scenario with the corresponding settings. The main research contribution of this proposed solution is its unique combination of DEA with machine learning models and genetic algorithms."
10.1109/SKIMA57145.2022.10029567,unknown,"This paper discusses the health monitoring of synchronous generators used in hydropower plants. In recent years, maintenance of generating stations has shifted its focus from preventive maintenance to predictive maintenance. Machine prognosis is a significant part of condition-based maintenance. It intends to monitor and track the time evolution of a fault, so that maintenance can be performed, or the task can be terminated to avoid a catastrophic failure. This paper focuses on the machine learning model for health detection of stator winding of synchronous generator by using stator terminal voltage and stator winding current as input and stator winding temperature as output. More than five years of real-time data of a synchronous generator of Sardikhola hydropower plant in Nepal are collected to predict and present the Adaptive Neuro-Fuzzy Interference System (ANFIS) model. This model predicts faulty data range and healthy data range of stator winding temperature corresponding to stator terminal voltage and current."
10.1021/acs.analchem.4c03466,unknown,"High-performance liquid chromatography (HPLC) remains the gold standard for analyzing and purifying molecular components in solutions. However, developing HPLC methods is material- and time-consuming, so computer-aided shortcuts are highly desirable. In line with the digitalization of process development and the growth of HPLC databases, we propose a data-driven methodology to predict molecule retention factors as a function of mobile phase composition without the need for any new experiments, solely relying on molecular descriptors (MDs) obtained via simplified molecular input line entry system (SMILES) string representations of molecules. This new approach combines: (a) quantitative structure−property relationships (QSPR) using MDs to predict solute-dependent parameters in (b) linear solvation energy relationships (LSER) and (c) linear solvent strength (LSS) theory. We demonstrate the potential of this computational methodology using experimental data for retention factors of small molecules made available by the research community for which the MDs were obtained via SMILES string representations determined by the structural formulas of the molecules. This method can be adopted directly to predict elution times of molecular components; however, in combination with first-principle-based mechanistic transport models, the method can also be employed to optimize HPLC methods in-silico. Both options can reduce the experimental load and accelerate HPLC method development significantly, lowering the time and cost of the drug manufacturing cycle and reducing the time to market. Given the growing number and quality of HPLC databases, the predictive power of this methodology will only increase in the coming years."
10.1039/d3mh00788j,unknown,"Green hydrogen produced via electrochemical water splitting is a suitable candidate to replace emission-intensive fuels. However, the successful widespread adoption of green hydrogen is contingent on the development of low-cost, earth-abundant catalysts. Herein, machine learning models built on experimental data were used to optimize the precursor ratios of hydroxide-based electrocatalysts, with the objective of improving the product's electrocatalytic performance for overall water splitting. The Neural Network-based models were found to be the most effective in predicting and minimizing the overpotentials of the catalysts, reaching a minimum in two iterations. The relatively mild reaction conditions of the synthesis procedure, coupled with its scalability demonstrated herein, renders the optimized catalyst relevant for industrial implementation in the future. The optimized catalyst, characterized to be a molybdate-intercalated CoFe LDH, demonstrated overpotentials of 266 and 272 mV at 10 mA cm−2 for oxygen and hydrogen evolution reactions respectively in alkaline electrolyte, alongside unwavering stability for overall water splitting over 50 h. Overall, our results reflect the efficacy and advantages of machine learning strategies to alleviate the time and labour-intensive nature of experimental optimizations, which can greatly accelerate electrocatalysts research."
10.1109/ICHI.2017.104,unknown,"This tutorial demonstrates the application of a range of process analytics techniques to the study and improvement of clinical care pathways. The past decade has seen increasing interest in care pathway design, documentation and dissemination but formal methods for describing, monitoring and assessing pathways have yet to be established. Outside of healthcare other industries have well established techniques for business processes and there is much scope for translating these to fit the unique nature of healthcare. In particular data analytics, data mining, and machine learning have converged on a set of technologies called process mining which has the potential to lead to a step-change in using e-health record data to mine and manage care pathways. The tutorial presents an iterative method developed with the UK NHS and the Connected Health Cities programme that combines process mining with other process analytics methods including process modeling, process simulation and business process improvement. The session is highly interactive and based on a series of hands-on exercises around a worked example supplemented by case studies of completed work. Links to further study are provided and the aim is encourage further research and build a global community of practice."
10.1051/e3sconf/202561603031,unknown,"A comprehensive review of cyber-physical architectures for DC microgrids is presented, focusing on the integration of deep learning and LoRa technology for secure, efficient, and scalable communication networks. DC microgrids, with their decentralized energy resources and low inertia, face challenges such as real-time monitoring, fault detection, and vulnerability to cyber-attacks. The review highlights the potential of LoRa technology for long-range, low-power communication, ensuring seamless data exchange between distributed components, including renewable energy sources, storage systems, and control units. Deep learning models are explored for their application in predictive maintenance, fault detection, and cyber-attack mitigation, such as false data injection attacks. By integrating these technologies, the review underscores enhanced operational efficiency, robust cybersecurity, and real-time control in DC microgrids. The scalability of such architectures is evaluated, showing suitability for diverse microgrid scales, from residential setups to utility-level implementations. Findings from this review emphasize the synergy between IoT-driven communication networks and machine learning models in addressing energy management and cybersecurity challenges. The paper calls for standardized frameworks and collaborative efforts to further develop and deploy secure, resilient DC microgrid architectures, laying the groundwork for sustainable and efficient energy systems of the future."
10.1007/978-981-96-7499-2_40,unknown,"2026.Emotional intelligence in artificial intelligence is an important and exciting growing field with much potential for assisting human–computer interactions in different domains. Self and others’ emotional awareness are referred to as emotional intelligence and is steadily being deemed paramount to develop technologies in artificial intelligence that will in the end be effective when handling needs and human states. In recent researches, it has been observed that although in real way, AI cannot be so expected to feel like human beings’ simulation does exhibit mimic emotions that add to the enhancement of the user experience and acceptance more so in service-oriented applications Emotional Simulation of Artificial Intelligence. The awareness of the EI is really rising in various organizations in today’s workplaces especially with integration and automation of work using artificial intelligence. Since the roles and responsibilities of human beings working in industries will change due to AI and automation, EI skills will be are important to be applied by the employee’s at all organizational levels. However, machines are good at things that involve rules of logic and therefore getting them to understand and among the limitations of URLs of expressing human feelings, answering to the feelings still remain a problem to be solved in AI. Hence, improving EI becomes something of enormous value to be competent in the new era of jobs."
10.1109/ICUFN.2018.8436973,unknown,"In this paper, we apply the data accumulated through E-IOT platform to machine learning method to find significant variables first and predict the electric power generated in manufacturing process by using these variables. Pre-processing such as resampling of data was carried out before the prediction. In order to select the significant variables, 25 variables were derived using Lasso (least absolute shrinkage and selection operator), one of the machine learning techniques. We used Deep Learning's LSTM technique, one of the field of machine learning for the prediction."
10.1007/s10845-024-02558-1,unknown,"Reconfigurable manufacturing systems represent the most adequate production paradigm due to their ability to meet mass customized needs while ensuring cost-effective flexibilities and performances. However, digital solutions are required to manage these dynamic environments over working shifts and processes’ reconfiguration. In this scenario, this work proposes a layout and task-insensitive cyber-physical architecture to monitor human-centric reconfigurable manufacturing systems. Workers’ motion patterns and industrial resources’ positions are acquired through a radio-frequency-based real-time locating system. These data streams are fed into a machine-learning cyber layer to segment operators’ activities during production cycles into two steps. The first computational stream assigns workers’ motion patterns to industrial resources regardless of the system configuration. The following step distinguishes workers’ operations into value-added and non-value-added. These outputs are stored in a decision support system where customized callback functions develop key performing indicators to monitor the performance of such reconfigurable human-centric environments. The validity of the cyber-physical architecture is demonstrated in an industrial-related pilot environment, involving 40 workers and 8 production set-ups."
10.1063/5.0098632,unknown,"Hydraulic system has been the mainstream choice in large engineering equipment due to its smooth transmission, large bearing capacity, and small volume. However, because of the tightness and invisibility in hydraulic equipment, it is difficult to check and predict its faults. Common fault diagnosis and maintenance methods for the hydraulic system can be divided into two types: a signal analysis based on the mathematical model and a machine learning algorithm based on artificial intelligence. The first method can only diagnose specific faults based on the mathematical model, which is not universal, and the second one must rely on abundant history fault data, which is impossible to obtain in the early running stage. In order to address these questions, a digital twin framework is proposed which combines the virtual model with the real part to solve practical problems. As a concrete realization form of a five-dimension digital twin model, this framework provides a more feasible solution mode for fault diagnosis in the hydraulic system. Meanwhile, it expands the functions of faults prediction and digital model display. A case study of a hydraulic cylinder is used to illustrate the effectiveness of the proposed framework. The experimental result shows that this method can improve diagnosis accuracy for a hydraulic cylinder greatly compared with the non-interactive simulation model. Meanwhile, with the supplement of actual fault data, the diagnosis accuracy can be further improved, which has a certain growth ability and good applicability."
10.2118/203995-MS,unknown,"Copyright 2021, Society of Petroleum Engineers.Sour gas injection operation has been implemented in Tengiz since 2008 and will be expanded as part of a future growth project. Due to limited gas handling capacity, producing wells at high GOR has been a challenge, resulting in potential well shutdowns. The objective of this study was to establish an efficient optimization workflow to improve vertical/areal sweep, thereby maximizing recovery under operation constraints. This will be enabled through conformance control completions that have been installed in many production/injection wells. A Dual-Porosity and Dual-Permeability (DPDK) compositional simulation model with advanced Field Management (FM) logic was used to perform the study. Vertical conformance control was implemented in the model enabling completion control of 4 compartments per well. A model-based optimization workflow was defined to maximize recovery. Objective functions considered were incremental recovery 1) after 5 years, and 2) at the end of concession. Control parameters considered for optimization are 1) injection allocation rate, 2) production allocation rate, 3) vertical completion compartments for injectors and producers. A combination of different optimization techniques e.g., Genetic Algorithm and Machine-Learning sampling method were utilized in an iterative manner. It was quickly realized that due to the number of mixed categorical and continuous control parameters and non-linearity in simulation response, the optimization problem became almost infeasible. In addition, the problem also became more complex with multiple time-varying operational constraints. Parameterization of the control variables, such as schedule and/or FM rules optimization were revisited. One observation from this study was that a hybrid approach of considering schedule-based optimization was the best way to maximize short term objectives while rule-based FM optimization was the best alternative for long term objective function improvement. This hybrid approach helped to improve practicality of applying optimization results into field operational guidelines. Several optimization techniques were tested for the study using both conceptual and full-field Tengiz models, realizing the utility of some techniques that could help in many field control parameters. However, all these optimization techniques required more than 2000 simulation runs to achieve optimal results, which was not practical for the study due to constraints in computational timing. It was observed that limiting control parameters to around 50 helped to achieve optimal results for the objective functions by conducting 500 simulation runs. These limited number of parameters were selected from flow diagnostics and heavy-hitter analyses from the pool of original 800+ control parameters. The novelty of this study includes three folds: 1) The model-based optimization outcome obtained in this study has been implemented in the field operations with observation of increased recovery 2) the hybrid optimization of both schedule and operation rule provided practicality in terms of optimization performance as well as application to the field operation 3) provides lessons learned from the application of optimization techniques ranging from conventional Genetic Algorithm to Machine-Learning supported technique."
10.1109/ICSCSA64454.2024.00033,unknown,"Machine Learning (ML), Deep Learning (DL), Internet of Things (IoT), Artificial Intelligence (AI) and Data Science are integrated to create innovative solutions that are powering industries today like never before. This paper reviews these technologies and how they can work together to transform industries like healthcare, finance, and manufacturing, as well as the immensely important space of smart cities. With ML and DL-driven analytics for predictions, IoT-based real-Time data capture mechanisms, AI making informed decisions along data science generating insights from the data makes organizations efficient in every aspect as well as reliable and innovative. Some example applications are predictive maintenance in manufacturing, personalized medicine in healthcare, algorithmic trading in finance and the development of smart/sustainable urban environments. While these potboilers offer a hopeful advantage, they also come with some hurdles, data privacy/security, integration complexity and the need for high-end technical skills being the topmost. In this manuscript, some case studies of success are highlighted in the belonging field and discuss the challenges for incorporation today along with future directions for seamless integration aimed at promoting even greater innovation."
10.3389/fmats.2021.803875,unknown,"Copyright © 2022 Chiang, Chiu and Chang.The emerging demand for advanced structural and biological materials calls for novel modeling tools that can rapidly yield high-fidelity estimation on materials properties in design cycles. Lattice spring model, a coarse-grained particle spring network, has gained attention in recent years for predicting the mechanical properties and giving insights into the fracture mechanism with high reproducibility and generalizability. However, to simulate the materials in sufficient detail for guaranteed numerical stability and convergence, most of the time a large number of particles are needed, greatly diminishing the potential for high-throughput computation and therewith data generation for machine learning frameworks. Here, we implement CuLSM, a GPU-accelerated compute unified device architecture C++ code realizing parallelism over the spring list instead of the commonly used spatial decomposition, which requires intermittent updates on the particle neighbor list. Along with the image-to-particle conversion tool Img2Particle, our toolkit offers a fast and flexible platform to characterize the elastic and fracture behaviors of materials, expediting the design process between additive manufacturing and computer-aided design. With the growing demand for new lightweight, adaptable, and multi-functional materials and structures, such tailored and optimized modeling platform has profound impacts, enabling faster exploration in design spaces, better quality control for 3D printing by digital twin techniques, and larger data generation pipelines for image-based generative machine learning models."
10.1016/j.jprocont.2022.06.011,unknown,"At the same time, modern industry is facing diversified market demand instead of ultra-large-scale demand, resulting in typical variable conditions, which enhances the nonstationary characteristics of modern industry, and brings great challenges to the monitoring of industrial processes. In this regard, this paper analyzes the complex characteristics of nonstationary industrial operation, reveals the effects on operating condition monitoring, and summarizes the difficulties faced by varying condition monitoring. Furthermore, by reviewing the recent 30 years of development of data-driven methods for industrial process monitoring, we sorted out the evolution of nonstationary monitoring methods, and analyzed the features, advantages and disadvantages of the methods at different stages. In addition, by summarizing the existing related research methods by category, we hope to provide reference for monitoring methods of nonstationary process. Finally, combined with the development trend of industrial artificial intelligence technologies, some promising research directions are given in the field of nonstationary process monitoring."
10.1111/itor.13412,unknown,"Global shipment volumes have been increasing due to changes in the business environment of e-commerce and manufacturing. Consequently, container vessels carry more cargo for international trade, increasing uncertainties in terminal management. Terminal operators manage terminals by establishing a proactive schedule that responds to disruptions such as vessel delays, and the introduction of buffer time is a representative proactive strategy. In this study, by analyzing historical delay data with machine learning, we propose data-driven buffer times to consider the heterogeneous arrival uncertainty of vessels. Thus, we proactive scheduling with data-driven buffer times according to the desired robustness levels. This is a novel study on berth scheduling that applies data mining approaches to improve operations research techniques. Numerical experiments were conducted on the berth scheduling with time-invariant quay crane assignment using real-life data to validate the effectiveness of the proposed method. These experimental results revealed that applying the data-driven buffer time could effectively reduce the cost incurred at the terminal by balancing baseline and recovery costs. In addition, our proposed methodology ensured the quality of the solution compared with a stochastic method and reduced the computational burden of a stochastic problem by using the data-driven buffer times obtained prior to the solution construction. Therefore, the proposed method can be introduced into terminal operations to overcome the deficiencies of traditional approaches in terms of academic perspective."
10.2118/213138-MS,unknown,"All rights reserved.This study proposes a method for integrated asset modelling by using machine learning along withoperations research algorithms to perform real-time constrained production optimization and maximizeoperational profit in a real-time basis. The methodology, which is mainly about the transformation of field and well performance to equations,inequalities, and matrixes, was tested successfully in the operation of a gas condensate field whereoperational profit increased, in abnormal conditions when personnel normally act mostly based onexperience, pre-conceived notion, or solutions to previously solved problems. The study provides a solutionwith full data-driven objectivity for decision-making using the results of a mixed integer non-linearprogramming problem."
10.3390/en18174637,unknown,"This article presents an overview of selected research focusing on digital real-time simulation (DRTS) in the context of digital twin (DT) realization with the primary aim of enabling the intelligent fault diagnosis (FD) and condition-based monitoring (CBM) of electrical machines. The concept of standalone DTs in conventional multiphysics digital offline simulations (DoSs) is widely utilized during the conceptualization and development phases of electrical machine manufacturing and processing, particularly for virtual testing under both standard and extreme operating conditions, as well as for aging assessments and lifecycle analysis. Recent advancements in data communication and information technologies, including virtual reality, cloud computing, parallel processing, machine learning, big data, and the Internet of Things (IoT), have facilitated the creation of real-time DTs based on physics-based (PHYB), circuit-oriented lumped-parameter (COLP), and data-driven approaches, as well as physics-informed machine learning (PIML), which is a combination of these models. These models are distinguished by their ability to enable real-time bidirectional data exchange with physical electrical machines. This article proposes a predictive-level framework with a particular emphasis on real-time multiphysics modeling to enhance the efficiency of the FD and CBM of electrical machines, which play a crucial role in various industrial applications."
10.1002/advs.202308152,unknown,"Advanced Science published by Wiley-VCH GmbH.Underwater superhydrophobic surfaces stand as a promising frontier in materials science, holding immense potential for applications in underwater infrastructure, vehicles, pipelines, robots, and sensors. Despite this potential, widespread commercial adoption of these surfaces faces limitations, primarily rooted in challenges related to material durability and the stability of the air plastron during prolonged submersion. Factors such as pressure, flow, and temperature further complicate the operational viability of underwater superhydrophobic technology. This comprehensive review navigates the evolving landscape of underwater superhydrophobic technology, providing a deep dive into the introduction, advancements, and innovations in design, fabrication, and testing techniques. Recent breakthroughs in nanotechnology, magnetic-responsive coatings, additive manufacturing, and machine learning are highlighted, showcasing the diverse avenues of progress. Notable research endeavors concentrate on enhancing the longevity of plastrons, the fundamental element governing superhydrophobic behavior. The review explores the multifaceted applications of superhydrophobic coatings in the underwater environment, encompassing areas such as drag reduction, anti-biofouling, and corrosion resistance. A critical examination of commercial offerings in the superhydrophobic coating landscape offers a current perspective on available solutions. In conclusion, the review provides valuable insights and forward-looking recommendations to propel the field of underwater superhydrophobicity toward new dimensions of innovation and practical utility."
10.1109/ICPS51978.2022.9816906,unknown,"Industrial automatic sewing machines are used for the production of technical textiles and safety critical work pieces such as parachutes or safety belts. Hence, the production does not tolerate sewing errors within the final product. Unfortunately, errors like skip stitches or illusive sewing may occur even on correctly adjusted production machines due to their complex kinematics. A recently developed sensor for such production systems is able to measure the lower thread rotation, a key parameter of the sewing process. This opens up the possibility to analyze the sewing quality on the basis of time series data whilst the work piece is still in production, thus being able to instantly detect anomalous sewing operations which leads to reduced cost for quality control and improves safety. In this research we analyze the suitability of existing Neural Network based Machine Learning algorithms to detect anomalies within the available process data. We give an overview regarding the Machine Learning pipeline, the tested Neural Network types and the experimental results. We show that several Neural Network architectures are able to detect anomalies within the sewing process."
10.14419/xk2n4x45,unknown,"“Every End Marks a New Beginning,” Cycle Continues—Life Changes! The world takes a step forward towards the future. The future is where revolutionary technology takes place and exploits quantum mechanics principles like superposition, entanglement, and interference. By existing in multiple states simultaneously, qubits perform fast and optimize operations growth. This paper explores the use case of quantum computing’s potential and integration with cutting-edge fields such as nanotechnology, AI, advanced DNA data storage, and sustainable Li-S energy storage devices. Achieving quantum computer integration with nanotechnology, advancing hardware for future challenges, and space exploration’ missions by precisely engineering qubit materials, superconducting circuits, and quantum dots. Graphene, carbon nanotubes, and fabrication techniques for driving scalable quantum device production. Quantum machine learning (QML) algorithms to solve complex optimizations and predictive tasks. Researching optimal solutions in data and battery storage systems and finding the best algorithm in quantum networking and communication for long-range connectivity with a fast and secure network. Investigating challenges such as error corrections, cost, accessibility, and adaptability. Combining all modern innovations with one technology offers the best result that can change the theoretical fiction world into the real world, not today, but in a few decades."
10.1007/978-3-031-12547-8_43,unknown,"The machine learning (ML) field is increasingly impacting industries within the Industry 4.0 paradigm, which among other things, enables the usage of vast amounts of data. Combining data and ML consequently enables continuous improvement that differs from conventional continuous improvement, especially in higher efficiency on default detection. However, scientific literature needs to be updated continuously. Hence, this work aims to gather research information on advancements in ML applications in organisations for continuous improvement purposes. Following the PRISMA Statement, 11 relevant articles were analysed. Results evidenced that most research is case-specific and focuses on applicability. Furthermore, it was observed that most papers are from the manufacturing industry. Although some theoretical research indicates the potential of ML applications in the operations domain (i.e., before and post-production processes), the literature in this segment is lacking. It can be concluded that the potential of ML in management systems is dependent on the amount and quality of data. However, this latter comes at a high cost and therefore, careful cost–benefit analysis should be made before adopting ML in businesses. Overall, this review provided promising perspectives for applying ML within quality systems and potential leading ways for continuous improvement in safety, environment and integrated management systems."
10.3390/cryst15030264,unknown,"This study aims to optimize the turning parameters for EN-GJL-250 grey cast iron using hybrid machine learning techniques integrated with multi-objective optimization algorithms. The experimental design focused on evaluating the impact of cutting tool type, testing three tools: uncoated and coated silicon nitride (Si3N4) ceramic inserts and coated cubic boron nitride (CBN). Key cutting parameters such as depth of cut (ap), feed rate (f), and cutting speed (Vc) were varied to examine their effects on surface roughness (Ra), cutting force (Fr), and power consumption (Pc). The results showed that the coated Si3N4 tool achieved the best surface finish, with minimal cutting force and power consumption, while the uncoated Si3N4 and CBN tools performed slightly worse. Advanced optimization models including improved grey wolf optimizer–deep neural networks (DNN-IGWOs), genetic algorithm–deep neural networks (DNN-GAs), and deep neural network–extended Kalman filters (DNN-EKF) were compared with traditional methods like Support Vector Machines (SVMs), Decision Trees (DTs), and Levenberg–Marquardt (LM). The DNN-EKF model demonstrated exceptional predictive accuracy with an R2 value of 0.99. The desirability function (DF) method identified the optimal machining parameters for the coated Si3N4 tool: ap = 0.25 mm, f = 0.08 mm/rev, and Vc = 437.76 m/min. At these settings, Fr ranged between 46.424 and 47.405 N, Ra remained around 0.520 µm, and Pc varied between 386.518 W and 392.412 W. The multi-objective grey wolf optimization (MOGWO) further refined these parameters to minimize Fr, Ra, and Pc. This study demonstrates the potential of integrating machine learning and optimization techniques to significantly enhance manufacturing efficiency."
10.1007/s10845-025-02690-6,unknown,"Additive manufacturing (AM), particularly metal-based AM, has transformed the manufacturing domain by easing the development of complex, high-performance components with minimal waste. This paper reviews various computational modeling techniques employed in the AM processes, highlighting their trends, advancements, and challenges. It explores fundamental mechanisms such as powder handling, energy-material interactions, melt pool dynamics, microstructural evolution, and defect formation, emphasizing their complexity and the need for accurate models. The paper categorizes computational frameworks into multi-scale and multi-physics models. Micro-scale methods like phase-field modeling, cellular automata, and Monte Carlo techniques, used to predict microstructural changes are discussed in detail. Meso-scale models address intermediate interactions, while macro-scale approaches, such as finite element modeling and CALPHAD-based heat transfer analysis, simulate stress, distortion, and thermal profiles. Emerging data-driven models and real-time simulations, which are pivotal for AM process optimization, are also reviewed in detail. Challenges in aligning computational models with experimental validation due to scalability, cost, and industrial integration barriers are highlighted. Future research areas, including advancements in machine learning, enhanced multi-scale modeling, and improved validation protocols, are discussed in this work."
10.3390/ma18102248,unknown,"Sodium-ion batteries (SIBs) have emerged as a viable alternative to lithium-ion technologies, with carbon-based anodes playing a pivotal role in addressing key challenges of sodium storage. This review systematically examines hard carbon as the premier anode material, elucidating its dual sodium storage mechanisms: (1) sloping capacity (2.0–0.1 V vs. Na+/Na) from surface/defect adsorption and (2) plateau capacity (<0.1 V) via closed-pore filling and pseudo-graphitic intercalation. Through critical analysis of recent advancements, we establish that optimized hard carbon architectures delivering 300–400 mAh/g capacity require precise coordination of pseudo-graphitic domains (d002 = 0.36–0.40 nm) and <1 nm closed pores. This review ultimately provides a design blueprint for next-generation carbon anodes, proposing three research frontiers: (1) machine learning-guided microstructure optimization, (2) dynamic sodiation/desodiation control in sub nm pores, and (3) scalable manufacturing of heteroatom-doped architectures with engineered pseudo-graphitic domains. These advancements position hard carbon anodes as critical enablers for high-performance, cost-effective SIBs in grid-scale energy storage applications."
10.1109/CISIS.2012.211,unknown,"In this paper we present a novel approach to the problem of understanding, monitoring, and controlling the machining process of composites materials. The approach is called Logical Analysis of Data (LAD). It is based on data mining and pattern recognition, and uses a machine learning artificial intelligence technique. This novel approach is used for the first time in order to define machining conditions that lead to conforming products, and also conditions which will lead to nonconforming products. In this paper, we introduce the LAD technique, we apply it to the machining of composites, and we report on the results based on data obtained experimentally. We conclude with a discussion of the potential use of LAD in manufacturing. © 2012 Crown Copyright."
10.4271/2023-36-0132,unknown,"Predictive maintenance plays a crucial role in the context of Industry 4.0, and the adoption of Digital Twin methodologies has emerged as a promising approach for predicting the remaining useful lifetime of assets, particularly after a fault is identified. However, there is a lack of understanding regarding how to effectively apply digital twins for prognosis purposes, including estimating confidence intervals and identifying root causes of faults. To address this gap, this paper presents a methodology based on a comprehensive literature review, aiming to provide a systematic approach for predicting the remaining useful lifetime of assets. The proposed methodology encompasses several steps. It starts with data collection from physical assets or relevant databases, followed by modeling the asset's behavior using dynamic equations. Machine learning algorithms are then applied to predict the asset's final state in response to corrective actions. The interpretation systems provide insights and recommendations based on the virtual model, which can be further utilized by users for decision-making or implemented directly in the physical product. This methodology focuses specifically on implementing digital twins to determine the remaining lifetime of battery discharge. By following the step-by-step procedure outlined in this study, practitioners and researchers can effectively implement digital twin models and utilize them for prognosis purposes, enhancing the accuracy of predictions and enabling proactive maintenance strategies. This research contributes to bridging the gap in understanding the application of digital twins for prognosis, presenting a systematic methodology that can be applied in various domains to predict the remaining useful lifetime of assets, thereby optimizing maintenance processes and ensuring efficient asset management."
10.3390/su152215922,unknown,"The purpose of this work is to substantiate the approach to assessing the state of organic waste generation by households of a given community, which is based on passive production observations and intellectual analysis of statistical data, which ensures consideration of the factors and features of organic waste generation, as well as the development of qualitative models for forecasting their receipt. To achieve the goal, the following tasks were solved: the analysis of the state of organic waste generation by households in the EU countries was performed; an approach to assessing the state of organic waste generation by households of a given community is proposed; based on the use of the proposed approach, and models for assessing the state of organic waste generation of households in a given community were substantiated. The hypothesis of the study is to substantiate and use an approach to assessing the generation of organic waste by households in individual communities, based on the method of association learning and search for association rules, which will identify factors that have a significant impact on the volume of organic waste generated by households, the consideration of which will improve the accuracy of forecasting models and improve the quality of management of the processes of collection and processing of this waste in communities. The research methodology used allows for the use of data mining, probability theory, mathematical statistics, machine learning technology, and the Associative Rule Learning (ARL) method. Based on the use of a reasonable algorithm, they identify key trends and relationships between the factors of organic waste generation in communities in different countries, which is the basis for creating accurate models for predicting the volume of collection and processing of this waste in communities. The study found that the largest number of households produced organic waste per capita in the range of 0.14–0.25 kg/person. At the same time, most households have from two to four residents and are located on the adjoining territory from 350 m2 to 680 m2. Based on the method of learning associative rules, it was found that there are no close correlations between individual factors that determine the daily volume of organic waste generation by households per capita. The highest correlation coefficient between the type of housing and the income level of household residents is 0.13. The number of residents and the occupied area of the adjacent territory have the greatest impact on the daily volume of organic waste generated by households per capita. The substantiated associative rules of relationships, as well as the diagrams of relationships between factors, have helped to identify those factors that have the greatest impact on the volume of organic waste generation. They are the basis for creating accurate models for predicting the volume of collection and planning the processing of this waste in communities. Based on the proposed approach, Python 3.9 software was developed. It makes it possible to quickly carry out calculations and perform a quantitative assessment of the state of organic waste generation by households of a given community according to the specified rules of association between the volumes of organic waste generation and their factors. The results of the study are the basis for the further development of models for accurate forecasting of the collection and planning of the processing of organic waste from households in communities."
10.1177/14680874241229514,unknown,"For energy-assisted compression ignition (EACI) engine propulsion at high-altitude operating conditions using sustainable jet fuels with varying cetane numbers, it is essential to develop an efficient engine control system for robust and optimal operation. Control systems are typically trained using experimental data, which can be costly and time consuming to generate due to setup time of experiments, unforeseen delays/issues with manufacturing, mishaps/engine failures and the consequent repairs (which can take weeks), and errors in measurements. Computational fluid dynamics (CFD) simulations can overcome such burdens by complementing experiments with simulated data for control system training. Such simulations, however, can be computationally expensive. Existing data-driven machine learning (ML) models have shown promise for emulating the expensive CFD simulator, but encounter key limitations here due to the expensive nature of the training data and the range of differing combustion behaviors (e.g. misfires and partial/delayed ignition) observed at such broad operating conditions. We thus develop a novel physics-integrated emulator, called the Misfire-Integrated GP (MInt-GP), which integrates important auxiliary information on engine misfires within a Gaussian process surrogate model. With limited CFD training data, we show the MInt-GP model can yield reliable predictions of in-cylinder pressure evolution profiles and subsequent heat release profiles and engine CA50 predictions at a broad range of input conditions. We further demonstrate much better prediction capabilities of the MInt-GP at different combustion behaviors compared to existing data-driven ML models such as kriging and neural networks, while also observing up to 80 times computational speed-up over CFD, thus establishing its effectiveness as a tool to assist CFD for fast data generation in control system training."
10.1016/j.rineng.2025.106038,unknown,"However, ensuring their reliability and longevity presents substantial challenges due to degradation caused by various internal and external factors. This review paper addresses the critical problem of accurately estimating the state of health (SoH), remaining useful life (RUL), and battery ageing in dynamic operating environments. The existing literature lacks a consolidated comparative analysis of traditional, adaptive, and emerging data-driven approaches to battery health management, particularly in the context of real-world applications. This review presents an in-depth synthesis of conventional methods, model-based techniques, adaptive filtering, and artificial intelligence (AI)-driven strategies including machine learning (ML), fuzzy logic, and cloud-integrated frameworks for SoH, RUL, and ageing prediction. Furthermore, the paper discusses the implications of battery cycling databases and highlights how open-source data and modern computational advancements support scalable predictive analytics. A comparative critique of various methodologies is provided to evaluate performance, adaptability, and real-world feasibility. The review identifies key challenges and research gaps, emphasizing the need for model interpretability, real-time validation, and long-term performance assessment. Overall, this paper contributes to the academic and industrial understanding of predictive battery management, guiding future research toward the development of accurate, interpretable, and scalable models that ensure sustainable EV battery operation."
