{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbe61b2",
   "metadata": {},
   "source": [
    "- Apply rule-based extraction to identify machine learning methods in abstracts\n",
    "- Test two complementary approaches:\n",
    "  - **Regex-based matching** for known ML terms\n",
    "  - **SciSpaCy + EntityRuler** for robust phrase detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5921f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "from typing import List\n",
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50837a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All directories verified/created.\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "\n",
    "data_path = Path(\"../../data/short-raw-refs-abs\")\n",
    "processed_abstracts_path = Path(\"../../data/processed/abstracts\")\n",
    "save_path = processed_abstracts_path / \"regex_scispacy\"\n",
    "ml_methods_path = Path(\"../../ml_methods/ml_methods_dict.json\")\n",
    "\n",
    "\n",
    "# Ensure directories exist\n",
    "for p in [data_path, processed_abstracts_path, save_path]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"All directories verified/created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a276afda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 52290 abstracts from 24 queries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105018574505</td>\n",
       "      <td>10.1016/j.measurement.2025.119261</td>\n",
       "      <td>Distillation anomaly and fault detection based...</td>\n",
       "      <td>© 2025 The Author(s)The detection of anomalies...</td>\n",
       "      <td>Indeed, highly efficient systems do not always...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105019192533</td>\n",
       "      <td>10.1007/978-3-032-06118-8_30</td>\n",
       "      <td>From Lab to Factory: Pitfalls and Guidelines f...</td>\n",
       "      <td>© The Author(s), under exclusive license to Sp...</td>\n",
       "      <td>The detection and localization of quality-rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105016669957</td>\n",
       "      <td>10.1007/978-3-032-04200-2_5</td>\n",
       "      <td>Intelligent Defect Detection for Manufacturing...</td>\n",
       "      <td>© The Author(s), under exclusive license to Sp...</td>\n",
       "      <td>In modern Industry, I4.0, artificial intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-85218693791</td>\n",
       "      <td>10.1038/s41598-025-90810-w</td>\n",
       "      <td>Hybrid machine learning framework for predicti...</td>\n",
       "      <td>© The Author(s) 2025.The critical necessity fo...</td>\n",
       "      <td>The critical necessity for sophisticated predi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105018301117</td>\n",
       "      <td>10.1016/j.comnet.2025.111753</td>\n",
       "      <td>BGP anomaly detection using the raw internet t...</td>\n",
       "      <td>© 2025 The AuthorsThe Border Gateway Protocol ...</td>\n",
       "      <td>Hence, detecting any anomaly concerning BGP an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          query_id                  eid  \\\n",
       "0  ml_anomaly_detection_production  2-s2.0-105018574505   \n",
       "1  ml_anomaly_detection_production  2-s2.0-105019192533   \n",
       "2  ml_anomaly_detection_production  2-s2.0-105016669957   \n",
       "3  ml_anomaly_detection_production   2-s2.0-85218693791   \n",
       "4  ml_anomaly_detection_production  2-s2.0-105018301117   \n",
       "\n",
       "                                 doi  \\\n",
       "0  10.1016/j.measurement.2025.119261   \n",
       "1       10.1007/978-3-032-06118-8_30   \n",
       "2        10.1007/978-3-032-04200-2_5   \n",
       "3         10.1038/s41598-025-90810-w   \n",
       "4       10.1016/j.comnet.2025.111753   \n",
       "\n",
       "                                               title  \\\n",
       "0  Distillation anomaly and fault detection based...   \n",
       "1  From Lab to Factory: Pitfalls and Guidelines f...   \n",
       "2  Intelligent Defect Detection for Manufacturing...   \n",
       "3  Hybrid machine learning framework for predicti...   \n",
       "4  BGP anomaly detection using the raw internet t...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  © 2025 The Author(s)The detection of anomalies...   \n",
       "1  © The Author(s), under exclusive license to Sp...   \n",
       "2  © The Author(s), under exclusive license to Sp...   \n",
       "3  © The Author(s) 2025.The critical necessity fo...   \n",
       "4  © 2025 The AuthorsThe Border Gateway Protocol ...   \n",
       "\n",
       "                                           clean_abs  \n",
       "0  Indeed, highly efficient systems do not always...  \n",
       "1  The detection and localization of quality-rela...  \n",
       "2  In modern Industry, I4.0, artificial intellige...  \n",
       "3  The critical necessity for sophisticated predi...  \n",
       "4  Hence, detecting any anomaly concerning BGP an...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load abstracts dataset\n",
    "\n",
    "abstracts_path = processed_abstracts_path / \"abstracts.csv\"\n",
    "df = pd.read_csv(abstracts_path)\n",
    "\n",
    "print(f\"Loaded {len(df)} abstracts from {df['query_id'].nunique()} queries.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f60535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 52290\n",
      "After removing duplicates: 33130\n",
      "Remaining duplicate DOIs: 0\n"
     ]
    }
   ],
   "source": [
    "# Count how many rows each query_id has\n",
    "query_counts = df[\"query_id\"].value_counts().to_dict()\n",
    "\n",
    "# Create a copy and map the counts to each row\n",
    "df = df.copy()\n",
    "df[\"query_size\"] = df[\"query_id\"].map(query_counts)\n",
    "\n",
    "# Sort so that query groups with fewer rows are prioritized\n",
    "df_sorted = df.sort_values(by=\"query_size\", ascending=True)\n",
    "\n",
    "# Remove duplicate DOIs, keeping the one in the smallest query group\n",
    "df_dedup = df_sorted.drop_duplicates(subset=\"doi\", keep=\"first\").drop(columns=[\"query_size\"])\n",
    "\n",
    "# Print results\n",
    "print(\"Original dataset size:\", len(df))\n",
    "print(\"After removing duplicates:\", len(df_dedup))\n",
    "print(\"Remaining duplicate DOIs:\", df_dedup[\"doi\"].duplicated().sum())\n",
    "\n",
    "df = df_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ec40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ml_methods_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    ml_methods_dict = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec15316",
   "metadata": {},
   "source": [
    "## Regex matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f33c5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33130/33130 [02:36<00:00, 211.03it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_methods(text, term_dict):\n",
    "    # Return empty list if input is not a string\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    found = []\n",
    "    \n",
    "    for method, phrases in term_dict.items():\n",
    "        for phrase in phrases:\n",
    "            # Escape special characters and enforce word boundaries\n",
    "            pattern = r\"\\b\" + re.escape(phrase.lower()) + r\"\\b\"\n",
    "            \n",
    "            # Perform case-insensitive boundary-safe regex search\n",
    "            if re.search(pattern, text.lower()):\n",
    "                found.append(method)\n",
    "                break  # Stop checking more variants for this method\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    return list(dict.fromkeys(found))\n",
    "\n",
    "# Apply extraction with pandas progress bar\n",
    "tqdm.pandas()\n",
    "df[\"ml_methods_regex\"] = df[\"clean_abs\"].fillna(\"\").progress_apply(\n",
    "    lambda x: extract_methods(x, ml_methods_dict)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6cde623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_count\n",
      "0     16875\n",
      "1      7586\n",
      "2      4283\n",
      "3      2132\n",
      "4      1152\n",
      "5       560\n",
      "6       297\n",
      "7       131\n",
      "8        71\n",
      "9        24\n",
      "10        9\n",
      "11        4\n",
      "12        2\n",
      "13        4\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ml_methods_regex\n",
       "Neural Network                    6747\n",
       "Random Forest                     3103\n",
       "Support Vector Machine            2176\n",
       "Decision Tree                     1652\n",
       "Convolutional Neural Network      1365\n",
       "Gradient Boosting                 1185\n",
       "LSTM                              1107\n",
       "XGBoost                           1091\n",
       "Reinforcement Learning             976\n",
       "Linear Regression                  906\n",
       "Bayesian Method                    893\n",
       "Genetic Algorithm                  843\n",
       "K-Nearest Neighbors                813\n",
       "Support Vector Regression          716\n",
       "Particle Swarm Optimization        597\n",
       "Principal Component Analysis       587\n",
       "Deep Neural Network                483\n",
       "Logistic Regression                473\n",
       "SHAP                               460\n",
       "Autoencoder                        451\n",
       "Transformers                       442\n",
       "Multi-Layer Perceptron             420\n",
       "Gaussian Process Regression        396\n",
       "K-Means                            345\n",
       "Recurrent Neural Network           318\n",
       "Explainable AI                     294\n",
       "Differential Evolution             275\n",
       "Generative Adversarial Network     263\n",
       "AdaBoost                           242\n",
       "Naive Bayes                        227\n",
       "LightGBM                           222\n",
       "Gated Recurrent Unit               210\n",
       "Deep Reinforcement Learning        202\n",
       "CatBoost                           192\n",
       "Attention Mechanism                172\n",
       "Lasso Regression                   155\n",
       "ARIMA                              151\n",
       "Linear Discriminant Analysis       150\n",
       "Simulated Annealing                148\n",
       "Ridge Regression                   135\n",
       "Partial Least Squares              130\n",
       "Residual Network                   127\n",
       "Q-Learning                         118\n",
       "Isolation Forest                   103\n",
       "Variational Autoencoder             93\n",
       "Extra Trees                         80\n",
       "Graph Neural Network                80\n",
       "Kalman Filter                       74\n",
       "OPTICS                              67\n",
       "Hierarchical Clustering             63\n",
       "Gaussian Mixture Model              63\n",
       "Proximal Policy Optimization        55\n",
       "Elastic Net                         51\n",
       "DBSCAN                              50\n",
       "Evolutionary Strategy               49\n",
       "Ant Colony Optimization             48\n",
       "Temporal Convolutional Network      47\n",
       "Local Outlier Factor                44\n",
       "Deep Q-Network                      44\n",
       "Actor-Critic                        43\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many ML methods were detected per abstract using the regex-based approach\n",
    "df[\"method_count\"] = df[\"ml_methods_regex\"].str.len()\n",
    "print(df[\"method_count\"].value_counts().sort_index())\n",
    "\n",
    "# Show the top 20 most frequently detected ML methods across all abstracts\n",
    "df.explode(\"ml_methods_regex\")[\"ml_methods_regex\"].value_counts().head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f58689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed abstracts with ML methods to: ../../data/processed/abstracts/regex_scispacy/abstracts_with_ml_methods_regex.csv\n"
     ]
    }
   ],
   "source": [
    "# Save updated dataframe with extracted ML methods\n",
    "output_path = save_path / \"abstracts_with_ml_methods_regex.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved processed abstracts with ML methods to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91fc441",
   "metadata": {},
   "source": [
    "## Scispacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8fbe9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer', 'parser', 'ner']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
     ]
    }
   ],
   "source": [
    "# Load the large SciSpaCy scientific language model and list all enabled NLP pipeline components\n",
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691d91b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 205 ML_METHOD patterns to EntityRuler.\n"
     ]
    }
   ],
   "source": [
    "# Add an EntityRuler to the NLP pipeline and register patterns for ML method detection\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "patterns = []\n",
    "\n",
    "# Create token-based matching patterns for each ML method phrase\n",
    "for label, phrases in ml_methods_dict.items():\n",
    "    for phrase in phrases:\n",
    "        # Create a case-insensitive match pattern using LOWER tokens\n",
    "        pattern = [{\"LOWER\": token.lower()} for token in phrase.split()]\n",
    "        patterns.append({\n",
    "            \"label\": \"ML_METHOD\",  # Custom entity label for ML methods\n",
    "            \"pattern\": pattern,\n",
    "            \"id\": label  # Canonical method name stored in ent_id_\n",
    "        })\n",
    "\n",
    "# Register all patterns in the EntityRuler\n",
    "ruler.add_patterns(patterns)\n",
    "print(f\"Added {len(patterns)} ML_METHOD patterns to EntityRuler.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd437b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ML method entities from a single abstract using the SciSpaCy EntityRuler\n",
    "def extract_ml_methods_scispacy(text: str) -> List[str]:\n",
    "    # Return empty list if input is not valid text\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    methods = []\n",
    "    \n",
    "    # Collect all detected ML_METHOD entities with their canonical IDs\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ML_METHOD\":\n",
    "            canonical = ent.ent_id_ if ent.ent_id_ else ent.text\n",
    "            methods.append(canonical)\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_methods = list(dict.fromkeys(methods))\n",
    "    return unique_methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6312ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33130/33130 [01:54<00:00, 288.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply the SciSpaCy EntityRuler to extract ML methods for all abstracts efficiently using nlp.pipe\n",
    "texts = df[\"clean_abs\"].fillna(\"\").tolist()\n",
    "\n",
    "ml_methods_all = []\n",
    "\n",
    "# Process abstracts in batches\n",
    "for doc in tqdm(nlp.pipe(texts, batch_size=32, n_process=8), total=len(texts)):\n",
    "    methods = []\n",
    "    \n",
    "    # Collect ML_METHOD entities found in each processed document\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ML_METHOD\":\n",
    "            canonical = ent.ent_id_ if ent.ent_id_ else ent.text\n",
    "            methods.append(canonical)\n",
    "            \n",
    "    # Store unique detected methods for this abstract\n",
    "    ml_methods_all.append(list(dict.fromkeys(methods)))\n",
    "\n",
    "# Save results\n",
    "df[\"ml_methods_scispacy\"] = ml_methods_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdab767e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed abstracts with ML methods to: ../../data/processed/abstracts/regex_scispacy/abstracts_with_ml_methods.csv\n"
     ]
    }
   ],
   "source": [
    "# Save updated dataframe with extracted ML methods\n",
    "output_path = save_path / \"abstracts_with_ml_methods.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved processed abstracts with ML methods to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250de0ad",
   "metadata": {},
   "source": [
    "### SciSpacy: Analyze Abstracts with ML methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7e0ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(save_path / \"abstracts_with_ml_methods.csv\")\n",
    "\n",
    "# Convert string lists to lists\n",
    "df[\"ml_methods_scispacy\"] = df[\"ml_methods_scispacy\"].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1d68766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blockchain-enabled decision system for reliabl...</td>\n",
       "      <td>10.1016/B978-0-443-33740-6.00012-8</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Systematic review of data modelling methods fo...</td>\n",
       "      <td>10.1080/19397038.2025.2563271</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clustering Locations of Collection Centers in ...</td>\n",
       "      <td>10.1109/TEMSCON-ASPAC62480.2024.11025082</td>\n",
       "      <td>[Reinforcement Learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artificial Intelligence: Basics, Impact, and H...</td>\n",
       "      <td>10.1188/23.CJON.595-601</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intersections between materials science and ma...</td>\n",
       "      <td>10.1039/d3va00106g</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Measuring Carbon in Cities and Their Buildings...</td>\n",
       "      <td>10.3390/asi6050076</td>\n",
       "      <td>[Linear Regression]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Predictive modeling for the quantity of recycl...</td>\n",
       "      <td>10.1016/j.resconrec.2023.107073</td>\n",
       "      <td>[Support Vector Regression, Gradient Boosting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Organizational Maturity and Its Influence on P...</td>\n",
       "      <td>10.1007/978-3-031-94484-0_27</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Toward Sustainable Manufacturing: A Review on ...</td>\n",
       "      <td>10.1109/ACCESS.2025.3576441</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Integrating Digital Twins and Robotics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Blockchain-enabled decision system for reliabl...   \n",
       "1  Systematic review of data modelling methods fo...   \n",
       "2  Clustering Locations of Collection Centers in ...   \n",
       "3  Artificial Intelligence: Basics, Impact, and H...   \n",
       "4  Intersections between materials science and ma...   \n",
       "5  Measuring Carbon in Cities and Their Buildings...   \n",
       "6  Predictive modeling for the quantity of recycl...   \n",
       "7  Organizational Maturity and Its Influence on P...   \n",
       "8  Toward Sustainable Manufacturing: A Review on ...   \n",
       "9             Integrating Digital Twins and Robotics   \n",
       "\n",
       "                                        doi  \\\n",
       "0        10.1016/B978-0-443-33740-6.00012-8   \n",
       "1             10.1080/19397038.2025.2563271   \n",
       "2  10.1109/TEMSCON-ASPAC62480.2024.11025082   \n",
       "3                   10.1188/23.CJON.595-601   \n",
       "4                        10.1039/d3va00106g   \n",
       "5                        10.3390/asi6050076   \n",
       "6           10.1016/j.resconrec.2023.107073   \n",
       "7              10.1007/978-3-031-94484-0_27   \n",
       "8               10.1109/ACCESS.2025.3576441   \n",
       "9                                       NaN   \n",
       "\n",
       "                                 ml_methods_scispacy  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                           [Reinforcement Learning]  \n",
       "3                                                 []  \n",
       "4                                                 []  \n",
       "5                                [Linear Regression]  \n",
       "6  [Support Vector Regression, Gradient Boosting,...  \n",
       "7                                                 []  \n",
       "8                                                 []  \n",
       "9                                                 []  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 papers with their extracted ML methods from SciSpaCy\n",
    "df[[\"title\", \"doi\", \"ml_methods_scispacy\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fc65f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method_count_scispacy\n",
       "0     17376\n",
       "1      8237\n",
       "2      3739\n",
       "3      1857\n",
       "4       969\n",
       "5       498\n",
       "6       244\n",
       "7       108\n",
       "8        62\n",
       "9        22\n",
       "10        9\n",
       "11        4\n",
       "12        2\n",
       "13        3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many ML methods SciSpaCy detected per abstract and summarize the distribution\n",
    "df[\"method_count_scispacy\"] = df[\"ml_methods_scispacy\"].str.len()\n",
    "df[\"method_count_scispacy\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a04ae7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ml_methods_scispacy\n",
       "Neural Network                  5540\n",
       "Random Forest                   3060\n",
       "Support Vector Machine          2106\n",
       "Decision Tree                   1614\n",
       "Convolutional Neural Network    1195\n",
       "Gradient Boosting               1173\n",
       "XGBoost                         1053\n",
       "LSTM                             964\n",
       "Bayesian Method                  882\n",
       "Linear Regression                862\n",
       "Reinforcement Learning           811\n",
       "K-Nearest Neighbors              798\n",
       "Genetic Algorithm                748\n",
       "Support Vector Regression        693\n",
       "Principal Component Analysis     562\n",
       "Particle Swarm Optimization      542\n",
       "Logistic Regression              469\n",
       "Deep Neural Network              458\n",
       "SHAP                             445\n",
       "Multi-Layer Perceptron           391\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the top 20 most frequently detected ML methods using the SciSpaCy extraction\n",
    "df.explode(\"ml_methods_scispacy\")[\"ml_methods_scispacy\"].value_counts().head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc4c9f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "      <th>ml_methods_regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14035</th>\n",
       "      <td>Sparse representation preserving embedding bas...</td>\n",
       "      <td>10.1177/0142331219898937</td>\n",
       "      <td>[Squared Prediction Error]</td>\n",
       "      <td>['Squared Prediction Error']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>A gaussian mixture model for automated corrosi...</td>\n",
       "      <td>10.3233/978-1-61499-902-7-63</td>\n",
       "      <td>[Gaussian Mixture Model]</td>\n",
       "      <td>['Gaussian Mixture Model']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28328</th>\n",
       "      <td>Prediction of structural deformation of a deck...</td>\n",
       "      <td>10.1016/j.oceaneng.2021.109835</td>\n",
       "      <td>[Generative Adversarial Network]</td>\n",
       "      <td>['Neural Network', 'Convolutional Neural Netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7549</th>\n",
       "      <td>Quality Inspection of Casting Product Using CA...</td>\n",
       "      <td>10.1109/ICISPC51671.2020.00014</td>\n",
       "      <td>[Convolutional Neural Network, Autoencoder]</td>\n",
       "      <td>['Neural Network', 'Convolutional Neural Netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24101</th>\n",
       "      <td>Hybrid AI-based forecasting of green hydrogen ...</td>\n",
       "      <td>10.1515/cppm-2025-0088</td>\n",
       "      <td>[AdaBoost]</td>\n",
       "      <td>['Decision Tree', 'AdaBoost', 'Multi-Layer Per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "14035  Sparse representation preserving embedding bas...   \n",
       "166    A gaussian mixture model for automated corrosi...   \n",
       "28328  Prediction of structural deformation of a deck...   \n",
       "7549   Quality Inspection of Casting Product Using CA...   \n",
       "24101  Hybrid AI-based forecasting of green hydrogen ...   \n",
       "\n",
       "                                  doi  \\\n",
       "14035        10.1177/0142331219898937   \n",
       "166      10.3233/978-1-61499-902-7-63   \n",
       "28328  10.1016/j.oceaneng.2021.109835   \n",
       "7549   10.1109/ICISPC51671.2020.00014   \n",
       "24101          10.1515/cppm-2025-0088   \n",
       "\n",
       "                               ml_methods_scispacy  \\\n",
       "14035                   [Squared Prediction Error]   \n",
       "166                       [Gaussian Mixture Model]   \n",
       "28328             [Generative Adversarial Network]   \n",
       "7549   [Convolutional Neural Network, Autoencoder]   \n",
       "24101                                   [AdaBoost]   \n",
       "\n",
       "                                        ml_methods_regex  \n",
       "14035                       ['Squared Prediction Error']  \n",
       "166                           ['Gaussian Mixture Model']  \n",
       "28328  ['Neural Network', 'Convolutional Neural Netwo...  \n",
       "7549   ['Neural Network', 'Convolutional Neural Netwo...  \n",
       "24101  ['Decision Tree', 'AdaBoost', 'Multi-Layer Per...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly inspect 5 abstracts where SciSpaCy successfully detected ML methods\n",
    "df[df[\"method_count_scispacy\"] > 0][[\"title\", \"doi\", \"ml_methods_scispacy\", \"ml_methods_regex\"]].sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde14409",
   "metadata": {},
   "source": [
    "## Compare Regex and SciSpacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c98e53c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert stringified lists in ml_methods_regex to real Python lists\n",
    "df[\"ml_methods_regex\"] = df[\"ml_methods_regex\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "214ecb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods with 0 matches in both regex and SciSpaCy: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all ML methods from the dictionary that are never detected by either regex or SciSpaCy\n",
    "\n",
    "# Ensure we are working with sets for easier membership checks\n",
    "df[\"regex_set\"] = df[\"ml_methods_regex\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "df[\"scispacy_set\"] = df[\"ml_methods_scispacy\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "\n",
    "all_methods = list(ml_methods_dict.keys())\n",
    "zero_hit_methods = []\n",
    "\n",
    "for method in all_methods:\n",
    "    regex_hits = df[\"regex_set\"].apply(lambda s: method in s).sum()\n",
    "    scispacy_hits = df[\"scispacy_set\"].apply(lambda s: method in s).sum()\n",
    "    \n",
    "    if regex_hits == 0 and scispacy_hits == 0:\n",
    "        zero_hit_methods.append(method)\n",
    "\n",
    "print(f\"Methods with 0 matches in both regex and SciSpaCy: {len(zero_hit_methods)}\")\n",
    "zero_hit_methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d0459d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>regex_count</th>\n",
       "      <th>scispacy_count</th>\n",
       "      <th>both_count</th>\n",
       "      <th>regex_only</th>\n",
       "      <th>scispacy_only</th>\n",
       "      <th>union_count</th>\n",
       "      <th>jaccard_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>6747</td>\n",
       "      <td>5540</td>\n",
       "      <td>5540</td>\n",
       "      <td>1207</td>\n",
       "      <td>0</td>\n",
       "      <td>6747</td>\n",
       "      <td>0.821106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3103</td>\n",
       "      <td>3060</td>\n",
       "      <td>3060</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>3103</td>\n",
       "      <td>0.986142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>2176</td>\n",
       "      <td>2106</td>\n",
       "      <td>2106</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2176</td>\n",
       "      <td>0.967831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1652</td>\n",
       "      <td>1614</td>\n",
       "      <td>1614</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1652</td>\n",
       "      <td>0.976998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Convolutional Neural Network</td>\n",
       "      <td>1365</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1365</td>\n",
       "      <td>0.875458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1185</td>\n",
       "      <td>1173</td>\n",
       "      <td>1172</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1186</td>\n",
       "      <td>0.988196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>1107</td>\n",
       "      <td>964</td>\n",
       "      <td>964</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>1107</td>\n",
       "      <td>0.870822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1091</td>\n",
       "      <td>1053</td>\n",
       "      <td>1053</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1091</td>\n",
       "      <td>0.965170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Reinforcement Learning</td>\n",
       "      <td>976</td>\n",
       "      <td>811</td>\n",
       "      <td>811</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>976</td>\n",
       "      <td>0.830943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>906</td>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>906</td>\n",
       "      <td>0.951435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bayesian Method</td>\n",
       "      <td>893</td>\n",
       "      <td>882</td>\n",
       "      <td>882</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>0.987682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Genetic Algorithm</td>\n",
       "      <td>843</td>\n",
       "      <td>748</td>\n",
       "      <td>748</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>843</td>\n",
       "      <td>0.887307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>813</td>\n",
       "      <td>798</td>\n",
       "      <td>798</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>813</td>\n",
       "      <td>0.981550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Support Vector Regression</td>\n",
       "      <td>716</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>716</td>\n",
       "      <td>0.967877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Particle Swarm Optimization</td>\n",
       "      <td>597</td>\n",
       "      <td>542</td>\n",
       "      <td>542</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>597</td>\n",
       "      <td>0.907873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Principal Component Analysis</td>\n",
       "      <td>587</td>\n",
       "      <td>562</td>\n",
       "      <td>562</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>587</td>\n",
       "      <td>0.957411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Deep Neural Network</td>\n",
       "      <td>483</td>\n",
       "      <td>458</td>\n",
       "      <td>458</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>483</td>\n",
       "      <td>0.948240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>473</td>\n",
       "      <td>469</td>\n",
       "      <td>469</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>473</td>\n",
       "      <td>0.991543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>SHAP</td>\n",
       "      <td>460</td>\n",
       "      <td>445</td>\n",
       "      <td>445</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>0.967391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>451</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>0.740576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Transformers</td>\n",
       "      <td>442</td>\n",
       "      <td>381</td>\n",
       "      <td>381</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>0.861991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Multi-Layer Perceptron</td>\n",
       "      <td>420</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>420</td>\n",
       "      <td>0.930952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Gaussian Process Regression</td>\n",
       "      <td>396</td>\n",
       "      <td>385</td>\n",
       "      <td>385</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>396</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>345</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>0.965217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Recurrent Neural Network</td>\n",
       "      <td>318</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>0.940252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Explainable AI</td>\n",
       "      <td>294</td>\n",
       "      <td>294</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Differential Evolution</td>\n",
       "      <td>275</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>0.669091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Generative Adversarial Network</td>\n",
       "      <td>263</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>0.939163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>242</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>0.975207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>227</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>0.933921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             method  regex_count  scispacy_count  both_count  \\\n",
       "67                   Neural Network         6747            5540        5540   \n",
       "80                    Random Forest         3103            3060        3060   \n",
       "93           Support Vector Machine         2176            2106        2106   \n",
       "15                    Decision Tree         1652            1614        1614   \n",
       "13     Convolutional Neural Network         1365            1195        1195   \n",
       "36                Gradient Boosting         1185            1173        1172   \n",
       "54                             LSTM         1107             964         964   \n",
       "103                         XGBoost         1091            1053        1053   \n",
       "82           Reinforcement Learning          976             811         811   \n",
       "58                Linear Regression          906             862         862   \n",
       "8                   Bayesian Method          893             882         882   \n",
       "35                Genetic Algorithm          843             748         748   \n",
       "52              K-Nearest Neighbors          813             798         798   \n",
       "94        Support Vector Regression          716             693         693   \n",
       "72      Particle Swarm Optimization          597             542         542   \n",
       "74     Principal Component Analysis          587             562         562   \n",
       "17              Deep Neural Network          483             458         458   \n",
       "60              Logistic Regression          473             469         469   \n",
       "88                             SHAP          460             445         445   \n",
       "6                       Autoencoder          451             334         334   \n",
       "97                     Transformers          442             381         381   \n",
       "64           Multi-Layer Perceptron          420             391         391   \n",
       "33      Gaussian Process Regression          396             385         385   \n",
       "50                          K-Means          345             333         333   \n",
       "81         Recurrent Neural Network          318             299         299   \n",
       "27                   Explainable AI          294             294         294   \n",
       "21           Differential Evolution          275             184         184   \n",
       "34   Generative Adversarial Network          263             247         247   \n",
       "3                          AdaBoost          242             236         236   \n",
       "66                      Naive Bayes          227             212         212   \n",
       "\n",
       "     regex_only  scispacy_only  union_count  jaccard_overlap  \n",
       "67         1207              0         6747         0.821106  \n",
       "80           43              0         3103         0.986142  \n",
       "93           70              0         2176         0.967831  \n",
       "15           38              0         1652         0.976998  \n",
       "13          170              0         1365         0.875458  \n",
       "36           13              1         1186         0.988196  \n",
       "54          143              0         1107         0.870822  \n",
       "103          38              0         1091         0.965170  \n",
       "82          165              0          976         0.830943  \n",
       "58           44              0          906         0.951435  \n",
       "8            11              0          893         0.987682  \n",
       "35           95              0          843         0.887307  \n",
       "52           15              0          813         0.981550  \n",
       "94           23              0          716         0.967877  \n",
       "72           55              0          597         0.907873  \n",
       "74           25              0          587         0.957411  \n",
       "17           25              0          483         0.948240  \n",
       "60            4              0          473         0.991543  \n",
       "88           15              0          460         0.967391  \n",
       "6           117              0          451         0.740576  \n",
       "97           61              0          442         0.861991  \n",
       "64           29              0          420         0.930952  \n",
       "33           11              0          396         0.972222  \n",
       "50           12              0          345         0.965217  \n",
       "81           19              0          318         0.940252  \n",
       "27            0              0          294         1.000000  \n",
       "21           91              0          275         0.669091  \n",
       "34           16              0          263         0.939163  \n",
       "3             6              0          242         0.975207  \n",
       "66           15              0          227         0.933921  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure we are working with list -> set for easier membership checks\n",
    "df[\"regex_set\"] = df[\"ml_methods_regex\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "df[\"scispacy_set\"] = df[\"ml_methods_scispacy\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "\n",
    "# Collect the universe of methods seen by either approach\n",
    "all_methods = sorted(\n",
    "    set().union(*df[\"regex_set\"]).union(*df[\"scispacy_set\"])\n",
    ")\n",
    "\n",
    "rows = []\n",
    "\n",
    "# For each method, compute overlap stats between regex and SciSpaCy\n",
    "for method in all_methods:\n",
    "    regex_mask = df[\"regex_set\"].apply(lambda s: method in s)\n",
    "    scis_mask = df[\"scispacy_set\"].apply(lambda s: method in s)\n",
    "    \n",
    "    regex_count = regex_mask.sum()\n",
    "    scispacy_count = scis_mask.sum()\n",
    "    both_count = (regex_mask & scis_mask).sum()\n",
    "    regex_only = (regex_mask & ~scis_mask).sum()\n",
    "    scispacy_only = (~regex_mask & scis_mask).sum()\n",
    "    union_count = (regex_mask | scis_mask).sum()\n",
    "    \n",
    "    jaccard = both_count / union_count if union_count > 0 else 0.0\n",
    "    \n",
    "    rows.append({\n",
    "        \"method\": method,\n",
    "        \"regex_count\": regex_count,\n",
    "        \"scispacy_count\": scispacy_count,\n",
    "        \"both_count\": both_count,\n",
    "        \"regex_only\": regex_only,\n",
    "        \"scispacy_only\": scispacy_only,\n",
    "        \"union_count\": union_count,\n",
    "        \"jaccard_overlap\": jaccard,\n",
    "    })\n",
    "\n",
    "overlap_df = pd.DataFrame(rows)\n",
    "\n",
    "# Sort by popularity (or by overlap) as you like\n",
    "overlap_df_sorted = overlap_df.sort_values(\"union_count\", ascending=False)\n",
    "\n",
    "# For a quick view: top 20 methods by total detections, with overlap stats\n",
    "overlap_df_sorted.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbaf8e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "      <th>ml_methods_regex</th>\n",
       "      <th>method_count</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "      <th>method_count_scispacy</th>\n",
       "      <th>regex_set</th>\n",
       "      <th>scispacy_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13735</th>\n",
       "      <td>ml_process_control</td>\n",
       "      <td>2-s2.0-85020415893</td>\n",
       "      <td>10.1117/12.2258039</td>\n",
       "      <td>Computational overlay metrology with adaptive ...</td>\n",
       "      <td>© 2017 SPIE.With photolithography as the funda...</td>\n",
       "      <td>With photolithography as the fundamental patte...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[Gradient Boosting]</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Gradient Boosting}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 query_id                 eid                 doi  \\\n",
       "13735  ml_process_control  2-s2.0-85020415893  10.1117/12.2258039   \n",
       "\n",
       "                                                   title  \\\n",
       "13735  Computational overlay metrology with adaptive ...   \n",
       "\n",
       "                                                abstract  \\\n",
       "13735  © 2017 SPIE.With photolithography as the funda...   \n",
       "\n",
       "                                               clean_abs ml_methods_regex  \\\n",
       "13735  With photolithography as the fundamental patte...               []   \n",
       "\n",
       "       method_count  ml_methods_scispacy  method_count_scispacy regex_set  \\\n",
       "13735             0  [Gradient Boosting]                      1        {}   \n",
       "\n",
       "              scispacy_set  \n",
       "13735  {Gradient Boosting}  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract rows where SciSpaCy found at least one method\n",
    "# and regex found none\n",
    "scispacy_only_df = df[\n",
    "    (df[\"scispacy_set\"].apply(len) > 0) &\n",
    "    (df[\"regex_set\"].apply(len) == 0)\n",
    "]\n",
    "\n",
    "scispacy_only_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b157942d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "      <th>ml_methods_regex</th>\n",
       "      <th>method_count</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "      <th>method_count_scispacy</th>\n",
       "      <th>regex_set</th>\n",
       "      <th>scispacy_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_end_of_life</td>\n",
       "      <td>2-s2.0-85178021268</td>\n",
       "      <td>10.1188/23.CJON.595-601</td>\n",
       "      <td>Artificial Intelligence: Basics, Impact, and H...</td>\n",
       "      <td>© 2023, Oncology Nursing Society. All rights r...</td>\n",
       "      <td>All rights reserved.Applying artificial intell...</td>\n",
       "      <td>[Differential Evolution]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{Differential Evolution}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ml_end_of_life</td>\n",
       "      <td>2-s2.0-85125327474</td>\n",
       "      <td>10.1109/ICCES54031.2021.9686083</td>\n",
       "      <td>Autonomous Non-Destructive Assembly/Disassembl...</td>\n",
       "      <td>© 2021 IEEE.E-waste recycling is becoming one ...</td>\n",
       "      <td>E-waste recycling is becoming one of the fast ...</td>\n",
       "      <td>[Differential Evolution]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{Differential Evolution}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>ml_recycling_manufacturing</td>\n",
       "      <td>2-s2.0-85166934684</td>\n",
       "      <td>10.1080/15376494.2023.2238220</td>\n",
       "      <td>Machine learning and RSM-CCD analysis of green...</td>\n",
       "      <td>© 2023 Taylor &amp; Francis Group, LLC.This study ...</td>\n",
       "      <td>This study aims to serve as a performance indi...</td>\n",
       "      <td>[Neural Network]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{Neural Network}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>ml_remanufacturing</td>\n",
       "      <td>2-s2.0-85185884385</td>\n",
       "      <td>10.1115/1.4064257</td>\n",
       "      <td>Multiscale Feature Fusion Convolutional Neural...</td>\n",
       "      <td>© 2024 by ASME.The detection of surface damage...</td>\n",
       "      <td>The detection of surface damage is an importan...</td>\n",
       "      <td>[Convolutional Neural Network]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{Convolutional Neural Network}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>ml_remanufacturing</td>\n",
       "      <td>2-s2.0-85127515751</td>\n",
       "      <td>10.1016/j.procir.2022.02.168</td>\n",
       "      <td>MotorFactory: A Blender Add-on for Large Datas...</td>\n",
       "      <td>© 2022 Elsevier B.V.. All rights reserved.To e...</td>\n",
       "      <td>V.. All rights reserved.To enable automatic di...</td>\n",
       "      <td>[Reinforcement Learning]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{Reinforcement Learning}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       query_id                 eid  \\\n",
       "3                ml_end_of_life  2-s2.0-85178021268   \n",
       "23               ml_end_of_life  2-s2.0-85125327474   \n",
       "126  ml_recycling_manufacturing  2-s2.0-85166934684   \n",
       "156          ml_remanufacturing  2-s2.0-85185884385   \n",
       "161          ml_remanufacturing  2-s2.0-85127515751   \n",
       "\n",
       "                                 doi  \\\n",
       "3            10.1188/23.CJON.595-601   \n",
       "23   10.1109/ICCES54031.2021.9686083   \n",
       "126    10.1080/15376494.2023.2238220   \n",
       "156                10.1115/1.4064257   \n",
       "161     10.1016/j.procir.2022.02.168   \n",
       "\n",
       "                                                 title  \\\n",
       "3    Artificial Intelligence: Basics, Impact, and H...   \n",
       "23   Autonomous Non-Destructive Assembly/Disassembl...   \n",
       "126  Machine learning and RSM-CCD analysis of green...   \n",
       "156  Multiscale Feature Fusion Convolutional Neural...   \n",
       "161  MotorFactory: A Blender Add-on for Large Datas...   \n",
       "\n",
       "                                              abstract  \\\n",
       "3    © 2023, Oncology Nursing Society. All rights r...   \n",
       "23   © 2021 IEEE.E-waste recycling is becoming one ...   \n",
       "126  © 2023 Taylor & Francis Group, LLC.This study ...   \n",
       "156  © 2024 by ASME.The detection of surface damage...   \n",
       "161  © 2022 Elsevier B.V.. All rights reserved.To e...   \n",
       "\n",
       "                                             clean_abs  \\\n",
       "3    All rights reserved.Applying artificial intell...   \n",
       "23   E-waste recycling is becoming one of the fast ...   \n",
       "126  This study aims to serve as a performance indi...   \n",
       "156  The detection of surface damage is an importan...   \n",
       "161  V.. All rights reserved.To enable automatic di...   \n",
       "\n",
       "                   ml_methods_regex  method_count ml_methods_scispacy  \\\n",
       "3          [Differential Evolution]             1                  []   \n",
       "23         [Differential Evolution]             1                  []   \n",
       "126                [Neural Network]             1                  []   \n",
       "156  [Convolutional Neural Network]             1                  []   \n",
       "161        [Reinforcement Learning]             1                  []   \n",
       "\n",
       "     method_count_scispacy                       regex_set scispacy_set  \n",
       "3                        0        {Differential Evolution}           {}  \n",
       "23                       0        {Differential Evolution}           {}  \n",
       "126                      0                {Neural Network}           {}  \n",
       "156                      0  {Convolutional Neural Network}           {}  \n",
       "161                      0        {Reinforcement Learning}           {}  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract rows where Regex found at least one method\n",
    "# and SciSpacy found none\n",
    "scispacy_only_df = df[\n",
    "    (df[\"regex_set\"].apply(len) > 0) &\n",
    "    (df[\"scispacy_set\"].apply(len) == 0)\n",
    "]\n",
    "\n",
    "scispacy_only_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e33f5",
   "metadata": {},
   "source": [
    "## Extract ML-Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01038781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define common \"method head\" words and extract ML-related candidate phrases from parsed abstracts\n",
    "# METHOD_HEADS = {\n",
    "#     \"network\", \"networks\",\n",
    "#     \"model\", \"models\",\n",
    "#     \"algorithm\", \"algorithms\",\n",
    "#     \"classifier\", \"classifiers\",\n",
    "#     \"regression\",\n",
    "#     \"forest\", \"forests\",\n",
    "#     \"clustering\", \"clusterer\", \"clusterers\",\n",
    "#     \"encoder\", \"encoders\",\n",
    "#     \"autoencoder\", \"autoencoders\",\n",
    "#     \"transformer\", \"transformers\",\n",
    "#     \"estimators\", \"estimator\",\n",
    "#     \"approach\", \"approaches\",\n",
    "#     \"architecture\", \"architectures\",\n",
    "# }\n",
    "\n",
    "# def extract_candidate_phrases_from_doc(doc):\n",
    "#     \"\"\"Extract candidate ML-method phrases from a spaCy Doc.\"\"\"\n",
    "#     candidates = []\n",
    "\n",
    "#     # Noun chunks that end with a \"method head\" word\n",
    "#     for chunk in doc.noun_chunks:\n",
    "#         tokens = [t for t in chunk if not t.is_punct]\n",
    "#         if not tokens:\n",
    "#             continue\n",
    "\n",
    "#         head = tokens[-1].lemma_.lower()\n",
    "#         if head in METHOD_HEADS:\n",
    "#             if 1 <= len(tokens) <= 7:\n",
    "#                 phrase = chunk.text.strip()\n",
    "#                 candidates.append(phrase)\n",
    "\n",
    "#     # All-caps acronyms (e.g., SVM, CNN, LSTM)\n",
    "#     for token in doc:\n",
    "#         if (\n",
    "#             token.is_alpha\n",
    "#             and token.text.isupper()\n",
    "#             and 2 <= len(token.text) <= 6\n",
    "#         ):\n",
    "#             candidates.append(token.text)\n",
    "\n",
    "#     # Remove duplicates, preserve order\n",
    "#     return list(dict.fromkeys(candidates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "882b1926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract ML-related candidate phrases from all abstracts efficiently using spaCy's nlp.pipe\n",
    "# texts = df[\"clean_abs\"].fillna(\"\").tolist()\n",
    "\n",
    "# candidate_counter = collections.Counter()\n",
    "\n",
    "# # Batch processing with multiple processes for faster NLP execution\n",
    "# for doc in tqdm(\n",
    "#     nlp.pipe(texts, batch_size=64, n_process=8),\n",
    "#     total=len(texts)\n",
    "# ):\n",
    "#     for cand in extract_candidate_phrases_from_doc(doc):\n",
    "#         candidate_counter[cand] += 1\n",
    "\n",
    "# print(f\"Extracted {len(candidate_counter)} unique candidate phrases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57879afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show the top candidate phrases by frequency\n",
    "# for phrase, count in candidate_counter.most_common(100):\n",
    "#     print(f\"{count:4d}  {phrase}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59191c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-catalogue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
