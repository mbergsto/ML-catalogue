{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbe61b2",
   "metadata": {},
   "source": [
    "- Apply rule-based extraction to identify machine learning methods in abstracts\n",
    "- Test two complementary approaches:\n",
    "  - **Regex-based matching** for known ML terms\n",
    "  - **SciSpaCy + EntityRuler** for robust phrase detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e5921f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "from typing import List\n",
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "50837a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All directories verified/created.\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "\n",
    "data_path = Path(\"../../data/short-raw-refs-abs\")\n",
    "processed_abstracts_path = Path(\"../../data/processed/abstracts\")\n",
    "save_path = processed_abstracts_path / \"regex_scispacy\"\n",
    "ml_methods_path = Path(\"../../ml_methods/ml_methods_dict.json\")\n",
    "\n",
    "\n",
    "# Ensure directories exist\n",
    "for p in [data_path, processed_abstracts_path, save_path]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"All directories verified/created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a276afda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 52290 abstracts from 24 queries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105018574505</td>\n",
       "      <td>10.1016/j.measurement.2025.119261</td>\n",
       "      <td>Distillation anomaly and fault detection based...</td>\n",
       "      <td>© 2025 The Author(s)The detection of anomalies...</td>\n",
       "      <td>Indeed, highly efficient systems do not always...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105019192533</td>\n",
       "      <td>10.1007/978-3-032-06118-8_30</td>\n",
       "      <td>From Lab to Factory: Pitfalls and Guidelines f...</td>\n",
       "      <td>© The Author(s), under exclusive license to Sp...</td>\n",
       "      <td>The detection and localization of quality-rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105016669957</td>\n",
       "      <td>10.1007/978-3-032-04200-2_5</td>\n",
       "      <td>Intelligent Defect Detection for Manufacturing...</td>\n",
       "      <td>© The Author(s), under exclusive license to Sp...</td>\n",
       "      <td>In modern Industry, I4.0, artificial intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-85218693791</td>\n",
       "      <td>10.1038/s41598-025-90810-w</td>\n",
       "      <td>Hybrid machine learning framework for predicti...</td>\n",
       "      <td>© The Author(s) 2025.The critical necessity fo...</td>\n",
       "      <td>The critical necessity for sophisticated predi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105018301117</td>\n",
       "      <td>10.1016/j.comnet.2025.111753</td>\n",
       "      <td>BGP anomaly detection using the raw internet t...</td>\n",
       "      <td>© 2025 The AuthorsThe Border Gateway Protocol ...</td>\n",
       "      <td>Hence, detecting any anomaly concerning BGP an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          query_id                  eid  \\\n",
       "0  ml_anomaly_detection_production  2-s2.0-105018574505   \n",
       "1  ml_anomaly_detection_production  2-s2.0-105019192533   \n",
       "2  ml_anomaly_detection_production  2-s2.0-105016669957   \n",
       "3  ml_anomaly_detection_production   2-s2.0-85218693791   \n",
       "4  ml_anomaly_detection_production  2-s2.0-105018301117   \n",
       "\n",
       "                                 doi  \\\n",
       "0  10.1016/j.measurement.2025.119261   \n",
       "1       10.1007/978-3-032-06118-8_30   \n",
       "2        10.1007/978-3-032-04200-2_5   \n",
       "3         10.1038/s41598-025-90810-w   \n",
       "4       10.1016/j.comnet.2025.111753   \n",
       "\n",
       "                                               title  \\\n",
       "0  Distillation anomaly and fault detection based...   \n",
       "1  From Lab to Factory: Pitfalls and Guidelines f...   \n",
       "2  Intelligent Defect Detection for Manufacturing...   \n",
       "3  Hybrid machine learning framework for predicti...   \n",
       "4  BGP anomaly detection using the raw internet t...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  © 2025 The Author(s)The detection of anomalies...   \n",
       "1  © The Author(s), under exclusive license to Sp...   \n",
       "2  © The Author(s), under exclusive license to Sp...   \n",
       "3  © The Author(s) 2025.The critical necessity fo...   \n",
       "4  © 2025 The AuthorsThe Border Gateway Protocol ...   \n",
       "\n",
       "                                           clean_abs  \n",
       "0  Indeed, highly efficient systems do not always...  \n",
       "1  The detection and localization of quality-rela...  \n",
       "2  In modern Industry, I4.0, artificial intellige...  \n",
       "3  The critical necessity for sophisticated predi...  \n",
       "4  Hence, detecting any anomaly concerning BGP an...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load abstracts dataset\n",
    "\n",
    "abstracts_path = processed_abstracts_path / \"abstracts.csv\"\n",
    "df = pd.read_csv(abstracts_path)\n",
    "\n",
    "print(f\"Loaded {len(df)} abstracts from {df['query_id'].nunique()} queries.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b8f60535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 52290\n",
      "After removing duplicates: 33130\n",
      "Remaining duplicate DOIs: 0\n"
     ]
    }
   ],
   "source": [
    "# Count how many rows each query_id has\n",
    "query_counts = df[\"query_id\"].value_counts().to_dict()\n",
    "\n",
    "# Create a copy and map the counts to each row\n",
    "df = df.copy()\n",
    "df[\"query_size\"] = df[\"query_id\"].map(query_counts)\n",
    "\n",
    "# Sort so that query groups with fewer rows are prioritized\n",
    "df_sorted = df.sort_values(by=\"query_size\", ascending=True)\n",
    "\n",
    "# Remove duplicate DOIs, keeping the one in the smallest query group\n",
    "df_dedup = df_sorted.drop_duplicates(subset=\"doi\", keep=\"first\").drop(columns=[\"query_size\"])\n",
    "\n",
    "# Print results\n",
    "print(\"Original dataset size:\", len(df))\n",
    "print(\"After removing duplicates:\", len(df_dedup))\n",
    "print(\"Remaining duplicate DOIs:\", df_dedup[\"doi\"].duplicated().sum())\n",
    "\n",
    "df = df_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "96ec40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ml_methods_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    ml_methods_dict = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec15316",
   "metadata": {},
   "source": [
    "## Regex matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9f33c5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33130/33130 [02:30<00:00, 219.71it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_methods(text, term_dict):\n",
    "    # Return empty list if input is not a string\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    found = []\n",
    "    \n",
    "    for method, phrases in term_dict.items():\n",
    "        for phrase in phrases:\n",
    "            # Escape special characters and enforce word boundaries\n",
    "            pattern = r\"\\b\" + re.escape(phrase.lower()) + r\"\\b\"\n",
    "            \n",
    "            # Perform case-insensitive boundary-safe regex search\n",
    "            if re.search(pattern, text.lower()):\n",
    "                found.append(method)\n",
    "                break  # Stop checking more variants for this method\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    return list(dict.fromkeys(found))\n",
    "\n",
    "# Apply extraction with pandas progress bar\n",
    "tqdm.pandas()\n",
    "df[\"ml_methods_regex\"] = df[\"clean_abs\"].fillna(\"\").progress_apply(\n",
    "    lambda x: extract_methods(x, ml_methods_dict)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d6cde623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_count\n",
      "0     17479\n",
      "1      7403\n",
      "2      4072\n",
      "3      2044\n",
      "4      1096\n",
      "5       521\n",
      "6       284\n",
      "7       127\n",
      "8        62\n",
      "9        23\n",
      "10        9\n",
      "11        4\n",
      "12        4\n",
      "13        2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ml_methods_regex\n",
      "Neural Network                  6659\n",
      "Random Forest                   3103\n",
      "Support Vector Machine          2176\n",
      "Decision Tree                   1652\n",
      "Convolutional Neural Network    1365\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count how many ML methods were detected per abstract using the regex-based approach\n",
    "df[\"method_count\"] = df[\"ml_methods_regex\"].str.len()\n",
    "print(df[\"method_count\"].value_counts().sort_index())\n",
    "\n",
    "# Show the top 20 most frequently detected ML methods across all abstracts\n",
    "print()\n",
    "print(df.explode(\"ml_methods_regex\")[\"ml_methods_regex\"].value_counts().head())\n",
    "\n",
    "# Save table of methods with counts \n",
    "method_counts = df.explode(\"ml_methods_regex\")[\"ml_methods_regex\"].value_counts().reset_index()\n",
    "method_counts.columns = [\"ml_method\", \"count\"]\n",
    "method_counts.to_csv(save_path / \"ml_method_counts_regex.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a0f58689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed abstracts with ML methods to: ../../data/processed/abstracts/regex_scispacy/abstracts_with_ml_methods_regex.csv\n"
     ]
    }
   ],
   "source": [
    "# Save updated dataframe with extracted ML methods\n",
    "output_path = save_path / \"abstracts_with_ml_methods_regex.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved processed abstracts with ML methods to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91fc441",
   "metadata": {},
   "source": [
    "## Scispacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c8fbe9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer', 'parser', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# Load the large SciSpaCy scientific language model and list all enabled NLP pipeline components\n",
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "691d91b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 193 ML_METHOD patterns to EntityRuler.\n"
     ]
    }
   ],
   "source": [
    "# Add an EntityRuler to the NLP pipeline and register patterns for ML method detection\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "patterns = []\n",
    "\n",
    "# Create token-based matching patterns for each ML method phrase\n",
    "for label, phrases in ml_methods_dict.items():\n",
    "    for phrase in phrases:\n",
    "        # Create a case-insensitive match pattern using LOWER tokens\n",
    "        pattern = [{\"LOWER\": token.lower()} for token in phrase.split()]\n",
    "        patterns.append({\n",
    "            \"label\": \"ML_METHOD\",  # Custom entity label for ML methods\n",
    "            \"pattern\": pattern,\n",
    "            \"id\": label  # Canonical method name stored in ent_id_\n",
    "        })\n",
    "\n",
    "# Register all patterns in the EntityRuler\n",
    "ruler.add_patterns(patterns)\n",
    "print(f\"Added {len(patterns)} ML_METHOD patterns to EntityRuler.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dd437b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ML method entities from a single abstract using the SciSpaCy EntityRuler\n",
    "def extract_ml_methods_scispacy(text: str) -> List[str]:\n",
    "    # Return empty list if input is not valid text\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    methods = []\n",
    "    \n",
    "    # Collect all detected ML_METHOD entities with their canonical IDs\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ML_METHOD\":\n",
    "            canonical = ent.ent_id_ if ent.ent_id_ else ent.text\n",
    "            methods.append(canonical)\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_methods = list(dict.fromkeys(methods))\n",
    "    return unique_methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6312ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33130/33130 [01:57<00:00, 282.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply the SciSpaCy EntityRuler to extract ML methods for all abstracts efficiently using nlp.pipe\n",
    "texts = df[\"clean_abs\"].fillna(\"\").tolist()\n",
    "\n",
    "ml_methods_all = []\n",
    "\n",
    "# Process abstracts in batches\n",
    "for doc in tqdm(nlp.pipe(texts, batch_size=32, n_process=8), total=len(texts)):\n",
    "    methods = []\n",
    "    \n",
    "    # Collect ML_METHOD entities found in each processed document\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ML_METHOD\":\n",
    "            canonical = ent.ent_id_ if ent.ent_id_ else ent.text\n",
    "            methods.append(canonical)\n",
    "            \n",
    "    # Store unique detected methods for this abstract\n",
    "    ml_methods_all.append(list(dict.fromkeys(methods)))\n",
    "\n",
    "# Save results\n",
    "df[\"ml_methods_scispacy\"] = ml_methods_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fdab767e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed abstracts with ML methods to: ../../data/processed/abstracts/regex_scispacy/abstracts_with_ml_methods.csv\n"
     ]
    }
   ],
   "source": [
    "# Save updated dataframe with extracted ML methods\n",
    "output_path = save_path / \"abstracts_with_ml_methods.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved processed abstracts with ML methods to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250de0ad",
   "metadata": {},
   "source": [
    "### SciSpacy: Analyze Abstracts with ML methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b7e0ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(save_path / \"abstracts_with_ml_methods.csv\")\n",
    "\n",
    "# Convert string lists to lists\n",
    "df[\"ml_methods_scispacy\"] = df[\"ml_methods_scispacy\"].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f1d68766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blockchain-enabled decision system for reliabl...</td>\n",
       "      <td>10.1016/B978-0-443-33740-6.00012-8</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Systematic review of data modelling methods fo...</td>\n",
       "      <td>10.1080/19397038.2025.2563271</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clustering Locations of Collection Centers in ...</td>\n",
       "      <td>10.1109/TEMSCON-ASPAC62480.2024.11025082</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artificial Intelligence: Basics, Impact, and H...</td>\n",
       "      <td>10.1188/23.CJON.595-601</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intersections between materials science and ma...</td>\n",
       "      <td>10.1039/d3va00106g</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Blockchain-enabled decision system for reliabl...   \n",
       "1  Systematic review of data modelling methods fo...   \n",
       "2  Clustering Locations of Collection Centers in ...   \n",
       "3  Artificial Intelligence: Basics, Impact, and H...   \n",
       "4  Intersections between materials science and ma...   \n",
       "\n",
       "                                        doi ml_methods_scispacy  \n",
       "0        10.1016/B978-0-443-33740-6.00012-8                  []  \n",
       "1             10.1080/19397038.2025.2563271                  []  \n",
       "2  10.1109/TEMSCON-ASPAC62480.2024.11025082                  []  \n",
       "3                   10.1188/23.CJON.595-601                  []  \n",
       "4                        10.1039/d3va00106g                  []  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 papers with their extracted ML methods from SciSpaCy\n",
    "df[[\"title\", \"doi\", \"ml_methods_scispacy\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5fc65f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method_count_scispacy\n",
       "0     17911\n",
       "1      8015\n",
       "2      3561\n",
       "3      1782\n",
       "4       951\n",
       "5       468\n",
       "6       236\n",
       "7       110\n",
       "8        56\n",
       "9        22\n",
       "10        9\n",
       "11        5\n",
       "12        2\n",
       "13        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many ML methods SciSpaCy detected per abstract and summarize the distribution\n",
    "df[\"method_count_scispacy\"] = df[\"ml_methods_scispacy\"].str.len()\n",
    "df[\"method_count_scispacy\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6a04ae7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ml_methods_scispacy\n",
       "Neural Network                  5521\n",
       "Random Forest                   3060\n",
       "Support Vector Machine          2106\n",
       "Decision Tree                   1614\n",
       "Convolutional Neural Network    1195\n",
       "Gradient Boosting               1173\n",
       "XGBoost                         1053\n",
       "LSTM                             964\n",
       "Bayesian Method                  882\n",
       "Linear Regression                862\n",
       "K-Nearest Neighbors              798\n",
       "Genetic Algorithm                748\n",
       "Support Vector Regression        693\n",
       "Principal Component Analysis     562\n",
       "Particle Swarm Optimization      542\n",
       "Logistic Regression              469\n",
       "Deep Neural Network              458\n",
       "SHAP                             445\n",
       "Multi-Layer Perceptron           391\n",
       "Gaussian Process Regression      385\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the top 20 most frequently detected ML methods using the SciSpaCy extraction\n",
    "df.explode(\"ml_methods_scispacy\")[\"ml_methods_scispacy\"].value_counts().head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bc4c9f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "      <th>ml_methods_regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20817</th>\n",
       "      <td>Establishment and Optimization of Gas Flow Pre...</td>\n",
       "      <td>10.23919/ChiCC.2018.8483446</td>\n",
       "      <td>[Support Vector Machine, Genetic Algorithm]</td>\n",
       "      <td>['Support Vector Machine', 'Genetic Algorithm']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>Towards Predictive Maintenance of a Heavy-Duty...</td>\n",
       "      <td>10.36001/phmconf.2022.v14i1.3148</td>\n",
       "      <td>[Neural Network, Bayesian Method]</td>\n",
       "      <td>['Bayesian Method', 'Neural Network']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>Deep Learning-Based Hardware Trojan Detection ...</td>\n",
       "      <td>10.1109/TETC.2021.3116484</td>\n",
       "      <td>[LSTM, Convolutional Neural Network]</td>\n",
       "      <td>['Neural Network', 'Convolutional Neural Netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26209</th>\n",
       "      <td>LOF weighted KNN regression ensemble and its a...</td>\n",
       "      <td>10.1007/s12046-023-02283-0</td>\n",
       "      <td>[K-Nearest Neighbors, Local Outlier Factor]</td>\n",
       "      <td>['K-Nearest Neighbors', 'Local Outlier Factor']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>Leveraging AutoML to optimize dataset selectio...</td>\n",
       "      <td>10.1016/j.csbj.2025.10.052</td>\n",
       "      <td>[SHAP]</td>\n",
       "      <td>['SHAP']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "20817  Establishment and Optimization of Gas Flow Pre...   \n",
       "19577  Towards Predictive Maintenance of a Heavy-Duty...   \n",
       "21946  Deep Learning-Based Hardware Trojan Detection ...   \n",
       "26209  LOF weighted KNN regression ensemble and its a...   \n",
       "705    Leveraging AutoML to optimize dataset selectio...   \n",
       "\n",
       "                                    doi  \\\n",
       "20817       10.23919/ChiCC.2018.8483446   \n",
       "19577  10.36001/phmconf.2022.v14i1.3148   \n",
       "21946         10.1109/TETC.2021.3116484   \n",
       "26209        10.1007/s12046-023-02283-0   \n",
       "705          10.1016/j.csbj.2025.10.052   \n",
       "\n",
       "                               ml_methods_scispacy  \\\n",
       "20817  [Support Vector Machine, Genetic Algorithm]   \n",
       "19577            [Neural Network, Bayesian Method]   \n",
       "21946         [LSTM, Convolutional Neural Network]   \n",
       "26209  [K-Nearest Neighbors, Local Outlier Factor]   \n",
       "705                                         [SHAP]   \n",
       "\n",
       "                                        ml_methods_regex  \n",
       "20817    ['Support Vector Machine', 'Genetic Algorithm']  \n",
       "19577              ['Bayesian Method', 'Neural Network']  \n",
       "21946  ['Neural Network', 'Convolutional Neural Netwo...  \n",
       "26209    ['K-Nearest Neighbors', 'Local Outlier Factor']  \n",
       "705                                             ['SHAP']  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly inspect 5 abstracts where SciSpaCy successfully detected ML methods\n",
    "df[df[\"method_count_scispacy\"] > 0][[\"title\", \"doi\", \"ml_methods_scispacy\", \"ml_methods_regex\"]].sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde14409",
   "metadata": {},
   "source": [
    "## Analyze - with both Regex and SciSpacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ec08613e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of abstracts with/without detected ML methods:\n",
      "Regex - With methods: 15651\n",
      "Regex - Without methods: 17479\n",
      "SciSpaCy - With methods: 15219\n",
      "SciSpaCy - Without methods: 17911\n"
     ]
    }
   ],
   "source": [
    "# How many abstracts had minimum 1 method, and how many had none, for each method extraction approach?\n",
    "regex_with_methods = (df[\"method_count\"] > 0).sum()\n",
    "regex_without_methods = (df[\"method_count\"] == 0).sum()\n",
    "scispacy_with_methods = (df[\"method_count_scispacy\"] > 0).sum()\n",
    "scispacy_without_methods = (df[\"method_count_scispacy\"] == 0).sum()\n",
    "\n",
    "print(\"Summary of abstracts with/without detected ML methods:\")\n",
    "\n",
    "print(\"Regex - With methods:\", regex_with_methods)\n",
    "print(\"Regex - Without methods:\", regex_without_methods)\n",
    "print(\"SciSpaCy - With methods:\", scispacy_with_methods)\n",
    "print(\"SciSpaCy - Without methods:\", scispacy_without_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c98e53c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert stringified lists in ml_methods_regex to real Python lists\n",
    "df[\"ml_methods_regex\"] = df[\"ml_methods_regex\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "214ecb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods with 0 matches in both regex and SciSpaCy: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Invariant Causal Prediction']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all ML methods from the dictionary that are never detected by either regex or SciSpaCy\n",
    "\n",
    "# Ensure we are working with sets for easier membership checks\n",
    "df[\"regex_set\"] = df[\"ml_methods_regex\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "df[\"scispacy_set\"] = df[\"ml_methods_scispacy\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "\n",
    "all_methods = list(ml_methods_dict.keys())\n",
    "zero_hit_methods = []\n",
    "\n",
    "for method in all_methods:\n",
    "    regex_hits = df[\"regex_set\"].apply(lambda s: method in s).sum()\n",
    "    scispacy_hits = df[\"scispacy_set\"].apply(lambda s: method in s).sum()\n",
    "    \n",
    "    if regex_hits == 0 and scispacy_hits == 0:\n",
    "        zero_hit_methods.append(method)\n",
    "\n",
    "print(f\"Methods with 0 matches in both regex and SciSpaCy: {len(zero_hit_methods)}\")\n",
    "zero_hit_methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1d0459d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>regex_count</th>\n",
       "      <th>scispacy_count</th>\n",
       "      <th>both_count</th>\n",
       "      <th>regex_only</th>\n",
       "      <th>scispacy_only</th>\n",
       "      <th>union_count</th>\n",
       "      <th>jaccard_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>6659</td>\n",
       "      <td>5521</td>\n",
       "      <td>5521</td>\n",
       "      <td>1138</td>\n",
       "      <td>0</td>\n",
       "      <td>6659</td>\n",
       "      <td>0.829103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3103</td>\n",
       "      <td>3060</td>\n",
       "      <td>3060</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>3103</td>\n",
       "      <td>0.986142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>2176</td>\n",
       "      <td>2106</td>\n",
       "      <td>2106</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2176</td>\n",
       "      <td>0.967831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1652</td>\n",
       "      <td>1614</td>\n",
       "      <td>1614</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1652</td>\n",
       "      <td>0.976998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Convolutional Neural Network</td>\n",
       "      <td>1365</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1365</td>\n",
       "      <td>0.875458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          method  regex_count  scispacy_count  both_count  \\\n",
       "66                Neural Network         6659            5521        5521   \n",
       "79                 Random Forest         3103            3060        3060   \n",
       "91        Support Vector Machine         2176            2106        2106   \n",
       "15                 Decision Tree         1652            1614        1614   \n",
       "13  Convolutional Neural Network         1365            1195        1195   \n",
       "\n",
       "    regex_only  scispacy_only  union_count  jaccard_overlap  \n",
       "66        1138              0         6659         0.829103  \n",
       "79          43              0         3103         0.986142  \n",
       "91          70              0         2176         0.967831  \n",
       "15          38              0         1652         0.976998  \n",
       "13         170              0         1365         0.875458  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure we are working with list -> set for easier membership checks\n",
    "df[\"regex_set\"] = df[\"ml_methods_regex\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "df[\"scispacy_set\"] = df[\"ml_methods_scispacy\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "\n",
    "# Collect the universe of methods seen by either approach\n",
    "all_methods = sorted(\n",
    "    set().union(*df[\"regex_set\"]).union(*df[\"scispacy_set\"])\n",
    ")\n",
    "\n",
    "rows = []\n",
    "\n",
    "# For each method, compute overlap stats between regex and SciSpaCy\n",
    "for method in all_methods:\n",
    "    regex_mask = df[\"regex_set\"].apply(lambda s: method in s)\n",
    "    scis_mask = df[\"scispacy_set\"].apply(lambda s: method in s)\n",
    "    \n",
    "    regex_count = regex_mask.sum()\n",
    "    scispacy_count = scis_mask.sum()\n",
    "    both_count = (regex_mask & scis_mask).sum()\n",
    "    regex_only = (regex_mask & ~scis_mask).sum()\n",
    "    scispacy_only = (~regex_mask & scis_mask).sum()\n",
    "    union_count = (regex_mask | scis_mask).sum()\n",
    "    \n",
    "    jaccard = both_count / union_count if union_count > 0 else 0.0\n",
    "    \n",
    "    rows.append({\n",
    "        \"method\": method,\n",
    "        \"regex_count\": regex_count,\n",
    "        \"scispacy_count\": scispacy_count,\n",
    "        \"both_count\": both_count,\n",
    "        \"regex_only\": regex_only,\n",
    "        \"scispacy_only\": scispacy_only,\n",
    "        \"union_count\": union_count,\n",
    "        \"jaccard_overlap\": jaccard,\n",
    "    })\n",
    "\n",
    "overlap_df = pd.DataFrame(rows)\n",
    "\n",
    "# Sort by popularity (or by overlap) as you like\n",
    "overlap_df_sorted = overlap_df.sort_values(\"union_count\", ascending=False)\n",
    "\n",
    "# For a quick view of the overlap statistics\n",
    "overlap_df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fbaf8e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "      <th>ml_methods_regex</th>\n",
       "      <th>method_count</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "      <th>method_count_scispacy</th>\n",
       "      <th>regex_set</th>\n",
       "      <th>scispacy_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13735</th>\n",
       "      <td>ml_process_control</td>\n",
       "      <td>2-s2.0-85020415893</td>\n",
       "      <td>10.1117/12.2258039</td>\n",
       "      <td>Computational overlay metrology with adaptive ...</td>\n",
       "      <td>© 2017 SPIE.With photolithography as the funda...</td>\n",
       "      <td>With photolithography as the fundamental patte...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[Gradient Boosting]</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Gradient Boosting}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 query_id                 eid                 doi  \\\n",
       "13735  ml_process_control  2-s2.0-85020415893  10.1117/12.2258039   \n",
       "\n",
       "                                                   title  \\\n",
       "13735  Computational overlay metrology with adaptive ...   \n",
       "\n",
       "                                                abstract  \\\n",
       "13735  © 2017 SPIE.With photolithography as the funda...   \n",
       "\n",
       "                                               clean_abs ml_methods_regex  \\\n",
       "13735  With photolithography as the fundamental patte...               []   \n",
       "\n",
       "       method_count  ml_methods_scispacy  method_count_scispacy regex_set  \\\n",
       "13735             0  [Gradient Boosting]                      1        {}   \n",
       "\n",
       "              scispacy_set  \n",
       "13735  {Gradient Boosting}  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract rows where SciSpaCy found at least one method\n",
    "# and regex found none\n",
    "scispacy_only_df = df[\n",
    "    (df[\"scispacy_set\"].apply(len) > 0) &\n",
    "    (df[\"regex_set\"].apply(len) == 0)\n",
    "]\n",
    "\n",
    "scispacy_only_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b157942d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abstracts where only Regex found methods: 433\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "      <th>ml_methods_regex</th>\n",
       "      <th>method_count</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "      <th>method_count_scispacy</th>\n",
       "      <th>regex_set</th>\n",
       "      <th>scispacy_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>ml_recycling_manufacturing</td>\n",
       "      <td>2-s2.0-85166934684</td>\n",
       "      <td>10.1080/15376494.2023.2238220</td>\n",
       "      <td>Machine learning and RSM-CCD analysis of green...</td>\n",
       "      <td>© 2023 Taylor &amp; Francis Group, LLC.This study ...</td>\n",
       "      <td>This study aims to serve as a performance indi...</td>\n",
       "      <td>[Neural Network]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{Neural Network}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>ml_remanufacturing</td>\n",
       "      <td>2-s2.0-85185884385</td>\n",
       "      <td>10.1115/1.4064257</td>\n",
       "      <td>Multiscale Feature Fusion Convolutional Neural...</td>\n",
       "      <td>© 2024 by ASME.The detection of surface damage...</td>\n",
       "      <td>The detection of surface damage is an importan...</td>\n",
       "      <td>[Convolutional Neural Network]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{Convolutional Neural Network}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>ml_plm</td>\n",
       "      <td>2-s2.0-105000236624</td>\n",
       "      <td>10.1016/j.cie.2025.111034</td>\n",
       "      <td>Early screening of potential breakthrough tech...</td>\n",
       "      <td>© 2025 Elsevier LtdMachine learning (ML) appro...</td>\n",
       "      <td>However, their practicality is often limited b...</td>\n",
       "      <td>[Attention Mechanism]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{Attention Mechanism}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>ml_plm</td>\n",
       "      <td>2-s2.0-85138449494</td>\n",
       "      <td>10.1109/TPAMI.2021.3095381</td>\n",
       "      <td>ProtTrans: Toward Understanding the Language o...</td>\n",
       "      <td>© 1979-2012 IEEE.Computational biology and bio...</td>\n",
       "      <td>Computational biology and bioinformatics provi...</td>\n",
       "      <td>[Transformers]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{Transformers}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>ml_plm</td>\n",
       "      <td>2-s2.0-85209659742</td>\n",
       "      <td>10.1007/s11277-024-11659-2</td>\n",
       "      <td>Automated Sleep Disorder Diagnosis Utilising E...</td>\n",
       "      <td>© The Author(s), under exclusive licence to Sp...</td>\n",
       "      <td>Automated sleep disorders diagnosis is difficu...</td>\n",
       "      <td>[LSTM]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{LSTM}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       query_id                  eid  \\\n",
       "126  ml_recycling_manufacturing   2-s2.0-85166934684   \n",
       "156          ml_remanufacturing   2-s2.0-85185884385   \n",
       "253                      ml_plm  2-s2.0-105000236624   \n",
       "289                      ml_plm   2-s2.0-85138449494   \n",
       "372                      ml_plm   2-s2.0-85209659742   \n",
       "\n",
       "                               doi  \\\n",
       "126  10.1080/15376494.2023.2238220   \n",
       "156              10.1115/1.4064257   \n",
       "253      10.1016/j.cie.2025.111034   \n",
       "289     10.1109/TPAMI.2021.3095381   \n",
       "372     10.1007/s11277-024-11659-2   \n",
       "\n",
       "                                                 title  \\\n",
       "126  Machine learning and RSM-CCD analysis of green...   \n",
       "156  Multiscale Feature Fusion Convolutional Neural...   \n",
       "253  Early screening of potential breakthrough tech...   \n",
       "289  ProtTrans: Toward Understanding the Language o...   \n",
       "372  Automated Sleep Disorder Diagnosis Utilising E...   \n",
       "\n",
       "                                              abstract  \\\n",
       "126  © 2023 Taylor & Francis Group, LLC.This study ...   \n",
       "156  © 2024 by ASME.The detection of surface damage...   \n",
       "253  © 2025 Elsevier LtdMachine learning (ML) appro...   \n",
       "289  © 1979-2012 IEEE.Computational biology and bio...   \n",
       "372  © The Author(s), under exclusive licence to Sp...   \n",
       "\n",
       "                                             clean_abs  \\\n",
       "126  This study aims to serve as a performance indi...   \n",
       "156  The detection of surface damage is an importan...   \n",
       "253  However, their practicality is often limited b...   \n",
       "289  Computational biology and bioinformatics provi...   \n",
       "372  Automated sleep disorders diagnosis is difficu...   \n",
       "\n",
       "                   ml_methods_regex  method_count ml_methods_scispacy  \\\n",
       "126                [Neural Network]             1                  []   \n",
       "156  [Convolutional Neural Network]             1                  []   \n",
       "253           [Attention Mechanism]             1                  []   \n",
       "289                  [Transformers]             1                  []   \n",
       "372                          [LSTM]             1                  []   \n",
       "\n",
       "     method_count_scispacy                       regex_set scispacy_set  \n",
       "126                      0                {Neural Network}           {}  \n",
       "156                      0  {Convolutional Neural Network}           {}  \n",
       "253                      0           {Attention Mechanism}           {}  \n",
       "289                      0                  {Transformers}           {}  \n",
       "372                      0                          {LSTM}           {}  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract rows where Regex found at least one method\n",
    "# and SciSpacy found none\n",
    "regex_only_df = df[\n",
    "    (df[\"regex_set\"].apply(len) > 0) &\n",
    "    (df[\"scispacy_set\"].apply(len) == 0)\n",
    "]\n",
    "\n",
    "# How many rows are in this set?\n",
    "print(\"Number of abstracts where only Regex found methods:\", len(regex_only_df))\n",
    "\n",
    "regex_only_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e33f5",
   "metadata": {},
   "source": [
    "## Extract ML-Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "01038781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define common \"method head\" words and extract ML-related candidate phrases from parsed abstracts\n",
    "# METHOD_HEADS = {\n",
    "#     \"network\", \"networks\",\n",
    "#     \"model\", \"models\",\n",
    "#     \"algorithm\", \"algorithms\",\n",
    "#     \"classifier\", \"classifiers\",\n",
    "#     \"regression\",\n",
    "#     \"forest\", \"forests\",\n",
    "#     \"clustering\", \"clusterer\", \"clusterers\",\n",
    "#     \"encoder\", \"encoders\",\n",
    "#     \"autoencoder\", \"autoencoders\",\n",
    "#     \"transformer\", \"transformers\",\n",
    "#     \"estimators\", \"estimator\",\n",
    "#     \"approach\", \"approaches\",\n",
    "#     \"architecture\", \"architectures\",\n",
    "# }\n",
    "\n",
    "# def extract_candidate_phrases_from_doc(doc):\n",
    "#     \"\"\"Extract candidate ML-method phrases from a spaCy Doc.\"\"\"\n",
    "#     candidates = []\n",
    "\n",
    "#     # Noun chunks that end with a \"method head\" word\n",
    "#     for chunk in doc.noun_chunks:\n",
    "#         tokens = [t for t in chunk if not t.is_punct]\n",
    "#         if not tokens:\n",
    "#             continue\n",
    "\n",
    "#         head = tokens[-1].lemma_.lower()\n",
    "#         if head in METHOD_HEADS:\n",
    "#             if 1 <= len(tokens) <= 7:\n",
    "#                 phrase = chunk.text.strip()\n",
    "#                 candidates.append(phrase)\n",
    "\n",
    "#     # All-caps acronyms (e.g., SVM, CNN, LSTM)\n",
    "#     for token in doc:\n",
    "#         if (\n",
    "#             token.is_alpha\n",
    "#             and token.text.isupper()\n",
    "#             and 2 <= len(token.text) <= 6\n",
    "#         ):\n",
    "#             candidates.append(token.text)\n",
    "\n",
    "#     # Remove duplicates, preserve order\n",
    "#     return list(dict.fromkeys(candidates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "882b1926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract ML-related candidate phrases from all abstracts efficiently using spaCy's nlp.pipe\n",
    "# texts = df[\"clean_abs\"].fillna(\"\").tolist()\n",
    "\n",
    "# candidate_counter = collections.Counter()\n",
    "\n",
    "# # Batch processing with multiple processes for faster NLP execution\n",
    "# for doc in tqdm(\n",
    "#     nlp.pipe(texts, batch_size=64, n_process=8),\n",
    "#     total=len(texts)\n",
    "# ):\n",
    "#     for cand in extract_candidate_phrases_from_doc(doc):\n",
    "#         candidate_counter[cand] += 1\n",
    "\n",
    "# print(f\"Extracted {len(candidate_counter)} unique candidate phrases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "57879afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show the top candidate phrases by frequency\n",
    "# for phrase, count in candidate_counter.most_common(100):\n",
    "#     print(f\"{count:4d}  {phrase}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59191c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-catalogue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
