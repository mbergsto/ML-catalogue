{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbe61b2",
   "metadata": {},
   "source": [
    "- Apply rule-based extraction to identify machine learning methods in abstracts\n",
    "- Test two complementary approaches:\n",
    "  - **Regex-based matching** for known ML terms\n",
    "  - **SciSpaCy + EntityRuler** for robust phrase detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5921f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "from typing import List\n",
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50837a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All directories verified/created.\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "\n",
    "data_path = Path(\"../../data/short-raw-refs-abs\")\n",
    "processed_abstracts_path = Path(\"../../data/processed/abstracts\")\n",
    "save_path = processed_abstracts_path / \"regex_scispacy\"\n",
    "ml_methods_path = Path(\"../../ml_methods/ml_methods_dict.json\")\n",
    "\n",
    "\n",
    "# Ensure directories exist\n",
    "for p in [data_path, processed_abstracts_path, save_path]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"All directories verified/created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a276afda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 52290 abstracts from 24 queries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105018574505</td>\n",
       "      <td>10.1016/j.measurement.2025.119261</td>\n",
       "      <td>Distillation anomaly and fault detection based...</td>\n",
       "      <td>© 2025 The Author(s)The detection of anomalies...</td>\n",
       "      <td>Indeed, highly efficient systems do not always...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105019192533</td>\n",
       "      <td>10.1007/978-3-032-06118-8_30</td>\n",
       "      <td>From Lab to Factory: Pitfalls and Guidelines f...</td>\n",
       "      <td>© The Author(s), under exclusive license to Sp...</td>\n",
       "      <td>The detection and localization of quality-rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105016669957</td>\n",
       "      <td>10.1007/978-3-032-04200-2_5</td>\n",
       "      <td>Intelligent Defect Detection for Manufacturing...</td>\n",
       "      <td>© The Author(s), under exclusive license to Sp...</td>\n",
       "      <td>In modern Industry, I4.0, artificial intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-85218693791</td>\n",
       "      <td>10.1038/s41598-025-90810-w</td>\n",
       "      <td>Hybrid machine learning framework for predicti...</td>\n",
       "      <td>© The Author(s) 2025.The critical necessity fo...</td>\n",
       "      <td>The critical necessity for sophisticated predi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105018301117</td>\n",
       "      <td>10.1016/j.comnet.2025.111753</td>\n",
       "      <td>BGP anomaly detection using the raw internet t...</td>\n",
       "      <td>© 2025 The AuthorsThe Border Gateway Protocol ...</td>\n",
       "      <td>Hence, detecting any anomaly concerning BGP an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          query_id                  eid  \\\n",
       "0  ml_anomaly_detection_production  2-s2.0-105018574505   \n",
       "1  ml_anomaly_detection_production  2-s2.0-105019192533   \n",
       "2  ml_anomaly_detection_production  2-s2.0-105016669957   \n",
       "3  ml_anomaly_detection_production   2-s2.0-85218693791   \n",
       "4  ml_anomaly_detection_production  2-s2.0-105018301117   \n",
       "\n",
       "                                 doi  \\\n",
       "0  10.1016/j.measurement.2025.119261   \n",
       "1       10.1007/978-3-032-06118-8_30   \n",
       "2        10.1007/978-3-032-04200-2_5   \n",
       "3         10.1038/s41598-025-90810-w   \n",
       "4       10.1016/j.comnet.2025.111753   \n",
       "\n",
       "                                               title  \\\n",
       "0  Distillation anomaly and fault detection based...   \n",
       "1  From Lab to Factory: Pitfalls and Guidelines f...   \n",
       "2  Intelligent Defect Detection for Manufacturing...   \n",
       "3  Hybrid machine learning framework for predicti...   \n",
       "4  BGP anomaly detection using the raw internet t...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  © 2025 The Author(s)The detection of anomalies...   \n",
       "1  © The Author(s), under exclusive license to Sp...   \n",
       "2  © The Author(s), under exclusive license to Sp...   \n",
       "3  © The Author(s) 2025.The critical necessity fo...   \n",
       "4  © 2025 The AuthorsThe Border Gateway Protocol ...   \n",
       "\n",
       "                                           clean_abs  \n",
       "0  Indeed, highly efficient systems do not always...  \n",
       "1  The detection and localization of quality-rela...  \n",
       "2  In modern Industry, I4.0, artificial intellige...  \n",
       "3  The critical necessity for sophisticated predi...  \n",
       "4  Hence, detecting any anomaly concerning BGP an...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load abstracts dataset\n",
    "\n",
    "abstracts_path = processed_abstracts_path / \"abstracts.csv\"\n",
    "df = pd.read_csv(abstracts_path)\n",
    "\n",
    "print(f\"Loaded {len(df)} abstracts from {df['query_id'].nunique()} queries.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f60535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 52290\n",
      "After removing duplicates: 33130\n",
      "Remaining duplicate DOIs: 0\n"
     ]
    }
   ],
   "source": [
    "# Count how many rows each query_id has\n",
    "query_counts = df[\"query_id\"].value_counts().to_dict()\n",
    "\n",
    "# Create a copy and map the counts to each row\n",
    "df = df.copy()\n",
    "df[\"query_size\"] = df[\"query_id\"].map(query_counts)\n",
    "\n",
    "# Sort so that query groups with fewer rows are prioritized\n",
    "df_sorted = df.sort_values(by=\"query_size\", ascending=True)\n",
    "\n",
    "# Remove duplicate DOIs, keeping the one in the smallest query group\n",
    "df_dedup = df_sorted.drop_duplicates(subset=\"doi\", keep=\"first\").drop(columns=[\"query_size\"])\n",
    "\n",
    "# Print results\n",
    "print(\"Original dataset size:\", len(df))\n",
    "print(\"After removing duplicates:\", len(df_dedup))\n",
    "print(\"Remaining duplicate DOIs:\", df_dedup[\"doi\"].duplicated().sum())\n",
    "\n",
    "df = df_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ec40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ml_methods_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    ml_methods_dict = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec15316",
   "metadata": {},
   "source": [
    "## Regex matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f33c5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33130/33130 [01:05<00:00, 503.52it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_methods(text, term_dict):\n",
    "    # Return empty list if input is not a string\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    found = []\n",
    "    \n",
    "    for method, phrases in term_dict.items():\n",
    "        for phrase in phrases:\n",
    "            # Escape special characters and enforce word boundaries\n",
    "            pattern = r\"\\b\" + re.escape(phrase.lower()) + r\"\\b\"\n",
    "            \n",
    "            # Perform case-insensitive boundary-safe regex search\n",
    "            if re.search(pattern, text.lower()):\n",
    "                found.append(method)\n",
    "                break  # Stop checking more variants for this method\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    return list(dict.fromkeys(found))\n",
    "\n",
    "# Apply extraction with pandas progress bar\n",
    "tqdm.pandas()\n",
    "df[\"ml_methods_regex\"] = df[\"clean_abs\"].fillna(\"\").progress_apply(\n",
    "    lambda x: extract_methods(x, ml_methods_dict)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6cde623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_count\n",
      "0     18184\n",
      "1      7339\n",
      "2      4029\n",
      "3      1896\n",
      "4       944\n",
      "5       425\n",
      "6       180\n",
      "7        82\n",
      "8        37\n",
      "9         7\n",
      "10        3\n",
      "11        3\n",
      "12        1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ml_methods_regex\n",
       "Neural Network                        6747\n",
       "Random Forest                         3103\n",
       "Support Vector Machine                2176\n",
       "Decision Tree                         1652\n",
       "Convolutional Neural Network          1365\n",
       "Gradient Boosting                     1185\n",
       "LSTM                                  1107\n",
       "XGBoost                               1091\n",
       "Reinforcement Learning                 976\n",
       "Linear Regression                      906\n",
       "Bayesian Method                        893\n",
       "Genetic Algorithm                      843\n",
       "K-Nearest Neighbors                    813\n",
       "Support Vector Regression              716\n",
       "Particle Swarm Optimization            597\n",
       "Principal Component Analysis           587\n",
       "Deep Neural Network                    483\n",
       "Logistic Regression                    473\n",
       "SHAP                                   460\n",
       "Multi-Layer Perceptron                 420\n",
       "Gaussian Process Regression            396\n",
       "K-Means                                345\n",
       "Recurrent Neural Network               318\n",
       "Explainable AI                         294\n",
       "Gated Recurrent Unit                   210\n",
       "Deep Reinforcement Learning            202\n",
       "ARIMA                                  151\n",
       "Q-Learning                             118\n",
       "Isolation Forest                       103\n",
       "Proximal Policy Optimization            55\n",
       "Local Outlier Factor                    44\n",
       "Deep Q-Network                          44\n",
       "Actor-Critic                            43\n",
       "Policy Gradient                         41\n",
       "Deep Deterministic Policy Gradient      39\n",
       "Squared Prediction Error                28\n",
       "Soft Actor-Critic                       27\n",
       "Hotelling T2                            14\n",
       "Twin Delayed DDPG                        9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many ML methods were detected per abstract using the regex-based approach\n",
    "df[\"method_count\"] = df[\"ml_methods_regex\"].str.len()\n",
    "print(df[\"method_count\"].value_counts().sort_index())\n",
    "\n",
    "# Show the top 20 most frequently detected ML methods across all abstracts\n",
    "df.explode(\"ml_methods_regex\")[\"ml_methods_regex\"].value_counts().head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f58689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed abstracts with ML methods to: ../../data/processed/abstracts/regex_scispacy/abstracts_with_ml_methods_regex.csv\n"
     ]
    }
   ],
   "source": [
    "# Save updated dataframe with extracted ML methods\n",
    "output_path = save_path / \"abstracts_with_ml_methods_regex.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved processed abstracts with ML methods to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91fc441",
   "metadata": {},
   "source": [
    "## Scispacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8fbe9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer', 'parser', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# Load the large SciSpaCy scientific language model and list all enabled NLP pipeline components\n",
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691d91b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 87 ML_METHOD patterns to EntityRuler.\n"
     ]
    }
   ],
   "source": [
    "# Add an EntityRuler to the NLP pipeline and register patterns for ML method detection\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "patterns = []\n",
    "\n",
    "# Create token-based matching patterns for each ML method phrase\n",
    "for label, phrases in ml_methods_dict.items():\n",
    "    for phrase in phrases:\n",
    "        # Create a case-insensitive match pattern using LOWER tokens\n",
    "        pattern = [{\"LOWER\": token.lower()} for token in phrase.split()]\n",
    "        patterns.append({\n",
    "            \"label\": \"ML_METHOD\",  # Custom entity label for ML methods\n",
    "            \"pattern\": pattern,\n",
    "            \"id\": label  # Canonical method name stored in ent_id_\n",
    "        })\n",
    "\n",
    "# Register all patterns in the EntityRuler\n",
    "ruler.add_patterns(patterns)\n",
    "print(f\"Added {len(patterns)} ML_METHOD patterns to EntityRuler.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd437b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ML method entities from a single abstract using the SciSpaCy EntityRuler\n",
    "def extract_ml_methods_scispacy(text: str) -> List[str]:\n",
    "    # Return empty list if input is not valid text\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    methods = []\n",
    "    \n",
    "    # Collect all detected ML_METHOD entities with their canonical IDs\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ML_METHOD\":\n",
    "            canonical = ent.ent_id_ if ent.ent_id_ else ent.text\n",
    "            methods.append(canonical)\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_methods = list(dict.fromkeys(methods))\n",
    "    return unique_methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6312ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33130/33130 [01:56<00:00, 283.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply the SciSpaCy EntityRuler to extract ML methods for all abstracts efficiently using nlp.pipe\n",
    "texts = df[\"clean_abs\"].fillna(\"\").tolist()\n",
    "\n",
    "ml_methods_all = []\n",
    "\n",
    "# Process abstracts in batches\n",
    "for doc in tqdm(nlp.pipe(texts, batch_size=32, n_process=8), total=len(texts)):\n",
    "    methods = []\n",
    "    \n",
    "    # Collect ML_METHOD entities found in each processed document\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ML_METHOD\":\n",
    "            canonical = ent.ent_id_ if ent.ent_id_ else ent.text\n",
    "            methods.append(canonical)\n",
    "            \n",
    "    # Store unique detected methods for this abstract\n",
    "    ml_methods_all.append(list(dict.fromkeys(methods)))\n",
    "\n",
    "# Save results\n",
    "df[\"ml_methods_scispacy\"] = ml_methods_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdab767e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed abstracts with ML methods to: ../../data/processed/abstracts/regex_scispacy/abstracts_with_ml_methods.csv\n"
     ]
    }
   ],
   "source": [
    "# Save updated dataframe with extracted ML methods\n",
    "output_path = save_path / \"abstracts_with_ml_methods.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved processed abstracts with ML methods to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250de0ad",
   "metadata": {},
   "source": [
    "### SciSpacy: Analyze Abstracts with ML methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7e0ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(save_path / \"abstracts_with_ml_methods.csv\")\n",
    "\n",
    "# Convert string lists to lists\n",
    "df[\"ml_methods_scispacy\"] = df[\"ml_methods_scispacy\"].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1d68766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blockchain-enabled decision system for reliabl...</td>\n",
       "      <td>10.1016/B978-0-443-33740-6.00012-8</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Systematic review of data modelling methods fo...</td>\n",
       "      <td>10.1080/19397038.2025.2563271</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clustering Locations of Collection Centers in ...</td>\n",
       "      <td>10.1109/TEMSCON-ASPAC62480.2024.11025082</td>\n",
       "      <td>[Reinforcement Learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artificial Intelligence: Basics, Impact, and H...</td>\n",
       "      <td>10.1188/23.CJON.595-601</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intersections between materials science and ma...</td>\n",
       "      <td>10.1039/d3va00106g</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Measuring Carbon in Cities and Their Buildings...</td>\n",
       "      <td>10.3390/asi6050076</td>\n",
       "      <td>[Linear Regression]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Predictive modeling for the quantity of recycl...</td>\n",
       "      <td>10.1016/j.resconrec.2023.107073</td>\n",
       "      <td>[Support Vector Regression, Gradient Boosting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Organizational Maturity and Its Influence on P...</td>\n",
       "      <td>10.1007/978-3-031-94484-0_27</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Toward Sustainable Manufacturing: A Review on ...</td>\n",
       "      <td>10.1109/ACCESS.2025.3576441</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Integrating Digital Twins and Robotics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Blockchain-enabled decision system for reliabl...   \n",
       "1  Systematic review of data modelling methods fo...   \n",
       "2  Clustering Locations of Collection Centers in ...   \n",
       "3  Artificial Intelligence: Basics, Impact, and H...   \n",
       "4  Intersections between materials science and ma...   \n",
       "5  Measuring Carbon in Cities and Their Buildings...   \n",
       "6  Predictive modeling for the quantity of recycl...   \n",
       "7  Organizational Maturity and Its Influence on P...   \n",
       "8  Toward Sustainable Manufacturing: A Review on ...   \n",
       "9             Integrating Digital Twins and Robotics   \n",
       "\n",
       "                                        doi  \\\n",
       "0        10.1016/B978-0-443-33740-6.00012-8   \n",
       "1             10.1080/19397038.2025.2563271   \n",
       "2  10.1109/TEMSCON-ASPAC62480.2024.11025082   \n",
       "3                   10.1188/23.CJON.595-601   \n",
       "4                        10.1039/d3va00106g   \n",
       "5                        10.3390/asi6050076   \n",
       "6           10.1016/j.resconrec.2023.107073   \n",
       "7              10.1007/978-3-031-94484-0_27   \n",
       "8               10.1109/ACCESS.2025.3576441   \n",
       "9                                       NaN   \n",
       "\n",
       "                                 ml_methods_scispacy  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                           [Reinforcement Learning]  \n",
       "3                                                 []  \n",
       "4                                                 []  \n",
       "5                                [Linear Regression]  \n",
       "6  [Support Vector Regression, Gradient Boosting,...  \n",
       "7                                                 []  \n",
       "8                                                 []  \n",
       "9                                                 []  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 papers with their extracted ML methods from SciSpaCy\n",
    "df[[\"title\", \"doi\", \"ml_methods_scispacy\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fc65f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method_count_scispacy\n",
       "0     18568\n",
       "1      8005\n",
       "2      3442\n",
       "3      1668\n",
       "4       806\n",
       "5       376\n",
       "6       153\n",
       "7        67\n",
       "8        32\n",
       "9         6\n",
       "10        5\n",
       "11        1\n",
       "12        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many ML methods SciSpaCy detected per abstract and summarize the distribution\n",
    "df[\"method_count_scispacy\"] = df[\"ml_methods_scispacy\"].str.len()\n",
    "df[\"method_count_scispacy\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a04ae7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ml_methods_scispacy\n",
       "Neural Network                  5580\n",
       "Random Forest                   3060\n",
       "Support Vector Machine          2127\n",
       "Decision Tree                   1614\n",
       "Convolutional Neural Network    1195\n",
       "Gradient Boosting               1173\n",
       "XGBoost                         1053\n",
       "LSTM                             964\n",
       "Bayesian Method                  882\n",
       "Linear Regression                862\n",
       "Reinforcement Learning           811\n",
       "K-Nearest Neighbors              798\n",
       "Genetic Algorithm                748\n",
       "Support Vector Regression        693\n",
       "Principal Component Analysis     562\n",
       "Particle Swarm Optimization      542\n",
       "Logistic Regression              469\n",
       "Deep Neural Network              458\n",
       "SHAP                             445\n",
       "Multi-Layer Perceptron           391\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the top 20 most frequently detected ML methods using the SciSpaCy extraction\n",
    "df.explode(\"ml_methods_scispacy\")[\"ml_methods_scispacy\"].value_counts().head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc4c9f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "      <th>ml_methods_regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12398</th>\n",
       "      <td>Research on machine learning-based solar energ...</td>\n",
       "      <td>10.1117/12.3026841</td>\n",
       "      <td>[Decision Tree, Support Vector Machine, Neural...</td>\n",
       "      <td>['Support Vector Machine', 'Decision Tree', 'N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11803</th>\n",
       "      <td>A hybrid model based on bidirectional long sho...</td>\n",
       "      <td>10.1080/01605682.2020.1843976</td>\n",
       "      <td>[Neural Network, Multi-Layer Perceptron, Suppo...</td>\n",
       "      <td>['Support Vector Regression', 'Neural Network'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20491</th>\n",
       "      <td>A modified TimeGAN-based data augmentation app...</td>\n",
       "      <td>10.1016/j.ress.2025.111297</td>\n",
       "      <td>[Gated Recurrent Unit, LSTM]</td>\n",
       "      <td>['Gated Recurrent Unit', 'LSTM']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14289</th>\n",
       "      <td>Active Simulation of Transient Wind Field in a...</td>\n",
       "      <td>10.1061/(ASCE)EM.1943-7889.0001967</td>\n",
       "      <td>[Deep Reinforcement Learning, Reinforcement Le...</td>\n",
       "      <td>['Neural Network', 'Deep Neural Network', 'Rei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7476</th>\n",
       "      <td>A machine learning approach for collaborative ...</td>\n",
       "      <td>10.1016/j.promfg.2020.10.003</td>\n",
       "      <td>[Reinforcement Learning]</td>\n",
       "      <td>['Reinforcement Learning']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "12398  Research on machine learning-based solar energ...   \n",
       "11803  A hybrid model based on bidirectional long sho...   \n",
       "20491  A modified TimeGAN-based data augmentation app...   \n",
       "14289  Active Simulation of Transient Wind Field in a...   \n",
       "7476   A machine learning approach for collaborative ...   \n",
       "\n",
       "                                      doi  \\\n",
       "12398                  10.1117/12.3026841   \n",
       "11803       10.1080/01605682.2020.1843976   \n",
       "20491          10.1016/j.ress.2025.111297   \n",
       "14289  10.1061/(ASCE)EM.1943-7889.0001967   \n",
       "7476         10.1016/j.promfg.2020.10.003   \n",
       "\n",
       "                                     ml_methods_scispacy  \\\n",
       "12398  [Decision Tree, Support Vector Machine, Neural...   \n",
       "11803  [Neural Network, Multi-Layer Perceptron, Suppo...   \n",
       "20491                       [Gated Recurrent Unit, LSTM]   \n",
       "14289  [Deep Reinforcement Learning, Reinforcement Le...   \n",
       "7476                            [Reinforcement Learning]   \n",
       "\n",
       "                                        ml_methods_regex  \n",
       "12398  ['Support Vector Machine', 'Decision Tree', 'N...  \n",
       "11803  ['Support Vector Regression', 'Neural Network'...  \n",
       "20491                   ['Gated Recurrent Unit', 'LSTM']  \n",
       "14289  ['Neural Network', 'Deep Neural Network', 'Rei...  \n",
       "7476                          ['Reinforcement Learning']  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly inspect 5 abstracts where SciSpaCy successfully detected ML methods\n",
    "df[df[\"method_count_scispacy\"] > 0][[\"title\", \"doi\", \"ml_methods_scispacy\", \"ml_methods_regex\"]].sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde14409",
   "metadata": {},
   "source": [
    "## Compare Regex and SciSpacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c98e53c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert stringified lists in ml_methods_regex to real Python lists\n",
    "df[\"ml_methods_regex\"] = df[\"ml_methods_regex\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "214ecb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods with 0 matches in both regex and SciSpaCy: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all ML methods from the dictionary that are never detected by either regex or SciSpaCy\n",
    "\n",
    "# Ensure we are working with sets for easier membership checks\n",
    "df[\"regex_set\"] = df[\"ml_methods_regex\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "df[\"scispacy_set\"] = df[\"ml_methods_scispacy\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "\n",
    "all_methods = list(ml_methods_dict.keys())\n",
    "zero_hit_methods = []\n",
    "\n",
    "for method in all_methods:\n",
    "    regex_hits = df[\"regex_set\"].apply(lambda s: method in s).sum()\n",
    "    scispacy_hits = df[\"scispacy_set\"].apply(lambda s: method in s).sum()\n",
    "    \n",
    "    if regex_hits == 0 and scispacy_hits == 0:\n",
    "        zero_hit_methods.append(method)\n",
    "\n",
    "print(f\"Methods with 0 matches in both regex and SciSpaCy: {len(zero_hit_methods)}\")\n",
    "zero_hit_methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d0459d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>regex_count</th>\n",
       "      <th>scispacy_count</th>\n",
       "      <th>both_count</th>\n",
       "      <th>regex_only</th>\n",
       "      <th>scispacy_only</th>\n",
       "      <th>union_count</th>\n",
       "      <th>jaccard_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>6747</td>\n",
       "      <td>5580</td>\n",
       "      <td>5580</td>\n",
       "      <td>1167</td>\n",
       "      <td>0</td>\n",
       "      <td>6747</td>\n",
       "      <td>0.827034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3103</td>\n",
       "      <td>3060</td>\n",
       "      <td>3060</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>3103</td>\n",
       "      <td>0.986142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>2176</td>\n",
       "      <td>2127</td>\n",
       "      <td>2127</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>2176</td>\n",
       "      <td>0.977482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1652</td>\n",
       "      <td>1614</td>\n",
       "      <td>1614</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1652</td>\n",
       "      <td>0.976998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Convolutional Neural Network</td>\n",
       "      <td>1365</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1365</td>\n",
       "      <td>0.875458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1185</td>\n",
       "      <td>1173</td>\n",
       "      <td>1172</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1186</td>\n",
       "      <td>0.988196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>1107</td>\n",
       "      <td>964</td>\n",
       "      <td>964</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>1107</td>\n",
       "      <td>0.870822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1091</td>\n",
       "      <td>1053</td>\n",
       "      <td>1053</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1091</td>\n",
       "      <td>0.965170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Reinforcement Learning</td>\n",
       "      <td>976</td>\n",
       "      <td>811</td>\n",
       "      <td>811</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>976</td>\n",
       "      <td>0.830943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>906</td>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>906</td>\n",
       "      <td>0.951435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayesian Method</td>\n",
       "      <td>893</td>\n",
       "      <td>882</td>\n",
       "      <td>882</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>0.987682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Genetic Algorithm</td>\n",
       "      <td>843</td>\n",
       "      <td>748</td>\n",
       "      <td>748</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>843</td>\n",
       "      <td>0.887307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>813</td>\n",
       "      <td>798</td>\n",
       "      <td>798</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>813</td>\n",
       "      <td>0.981550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Support Vector Regression</td>\n",
       "      <td>716</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>716</td>\n",
       "      <td>0.967877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Particle Swarm Optimization</td>\n",
       "      <td>597</td>\n",
       "      <td>542</td>\n",
       "      <td>542</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>597</td>\n",
       "      <td>0.907873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Principal Component Analysis</td>\n",
       "      <td>587</td>\n",
       "      <td>562</td>\n",
       "      <td>562</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>587</td>\n",
       "      <td>0.957411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deep Neural Network</td>\n",
       "      <td>483</td>\n",
       "      <td>458</td>\n",
       "      <td>458</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>483</td>\n",
       "      <td>0.948240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>473</td>\n",
       "      <td>469</td>\n",
       "      <td>469</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>473</td>\n",
       "      <td>0.991543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SHAP</td>\n",
       "      <td>460</td>\n",
       "      <td>445</td>\n",
       "      <td>445</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>0.967391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Multi-Layer Perceptron</td>\n",
       "      <td>420</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>420</td>\n",
       "      <td>0.930952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gaussian Process Regression</td>\n",
       "      <td>396</td>\n",
       "      <td>385</td>\n",
       "      <td>385</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>396</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>345</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>0.965217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Recurrent Neural Network</td>\n",
       "      <td>318</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>0.940252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Explainable AI</td>\n",
       "      <td>294</td>\n",
       "      <td>294</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gated Recurrent Unit</td>\n",
       "      <td>210</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>0.938095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deep Reinforcement Learning</td>\n",
       "      <td>202</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>0.980198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARIMA</td>\n",
       "      <td>151</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0.973510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Q-Learning</td>\n",
       "      <td>118</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>0.923729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Proximal Policy Optimization</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          method  regex_count  scispacy_count  both_count  \\\n",
       "23                Neural Network         6747            5580        5580   \n",
       "29                 Random Forest         3103            3060        3060   \n",
       "35        Support Vector Machine         2176            2127        2127   \n",
       "4                  Decision Tree         1652            1614        1614   \n",
       "3   Convolutional Neural Network         1365            1195        1195   \n",
       "13             Gradient Boosting         1185            1173        1172   \n",
       "18                          LSTM         1107             964         964   \n",
       "38                       XGBoost         1091            1053        1053   \n",
       "31        Reinforcement Learning          976             811         811   \n",
       "19             Linear Regression          906             862         862   \n",
       "2                Bayesian Method          893             882         882   \n",
       "12             Genetic Algorithm          843             748         748   \n",
       "17           K-Nearest Neighbors          813             798         798   \n",
       "36     Support Vector Regression          716             693         693   \n",
       "24   Particle Swarm Optimization          597             542         542   \n",
       "26  Principal Component Analysis          587             562         562   \n",
       "6            Deep Neural Network          483             458         458   \n",
       "21           Logistic Regression          473             469         469   \n",
       "32                          SHAP          460             445         445   \n",
       "22        Multi-Layer Perceptron          420             391         391   \n",
       "11   Gaussian Process Regression          396             385         385   \n",
       "16                       K-Means          345             333         333   \n",
       "30      Recurrent Neural Network          318             299         299   \n",
       "9                 Explainable AI          294             294         294   \n",
       "10          Gated Recurrent Unit          210             197         197   \n",
       "8    Deep Reinforcement Learning          202             198         198   \n",
       "0                          ARIMA          151             147         147   \n",
       "28                    Q-Learning          118             109         109   \n",
       "15              Isolation Forest          103             103         103   \n",
       "27  Proximal Policy Optimization           55              55          55   \n",
       "\n",
       "    regex_only  scispacy_only  union_count  jaccard_overlap  \n",
       "23        1167              0         6747         0.827034  \n",
       "29          43              0         3103         0.986142  \n",
       "35          49              0         2176         0.977482  \n",
       "4           38              0         1652         0.976998  \n",
       "3          170              0         1365         0.875458  \n",
       "13          13              1         1186         0.988196  \n",
       "18         143              0         1107         0.870822  \n",
       "38          38              0         1091         0.965170  \n",
       "31         165              0          976         0.830943  \n",
       "19          44              0          906         0.951435  \n",
       "2           11              0          893         0.987682  \n",
       "12          95              0          843         0.887307  \n",
       "17          15              0          813         0.981550  \n",
       "36          23              0          716         0.967877  \n",
       "24          55              0          597         0.907873  \n",
       "26          25              0          587         0.957411  \n",
       "6           25              0          483         0.948240  \n",
       "21           4              0          473         0.991543  \n",
       "32          15              0          460         0.967391  \n",
       "22          29              0          420         0.930952  \n",
       "11          11              0          396         0.972222  \n",
       "16          12              0          345         0.965217  \n",
       "30          19              0          318         0.940252  \n",
       "9            0              0          294         1.000000  \n",
       "10          13              0          210         0.938095  \n",
       "8            4              0          202         0.980198  \n",
       "0            4              0          151         0.973510  \n",
       "28           9              0          118         0.923729  \n",
       "15           0              0          103         1.000000  \n",
       "27           0              0           55         1.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure we are working with list -> set for easier membership checks\n",
    "df[\"regex_set\"] = df[\"ml_methods_regex\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "df[\"scispacy_set\"] = df[\"ml_methods_scispacy\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "\n",
    "# Collect the universe of methods seen by either approach\n",
    "all_methods = sorted(\n",
    "    set().union(*df[\"regex_set\"]).union(*df[\"scispacy_set\"])\n",
    ")\n",
    "\n",
    "rows = []\n",
    "\n",
    "# For each method, compute overlap stats between regex and SciSpaCy\n",
    "for method in all_methods:\n",
    "    regex_mask = df[\"regex_set\"].apply(lambda s: method in s)\n",
    "    scis_mask = df[\"scispacy_set\"].apply(lambda s: method in s)\n",
    "    \n",
    "    regex_count = regex_mask.sum()\n",
    "    scispacy_count = scis_mask.sum()\n",
    "    both_count = (regex_mask & scis_mask).sum()\n",
    "    regex_only = (regex_mask & ~scis_mask).sum()\n",
    "    scispacy_only = (~regex_mask & scis_mask).sum()\n",
    "    union_count = (regex_mask | scis_mask).sum()\n",
    "    \n",
    "    jaccard = both_count / union_count if union_count > 0 else 0.0\n",
    "    \n",
    "    rows.append({\n",
    "        \"method\": method,\n",
    "        \"regex_count\": regex_count,\n",
    "        \"scispacy_count\": scispacy_count,\n",
    "        \"both_count\": both_count,\n",
    "        \"regex_only\": regex_only,\n",
    "        \"scispacy_only\": scispacy_only,\n",
    "        \"union_count\": union_count,\n",
    "        \"jaccard_overlap\": jaccard,\n",
    "    })\n",
    "\n",
    "overlap_df = pd.DataFrame(rows)\n",
    "\n",
    "# Sort by popularity (or by overlap) as you like\n",
    "overlap_df_sorted = overlap_df.sort_values(\"union_count\", ascending=False)\n",
    "\n",
    "# For a quick view: top 20 methods by total detections, with overlap stats\n",
    "overlap_df_sorted.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbaf8e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "      <th>ml_methods_regex</th>\n",
       "      <th>method_count</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "      <th>method_count_scispacy</th>\n",
       "      <th>regex_set</th>\n",
       "      <th>scispacy_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13735</th>\n",
       "      <td>ml_process_control</td>\n",
       "      <td>2-s2.0-85020415893</td>\n",
       "      <td>10.1117/12.2258039</td>\n",
       "      <td>Computational overlay metrology with adaptive ...</td>\n",
       "      <td>© 2017 SPIE.With photolithography as the funda...</td>\n",
       "      <td>With photolithography as the fundamental patte...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[Gradient Boosting]</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Gradient Boosting}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 query_id                 eid                 doi  \\\n",
       "13735  ml_process_control  2-s2.0-85020415893  10.1117/12.2258039   \n",
       "\n",
       "                                                   title  \\\n",
       "13735  Computational overlay metrology with adaptive ...   \n",
       "\n",
       "                                                abstract  \\\n",
       "13735  © 2017 SPIE.With photolithography as the funda...   \n",
       "\n",
       "                                               clean_abs ml_methods_regex  \\\n",
       "13735  With photolithography as the fundamental patte...               []   \n",
       "\n",
       "       method_count  ml_methods_scispacy  method_count_scispacy regex_set  \\\n",
       "13735             0  [Gradient Boosting]                      1        {}   \n",
       "\n",
       "              scispacy_set  \n",
       "13735  {Gradient Boosting}  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract rows where SciSpaCy found at least one method\n",
    "# and regex found none\n",
    "scispacy_only_df = df[\n",
    "    (df[\"scispacy_set\"].apply(len) > 0) &\n",
    "    (df[\"regex_set\"].apply(len) == 0)\n",
    "]\n",
    "\n",
    "scispacy_only_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b157942d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "      <th>ml_methods_regex</th>\n",
       "      <th>method_count</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "      <th>method_count_scispacy</th>\n",
       "      <th>regex_set</th>\n",
       "      <th>scispacy_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>ml_recycling_manufacturing</td>\n",
       "      <td>2-s2.0-85166934684</td>\n",
       "      <td>10.1080/15376494.2023.2238220</td>\n",
       "      <td>Machine learning and RSM-CCD analysis of green...</td>\n",
       "      <td>© 2023 Taylor &amp; Francis Group, LLC.This study ...</td>\n",
       "      <td>This study aims to serve as a performance indi...</td>\n",
       "      <td>[Neural Network]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{Neural Network}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>ml_remanufacturing</td>\n",
       "      <td>2-s2.0-85185884385</td>\n",
       "      <td>10.1115/1.4064257</td>\n",
       "      <td>Multiscale Feature Fusion Convolutional Neural...</td>\n",
       "      <td>© 2024 by ASME.The detection of surface damage...</td>\n",
       "      <td>The detection of surface damage is an importan...</td>\n",
       "      <td>[Convolutional Neural Network]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{Convolutional Neural Network}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>ml_remanufacturing</td>\n",
       "      <td>2-s2.0-85127515751</td>\n",
       "      <td>10.1016/j.procir.2022.02.168</td>\n",
       "      <td>MotorFactory: A Blender Add-on for Large Datas...</td>\n",
       "      <td>© 2022 Elsevier B.V.. All rights reserved.To e...</td>\n",
       "      <td>V.. All rights reserved.To enable automatic di...</td>\n",
       "      <td>[Reinforcement Learning]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{Reinforcement Learning}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>ml_plm</td>\n",
       "      <td>2-s2.0-85209659742</td>\n",
       "      <td>10.1007/s11277-024-11659-2</td>\n",
       "      <td>Automated Sleep Disorder Diagnosis Utilising E...</td>\n",
       "      <td>© The Author(s), under exclusive licence to Sp...</td>\n",
       "      <td>Automated sleep disorders diagnosis is difficu...</td>\n",
       "      <td>[LSTM]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{LSTM}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>ml_plm</td>\n",
       "      <td>2-s2.0-105014826125</td>\n",
       "      <td>10.1016/j.jss.2025.112604</td>\n",
       "      <td>Syntactic multilingual probing of pre-trained ...</td>\n",
       "      <td>© 2025 The Author(s)Pre-trained language model...</td>\n",
       "      <td>However, due to their deep neural network-base...</td>\n",
       "      <td>[Neural Network, Deep Neural Network]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>{Deep Neural Network, Neural Network}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       query_id                  eid  \\\n",
       "126  ml_recycling_manufacturing   2-s2.0-85166934684   \n",
       "156          ml_remanufacturing   2-s2.0-85185884385   \n",
       "161          ml_remanufacturing   2-s2.0-85127515751   \n",
       "372                      ml_plm   2-s2.0-85209659742   \n",
       "457                      ml_plm  2-s2.0-105014826125   \n",
       "\n",
       "                               doi  \\\n",
       "126  10.1080/15376494.2023.2238220   \n",
       "156              10.1115/1.4064257   \n",
       "161   10.1016/j.procir.2022.02.168   \n",
       "372     10.1007/s11277-024-11659-2   \n",
       "457      10.1016/j.jss.2025.112604   \n",
       "\n",
       "                                                 title  \\\n",
       "126  Machine learning and RSM-CCD analysis of green...   \n",
       "156  Multiscale Feature Fusion Convolutional Neural...   \n",
       "161  MotorFactory: A Blender Add-on for Large Datas...   \n",
       "372  Automated Sleep Disorder Diagnosis Utilising E...   \n",
       "457  Syntactic multilingual probing of pre-trained ...   \n",
       "\n",
       "                                              abstract  \\\n",
       "126  © 2023 Taylor & Francis Group, LLC.This study ...   \n",
       "156  © 2024 by ASME.The detection of surface damage...   \n",
       "161  © 2022 Elsevier B.V.. All rights reserved.To e...   \n",
       "372  © The Author(s), under exclusive licence to Sp...   \n",
       "457  © 2025 The Author(s)Pre-trained language model...   \n",
       "\n",
       "                                             clean_abs  \\\n",
       "126  This study aims to serve as a performance indi...   \n",
       "156  The detection of surface damage is an importan...   \n",
       "161  V.. All rights reserved.To enable automatic di...   \n",
       "372  Automated sleep disorders diagnosis is difficu...   \n",
       "457  However, due to their deep neural network-base...   \n",
       "\n",
       "                          ml_methods_regex  method_count ml_methods_scispacy  \\\n",
       "126                       [Neural Network]             1                  []   \n",
       "156         [Convolutional Neural Network]             1                  []   \n",
       "161               [Reinforcement Learning]             1                  []   \n",
       "372                                 [LSTM]             1                  []   \n",
       "457  [Neural Network, Deep Neural Network]             2                  []   \n",
       "\n",
       "     method_count_scispacy                              regex_set scispacy_set  \n",
       "126                      0                       {Neural Network}           {}  \n",
       "156                      0         {Convolutional Neural Network}           {}  \n",
       "161                      0               {Reinforcement Learning}           {}  \n",
       "372                      0                                 {LSTM}           {}  \n",
       "457                      0  {Deep Neural Network, Neural Network}           {}  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract rows where Regex found at least one method\n",
    "# and SciSpacy found none\n",
    "scispacy_only_df = df[\n",
    "    (df[\"regex_set\"].apply(len) > 0) &\n",
    "    (df[\"scispacy_set\"].apply(len) == 0)\n",
    "]\n",
    "\n",
    "scispacy_only_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e33f5",
   "metadata": {},
   "source": [
    "## Extract ML-Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01038781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define common \"method head\" words and extract ML-related candidate phrases from parsed abstracts\n",
    "# METHOD_HEADS = {\n",
    "#     \"network\", \"networks\",\n",
    "#     \"model\", \"models\",\n",
    "#     \"algorithm\", \"algorithms\",\n",
    "#     \"classifier\", \"classifiers\",\n",
    "#     \"regression\",\n",
    "#     \"forest\", \"forests\",\n",
    "#     \"clustering\", \"clusterer\", \"clusterers\",\n",
    "#     \"encoder\", \"encoders\",\n",
    "#     \"autoencoder\", \"autoencoders\",\n",
    "#     \"transformer\", \"transformers\",\n",
    "#     \"estimators\", \"estimator\",\n",
    "#     \"approach\", \"approaches\",\n",
    "#     \"architecture\", \"architectures\",\n",
    "# }\n",
    "\n",
    "# def extract_candidate_phrases_from_doc(doc):\n",
    "#     \"\"\"Extract candidate ML-method phrases from a spaCy Doc.\"\"\"\n",
    "#     candidates = []\n",
    "\n",
    "#     # Noun chunks that end with a \"method head\" word\n",
    "#     for chunk in doc.noun_chunks:\n",
    "#         tokens = [t for t in chunk if not t.is_punct]\n",
    "#         if not tokens:\n",
    "#             continue\n",
    "\n",
    "#         head = tokens[-1].lemma_.lower()\n",
    "#         if head in METHOD_HEADS:\n",
    "#             if 1 <= len(tokens) <= 7:\n",
    "#                 phrase = chunk.text.strip()\n",
    "#                 candidates.append(phrase)\n",
    "\n",
    "#     # All-caps acronyms (e.g., SVM, CNN, LSTM)\n",
    "#     for token in doc:\n",
    "#         if (\n",
    "#             token.is_alpha\n",
    "#             and token.text.isupper()\n",
    "#             and 2 <= len(token.text) <= 6\n",
    "#         ):\n",
    "#             candidates.append(token.text)\n",
    "\n",
    "#     # Remove duplicates, preserve order\n",
    "#     return list(dict.fromkeys(candidates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "882b1926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract ML-related candidate phrases from all abstracts efficiently using spaCy's nlp.pipe\n",
    "# texts = df[\"clean_abs\"].fillna(\"\").tolist()\n",
    "\n",
    "# candidate_counter = collections.Counter()\n",
    "\n",
    "# # Batch processing with multiple processes for faster NLP execution\n",
    "# for doc in tqdm(\n",
    "#     nlp.pipe(texts, batch_size=64, n_process=8),\n",
    "#     total=len(texts)\n",
    "# ):\n",
    "#     for cand in extract_candidate_phrases_from_doc(doc):\n",
    "#         candidate_counter[cand] += 1\n",
    "\n",
    "# print(f\"Extracted {len(candidate_counter)} unique candidate phrases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57879afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show the top candidate phrases by frequency\n",
    "# for phrase, count in candidate_counter.most_common(100):\n",
    "#     print(f\"{count:4d}  {phrase}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59191c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-catalogue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
