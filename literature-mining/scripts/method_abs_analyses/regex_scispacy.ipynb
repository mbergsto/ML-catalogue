{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbe61b2",
   "metadata": {},
   "source": [
    "- Apply rule-based extraction to identify machine learning methods in abstracts\n",
    "- Test two complementary approaches:\n",
    "  - **Regex-based matching** for known ML terms\n",
    "  - **SciSpaCy + EntityRuler** for robust phrase detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5921f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "from typing import List\n",
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50837a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All directories verified/created.\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "\n",
    "data_path = Path(\"../../data/short-raw-refs-abs\")\n",
    "processed_abstracts_path = Path(\"../../data/processed/abstracts\")\n",
    "save_path = processed_abstracts_path / \"regex_scispacy\"\n",
    "ml_methods_path = Path(\"../../ml_methods/ml_methods_dict.json\")\n",
    "\n",
    "\n",
    "# Ensure directories exist\n",
    "for p in [data_path, processed_abstracts_path, save_path]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"All directories verified/created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a276afda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 52290 abstracts from 24 queries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105018574505</td>\n",
       "      <td>10.1016/j.measurement.2025.119261</td>\n",
       "      <td>Distillation anomaly and fault detection based...</td>\n",
       "      <td>© 2025 The Author(s)The detection of anomalies...</td>\n",
       "      <td>Indeed, highly efficient systems do not always...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105019192533</td>\n",
       "      <td>10.1007/978-3-032-06118-8_30</td>\n",
       "      <td>From Lab to Factory: Pitfalls and Guidelines f...</td>\n",
       "      <td>© The Author(s), under exclusive license to Sp...</td>\n",
       "      <td>The detection and localization of quality-rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105016669957</td>\n",
       "      <td>10.1007/978-3-032-04200-2_5</td>\n",
       "      <td>Intelligent Defect Detection for Manufacturing...</td>\n",
       "      <td>© The Author(s), under exclusive license to Sp...</td>\n",
       "      <td>In modern Industry, I4.0, artificial intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-85218693791</td>\n",
       "      <td>10.1038/s41598-025-90810-w</td>\n",
       "      <td>Hybrid machine learning framework for predicti...</td>\n",
       "      <td>© The Author(s) 2025.The critical necessity fo...</td>\n",
       "      <td>The critical necessity for sophisticated predi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105018301117</td>\n",
       "      <td>10.1016/j.comnet.2025.111753</td>\n",
       "      <td>BGP anomaly detection using the raw internet t...</td>\n",
       "      <td>© 2025 The AuthorsThe Border Gateway Protocol ...</td>\n",
       "      <td>Hence, detecting any anomaly concerning BGP an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          query_id                  eid  \\\n",
       "0  ml_anomaly_detection_production  2-s2.0-105018574505   \n",
       "1  ml_anomaly_detection_production  2-s2.0-105019192533   \n",
       "2  ml_anomaly_detection_production  2-s2.0-105016669957   \n",
       "3  ml_anomaly_detection_production   2-s2.0-85218693791   \n",
       "4  ml_anomaly_detection_production  2-s2.0-105018301117   \n",
       "\n",
       "                                 doi  \\\n",
       "0  10.1016/j.measurement.2025.119261   \n",
       "1       10.1007/978-3-032-06118-8_30   \n",
       "2        10.1007/978-3-032-04200-2_5   \n",
       "3         10.1038/s41598-025-90810-w   \n",
       "4       10.1016/j.comnet.2025.111753   \n",
       "\n",
       "                                               title  \\\n",
       "0  Distillation anomaly and fault detection based...   \n",
       "1  From Lab to Factory: Pitfalls and Guidelines f...   \n",
       "2  Intelligent Defect Detection for Manufacturing...   \n",
       "3  Hybrid machine learning framework for predicti...   \n",
       "4  BGP anomaly detection using the raw internet t...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  © 2025 The Author(s)The detection of anomalies...   \n",
       "1  © The Author(s), under exclusive license to Sp...   \n",
       "2  © The Author(s), under exclusive license to Sp...   \n",
       "3  © The Author(s) 2025.The critical necessity fo...   \n",
       "4  © 2025 The AuthorsThe Border Gateway Protocol ...   \n",
       "\n",
       "                                           clean_abs  \n",
       "0  Indeed, highly efficient systems do not always...  \n",
       "1  The detection and localization of quality-rela...  \n",
       "2  In modern Industry, I4.0, artificial intellige...  \n",
       "3  The critical necessity for sophisticated predi...  \n",
       "4  Hence, detecting any anomaly concerning BGP an...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load abstracts dataset\n",
    "\n",
    "abstracts_path = processed_abstracts_path / \"abstracts.csv\"\n",
    "df = pd.read_csv(abstracts_path)\n",
    "\n",
    "print(f\"Loaded {len(df)} abstracts from {df['query_id'].nunique()} queries.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f60535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 52290\n",
      "After removing duplicates: 33130\n",
      "Remaining duplicate DOIs: 0\n"
     ]
    }
   ],
   "source": [
    "# Count how many rows each query_id has\n",
    "query_counts = df[\"query_id\"].value_counts().to_dict()\n",
    "\n",
    "# Create a copy and map the counts to each row\n",
    "df = df.copy()\n",
    "df[\"query_size\"] = df[\"query_id\"].map(query_counts)\n",
    "\n",
    "# Sort so that query groups with fewer rows are prioritized\n",
    "df_sorted = df.sort_values(by=\"query_size\", ascending=True)\n",
    "\n",
    "# Remove duplicate DOIs, keeping the one in the smallest query group\n",
    "df_dedup = df_sorted.drop_duplicates(subset=\"doi\", keep=\"first\").drop(columns=[\"query_size\"])\n",
    "\n",
    "# Print results\n",
    "print(\"Original dataset size:\", len(df))\n",
    "print(\"After removing duplicates:\", len(df_dedup))\n",
    "print(\"Remaining duplicate DOIs:\", df_dedup[\"doi\"].duplicated().sum())\n",
    "\n",
    "df = df_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ec40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ml_methods_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    ml_methods_dict = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec15316",
   "metadata": {},
   "source": [
    "## Regex matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f33c5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33130/33130 [00:48<00:00, 688.75it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_methods(text, term_dict):\n",
    "    # Return empty list if input is not a string\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    found = []\n",
    "    \n",
    "    for method, phrases in term_dict.items():\n",
    "        for phrase in phrases:\n",
    "            # Escape special characters and enforce word boundaries\n",
    "            pattern = r\"\\b\" + re.escape(phrase.lower()) + r\"\\b\"\n",
    "            \n",
    "            # Perform case-insensitive boundary-safe regex search\n",
    "            if re.search(pattern, text.lower()):\n",
    "                found.append(method)\n",
    "                break  # Stop checking more variants for this method\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    return list(dict.fromkeys(found))\n",
    "\n",
    "# Apply extraction with pandas progress bar\n",
    "tqdm.pandas()\n",
    "df[\"ml_methods_regex\"] = df[\"clean_abs\"].fillna(\"\").progress_apply(\n",
    "    lambda x: extract_methods(x, ml_methods_dict)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6cde623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_count\n",
      "0     18932\n",
      "1      7046\n",
      "2      3763\n",
      "3      1799\n",
      "4       889\n",
      "5       400\n",
      "6       178\n",
      "7        78\n",
      "8        33\n",
      "9         6\n",
      "10        3\n",
      "11        3\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ml_methods_regex\n",
       "Neural Network                  6747\n",
       "Random Forest                   3103\n",
       "Support Vector Machine          2176\n",
       "Decision Tree                   1652\n",
       "Convolutional Neural Network    1365\n",
       "Gradient Boosting               1185\n",
       "LSTM                            1107\n",
       "XGBoost                         1091\n",
       "Linear Regression                906\n",
       "Bayesian Method                  893\n",
       "Genetic Algorithm                843\n",
       "K-Nearest Neighbors              813\n",
       "Support Vector Regression        716\n",
       "Particle Swarm Optimization      597\n",
       "Principal Component Analysis     587\n",
       "Deep Neural Network              483\n",
       "Logistic Regression              473\n",
       "SHAP                             460\n",
       "Multi-Layer Perceptron           420\n",
       "Gaussian Process Regression      396\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many ML methods were detected per abstract using the regex-based approach\n",
    "df[\"method_count\"] = df[\"ml_methods_regex\"].str.len()\n",
    "print(df[\"method_count\"].value_counts().sort_index())\n",
    "\n",
    "# Show the top 20 most frequently detected ML methods across all abstracts\n",
    "df.explode(\"ml_methods_regex\")[\"ml_methods_regex\"].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0f58689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed abstracts with ML methods to: ../../data/processed/abstracts/regex_scispacy/abstracts_with_ml_methods_regex.csv\n"
     ]
    }
   ],
   "source": [
    "# Save updated dataframe with extracted ML methods\n",
    "output_path = save_path / \"abstracts_with_ml_methods_regex.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved processed abstracts with ML methods to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91fc441",
   "metadata": {},
   "source": [
    "## Scispacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8fbe9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer', 'parser', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# Load the large SciSpaCy scientific language model and list all enabled NLP pipeline components\n",
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "691d91b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 64 ML_METHOD patterns to EntityRuler.\n"
     ]
    }
   ],
   "source": [
    "# Add an EntityRuler to the NLP pipeline and register patterns for ML method detection\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "patterns = []\n",
    "\n",
    "# Create token-based matching patterns for each ML method phrase\n",
    "for label, phrases in ml_methods_dict.items():\n",
    "    for phrase in phrases:\n",
    "        # Create a case-insensitive match pattern using LOWER tokens\n",
    "        pattern = [{\"LOWER\": token.lower()} for token in phrase.split()]\n",
    "        patterns.append({\n",
    "            \"label\": \"ML_METHOD\",  # Custom entity label for ML methods\n",
    "            \"pattern\": pattern,\n",
    "            \"id\": label  # Canonical method name stored in ent_id_\n",
    "        })\n",
    "\n",
    "# Register all patterns in the EntityRuler\n",
    "ruler.add_patterns(patterns)\n",
    "print(f\"Added {len(patterns)} ML_METHOD patterns to EntityRuler.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd437b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ML method entities from a single abstract using the SciSpaCy EntityRuler\n",
    "def extract_ml_methods_scispacy(text: str) -> List[str]:\n",
    "    # Return empty list if input is not valid text\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    methods = []\n",
    "    \n",
    "    # Collect all detected ML_METHOD entities with their canonical IDs\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ML_METHOD\":\n",
    "            canonical = ent.ent_id_ if ent.ent_id_ else ent.text\n",
    "            methods.append(canonical)\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_methods = list(dict.fromkeys(methods))\n",
    "    return unique_methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6312ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33130/33130 [02:01<00:00, 273.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply the SciSpaCy EntityRuler to extract ML methods for all abstracts efficiently using nlp.pipe\n",
    "texts = df[\"clean_abs\"].fillna(\"\").tolist()\n",
    "\n",
    "ml_methods_all = []\n",
    "\n",
    "# Process abstracts in batches\n",
    "for doc in tqdm(nlp.pipe(texts, batch_size=32, n_process=8), total=len(texts)):\n",
    "    methods = []\n",
    "    \n",
    "    # Collect ML_METHOD entities found in each processed document\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ML_METHOD\":\n",
    "            canonical = ent.ent_id_ if ent.ent_id_ else ent.text\n",
    "            methods.append(canonical)\n",
    "            \n",
    "    # Store unique detected methods for this abstract\n",
    "    ml_methods_all.append(list(dict.fromkeys(methods)))\n",
    "\n",
    "# Save results\n",
    "df[\"ml_methods_scispacy\"] = ml_methods_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdab767e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed abstracts with ML methods to: ../../data/processed/abstracts/regex_scispacy/abstracts_with_ml_methods.csv\n"
     ]
    }
   ],
   "source": [
    "# Save updated dataframe with extracted ML methods\n",
    "output_path = save_path / \"abstracts_with_ml_methods.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved processed abstracts with ML methods to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250de0ad",
   "metadata": {},
   "source": [
    "### SciSpacy: Analyze Abstracts with ML methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7e0ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(save_path / \"abstracts_with_ml_methods.csv\")\n",
    "\n",
    "# Convert string lists to lists\n",
    "df[\"ml_methods_scispacy\"] = df[\"ml_methods_scispacy\"].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1d68766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blockchain-enabled decision system for reliabl...</td>\n",
       "      <td>10.1016/B978-0-443-33740-6.00012-8</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Systematic review of data modelling methods fo...</td>\n",
       "      <td>10.1080/19397038.2025.2563271</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clustering Locations of Collection Centers in ...</td>\n",
       "      <td>10.1109/TEMSCON-ASPAC62480.2024.11025082</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artificial Intelligence: Basics, Impact, and H...</td>\n",
       "      <td>10.1188/23.CJON.595-601</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intersections between materials science and ma...</td>\n",
       "      <td>10.1039/d3va00106g</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Measuring Carbon in Cities and Their Buildings...</td>\n",
       "      <td>10.3390/asi6050076</td>\n",
       "      <td>[Linear Regression]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Predictive modeling for the quantity of recycl...</td>\n",
       "      <td>10.1016/j.resconrec.2023.107073</td>\n",
       "      <td>[Support Vector Regression, Gradient Boosting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Organizational Maturity and Its Influence on P...</td>\n",
       "      <td>10.1007/978-3-031-94484-0_27</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Toward Sustainable Manufacturing: A Review on ...</td>\n",
       "      <td>10.1109/ACCESS.2025.3576441</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Integrating Digital Twins and Robotics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Blockchain-enabled decision system for reliabl...   \n",
       "1  Systematic review of data modelling methods fo...   \n",
       "2  Clustering Locations of Collection Centers in ...   \n",
       "3  Artificial Intelligence: Basics, Impact, and H...   \n",
       "4  Intersections between materials science and ma...   \n",
       "5  Measuring Carbon in Cities and Their Buildings...   \n",
       "6  Predictive modeling for the quantity of recycl...   \n",
       "7  Organizational Maturity and Its Influence on P...   \n",
       "8  Toward Sustainable Manufacturing: A Review on ...   \n",
       "9             Integrating Digital Twins and Robotics   \n",
       "\n",
       "                                        doi  \\\n",
       "0        10.1016/B978-0-443-33740-6.00012-8   \n",
       "1             10.1080/19397038.2025.2563271   \n",
       "2  10.1109/TEMSCON-ASPAC62480.2024.11025082   \n",
       "3                   10.1188/23.CJON.595-601   \n",
       "4                        10.1039/d3va00106g   \n",
       "5                        10.3390/asi6050076   \n",
       "6           10.1016/j.resconrec.2023.107073   \n",
       "7              10.1007/978-3-031-94484-0_27   \n",
       "8               10.1109/ACCESS.2025.3576441   \n",
       "9                                       NaN   \n",
       "\n",
       "                                 ml_methods_scispacy  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  \n",
       "5                                [Linear Regression]  \n",
       "6  [Support Vector Regression, Gradient Boosting,...  \n",
       "7                                                 []  \n",
       "8                                                 []  \n",
       "9                                                 []  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 papers with their extracted ML methods from SciSpaCy\n",
    "df[[\"title\", \"doi\", \"ml_methods_scispacy\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fc65f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method_count_scispacy\n",
       "0     19301\n",
       "1      7646\n",
       "2      3195\n",
       "3      1593\n",
       "4       774\n",
       "5       364\n",
       "6       152\n",
       "7        64\n",
       "8        29\n",
       "9         6\n",
       "10        5\n",
       "11        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many ML methods SciSpaCy detected per abstract and summarize the distribution\n",
    "df[\"method_count_scispacy\"] = df[\"ml_methods_scispacy\"].str.len()\n",
    "df[\"method_count_scispacy\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a04ae7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ml_methods_scispacy\n",
       "Neural Network                  5580\n",
       "Random Forest                   3060\n",
       "Support Vector Machine          2127\n",
       "Decision Tree                   1614\n",
       "Convolutional Neural Network    1195\n",
       "Gradient Boosting               1173\n",
       "XGBoost                         1053\n",
       "LSTM                             964\n",
       "Bayesian Method                  882\n",
       "Linear Regression                862\n",
       "K-Nearest Neighbors              798\n",
       "Genetic Algorithm                748\n",
       "Support Vector Regression        693\n",
       "Principal Component Analysis     562\n",
       "Particle Swarm Optimization      542\n",
       "Logistic Regression              469\n",
       "Deep Neural Network              458\n",
       "SHAP                             445\n",
       "Multi-Layer Perceptron           391\n",
       "Gaussian Process Regression      385\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the top 20 most frequently detected ML methods using the SciSpaCy extraction\n",
    "df.explode(\"ml_methods_scispacy\")[\"ml_methods_scispacy\"].value_counts().head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc4c9f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16110</th>\n",
       "      <td>Machine learning-driven process of alumina cer...</td>\n",
       "      <td>10.1088/1402-4896/aca3da</td>\n",
       "      <td>[Neural Network]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21455</th>\n",
       "      <td>Reservoir production optimization based on sur...</td>\n",
       "      <td>10.1016/j.petrol.2021.108879</td>\n",
       "      <td>[Gradient Boosting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17312</th>\n",
       "      <td>POSSIBILITIES OF APPLYING MACHINE LEARNING TEC...</td>\n",
       "      <td>10.1115/GT2024-122477</td>\n",
       "      <td>[Neural Network, Deep Neural Network]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21542</th>\n",
       "      <td>An Optimized Convolution Neural Network Archit...</td>\n",
       "      <td>10.32604/cmc.2022.022215</td>\n",
       "      <td>[Neural Network, Convolutional Neural Network,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22222</th>\n",
       "      <td>Asynchronous Decentralized Bayesian Optimizati...</td>\n",
       "      <td>10.1109/e-Science58273.2023.10254839</td>\n",
       "      <td>[Bayesian Method, Neural Network]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "16110  Machine learning-driven process of alumina cer...   \n",
       "21455  Reservoir production optimization based on sur...   \n",
       "17312  POSSIBILITIES OF APPLYING MACHINE LEARNING TEC...   \n",
       "21542  An Optimized Convolution Neural Network Archit...   \n",
       "22222  Asynchronous Decentralized Bayesian Optimizati...   \n",
       "\n",
       "                                        doi  \\\n",
       "16110              10.1088/1402-4896/aca3da   \n",
       "21455          10.1016/j.petrol.2021.108879   \n",
       "17312                 10.1115/GT2024-122477   \n",
       "21542              10.32604/cmc.2022.022215   \n",
       "22222  10.1109/e-Science58273.2023.10254839   \n",
       "\n",
       "                                     ml_methods_scispacy  \n",
       "16110                                   [Neural Network]  \n",
       "21455                                [Gradient Boosting]  \n",
       "17312              [Neural Network, Deep Neural Network]  \n",
       "21542  [Neural Network, Convolutional Neural Network,...  \n",
       "22222                  [Bayesian Method, Neural Network]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly inspect 5 abstracts where SciSpaCy successfully detected ML methods\n",
    "df[df[\"method_count_scispacy\"] > 0][[\"title\", \"doi\", \"ml_methods_scispacy\"]].sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde14409",
   "metadata": {},
   "source": [
    "## Compare Regex and SciSpacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d0459d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>regex_count</th>\n",
       "      <th>scispacy_count</th>\n",
       "      <th>both_count</th>\n",
       "      <th>regex_only</th>\n",
       "      <th>scispacy_only</th>\n",
       "      <th>union_count</th>\n",
       "      <th>jaccard_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0</td>\n",
       "      <td>5580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5580</td>\n",
       "      <td>5580</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0</td>\n",
       "      <td>3060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3060</td>\n",
       "      <td>3060</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0</td>\n",
       "      <td>2127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2127</td>\n",
       "      <td>2127</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0</td>\n",
       "      <td>1614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1614</td>\n",
       "      <td>1614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Convolutional Neural Network</td>\n",
       "      <td>0</td>\n",
       "      <td>1195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0</td>\n",
       "      <td>1173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1173</td>\n",
       "      <td>1173</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1053</td>\n",
       "      <td>1053</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0</td>\n",
       "      <td>964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>964</td>\n",
       "      <td>964</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bayesian Method</td>\n",
       "      <td>0</td>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>882</td>\n",
       "      <td>882</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0</td>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0</td>\n",
       "      <td>798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>798</td>\n",
       "      <td>798</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Genetic Algorithm</td>\n",
       "      <td>0</td>\n",
       "      <td>748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>748</td>\n",
       "      <td>748</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Support Vector Regression</td>\n",
       "      <td>0</td>\n",
       "      <td>693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Principal Component Analysis</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "      <td>562</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Particle Swarm Optimization</td>\n",
       "      <td>0</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>542</td>\n",
       "      <td>542</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "      <td>469</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deep Neural Network</td>\n",
       "      <td>0</td>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>458</td>\n",
       "      <td>458</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SHAP</td>\n",
       "      <td>0</td>\n",
       "      <td>445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>445</td>\n",
       "      <td>445</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Multi-Layer Perceptron</td>\n",
       "      <td>0</td>\n",
       "      <td>391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gaussian Process Regression</td>\n",
       "      <td>0</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>385</td>\n",
       "      <td>385</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Recurrent Neural Network</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explainable AI</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gated Recurrent Unit</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARIMA</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Local Outlier Factor</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Squared Prediction Error</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hotelling T2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          method  regex_count  scispacy_count  both_count  \\\n",
       "19                Neural Network            0            5580           0   \n",
       "22                 Random Forest            0            3060           0   \n",
       "26        Support Vector Machine            0            2127           0   \n",
       "3                  Decision Tree            0            1614           0   \n",
       "2   Convolutional Neural Network            0            1195           0   \n",
       "9              Gradient Boosting            0            1173           0   \n",
       "28                       XGBoost            0            1053           0   \n",
       "14                          LSTM            0             964           0   \n",
       "1                Bayesian Method            0             882           0   \n",
       "15             Linear Regression            0             862           0   \n",
       "13           K-Nearest Neighbors            0             798           0   \n",
       "8              Genetic Algorithm            0             748           0   \n",
       "27     Support Vector Regression            0             693           0   \n",
       "21  Principal Component Analysis            0             562           0   \n",
       "20   Particle Swarm Optimization            0             542           0   \n",
       "17           Logistic Regression            0             469           0   \n",
       "4            Deep Neural Network            0             458           0   \n",
       "24                          SHAP            0             445           0   \n",
       "18        Multi-Layer Perceptron            0             391           0   \n",
       "7    Gaussian Process Regression            0             385           0   \n",
       "12                       K-Means            0             333           0   \n",
       "23      Recurrent Neural Network            0             299           0   \n",
       "5                 Explainable AI            0             294           0   \n",
       "6           Gated Recurrent Unit            0             197           0   \n",
       "0                          ARIMA            0             147           0   \n",
       "11              Isolation Forest            0             103           0   \n",
       "16          Local Outlier Factor            0              42           0   \n",
       "25      Squared Prediction Error            0              16           0   \n",
       "10                  Hotelling T2            0               6           0   \n",
       "\n",
       "    regex_only  scispacy_only  union_count  jaccard_overlap  \n",
       "19           0           5580         5580              0.0  \n",
       "22           0           3060         3060              0.0  \n",
       "26           0           2127         2127              0.0  \n",
       "3            0           1614         1614              0.0  \n",
       "2            0           1195         1195              0.0  \n",
       "9            0           1173         1173              0.0  \n",
       "28           0           1053         1053              0.0  \n",
       "14           0            964          964              0.0  \n",
       "1            0            882          882              0.0  \n",
       "15           0            862          862              0.0  \n",
       "13           0            798          798              0.0  \n",
       "8            0            748          748              0.0  \n",
       "27           0            693          693              0.0  \n",
       "21           0            562          562              0.0  \n",
       "20           0            542          542              0.0  \n",
       "17           0            469          469              0.0  \n",
       "4            0            458          458              0.0  \n",
       "24           0            445          445              0.0  \n",
       "18           0            391          391              0.0  \n",
       "7            0            385          385              0.0  \n",
       "12           0            333          333              0.0  \n",
       "23           0            299          299              0.0  \n",
       "5            0            294          294              0.0  \n",
       "6            0            197          197              0.0  \n",
       "0            0            147          147              0.0  \n",
       "11           0            103          103              0.0  \n",
       "16           0             42           42              0.0  \n",
       "25           0             16           16              0.0  \n",
       "10           0              6            6              0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure we are working with list -> set for easier membership checks\n",
    "df[\"regex_set\"] = df[\"ml_methods_regex\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "df[\"scispacy_set\"] = df[\"ml_methods_scispacy\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "\n",
    "# Collect the universe of methods seen by either approach\n",
    "all_methods = sorted(\n",
    "    set().union(*df[\"regex_set\"]).union(*df[\"scispacy_set\"])\n",
    ")\n",
    "\n",
    "rows = []\n",
    "\n",
    "# For each method, compute overlap stats between regex and SciSpaCy\n",
    "for method in all_methods:\n",
    "    regex_mask = df[\"regex_set\"].apply(lambda s: method in s)\n",
    "    scis_mask = df[\"scispacy_set\"].apply(lambda s: method in s)\n",
    "    \n",
    "    regex_count = regex_mask.sum()\n",
    "    scispacy_count = scis_mask.sum()\n",
    "    both_count = (regex_mask & scis_mask).sum()\n",
    "    regex_only = (regex_mask & ~scis_mask).sum()\n",
    "    scispacy_only = (~regex_mask & scis_mask).sum()\n",
    "    union_count = (regex_mask | scis_mask).sum()\n",
    "    \n",
    "    jaccard = both_count / union_count if union_count > 0 else 0.0\n",
    "    \n",
    "    rows.append({\n",
    "        \"method\": method,\n",
    "        \"regex_count\": regex_count,\n",
    "        \"scispacy_count\": scispacy_count,\n",
    "        \"both_count\": both_count,\n",
    "        \"regex_only\": regex_only,\n",
    "        \"scispacy_only\": scispacy_only,\n",
    "        \"union_count\": union_count,\n",
    "        \"jaccard_overlap\": jaccard,\n",
    "    })\n",
    "\n",
    "overlap_df = pd.DataFrame(rows)\n",
    "\n",
    "# Sort by popularity (or by overlap) as you like\n",
    "overlap_df_sorted = overlap_df.sort_values(\"union_count\", ascending=False)\n",
    "\n",
    "# For a quick view: top 20 methods by total detections, with overlap stats\n",
    "overlap_df_sorted.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbaf8e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "      <th>ml_methods_regex</th>\n",
       "      <th>method_count</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "      <th>method_count_scispacy</th>\n",
       "      <th>regex_set</th>\n",
       "      <th>scispacy_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ml_end_of_life</td>\n",
       "      <td>2-s2.0-85174142475</td>\n",
       "      <td>10.3390/asi6050076</td>\n",
       "      <td>Measuring Carbon in Cities and Their Buildings...</td>\n",
       "      <td>© 2023 by the authors.According to the Europea...</td>\n",
       "      <td>According to the European Green Deal, excessiv...</td>\n",
       "      <td>['Linear Regression']</td>\n",
       "      <td>1</td>\n",
       "      <td>[Linear Regression]</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Linear Regression}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ml_end_of_life</td>\n",
       "      <td>2-s2.0-85161673110</td>\n",
       "      <td>10.1016/j.resconrec.2023.107073</td>\n",
       "      <td>Predictive modeling for the quantity of recycl...</td>\n",
       "      <td>© 2023 The Author(s)The rapid development of m...</td>\n",
       "      <td>However, the Stacking ensemble model is less w...</td>\n",
       "      <td>['Support Vector Regression', 'Linear Regressi...</td>\n",
       "      <td>3</td>\n",
       "      <td>[Support Vector Regression, Gradient Boosting,...</td>\n",
       "      <td>3</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Gradient Boosting, Support Vector Regression,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ml_end_of_life</td>\n",
       "      <td>2-s2.0-85171544836</td>\n",
       "      <td>10.30638/eemj.2023.018</td>\n",
       "      <td>END-OF-LIFE VEHICLES ASSESSMENT OF THE AUTOMOB...</td>\n",
       "      <td>© 2023 Gheorghe Asachi Technical University of...</td>\n",
       "      <td>All rights reserved.Automotive industry is hig...</td>\n",
       "      <td>['Neural Network']</td>\n",
       "      <td>1</td>\n",
       "      <td>[Neural Network]</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Neural Network}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ml_end_of_life</td>\n",
       "      <td>2-s2.0-85179507482</td>\n",
       "      <td>10.1115/DETC2023-114718</td>\n",
       "      <td>PREDICTING THE QUANTITY OF RECYCLED END-OF-LIF...</td>\n",
       "      <td>© 2023 American Society of Mechanical Engineer...</td>\n",
       "      <td>All rights reserved.End-of-life product recycl...</td>\n",
       "      <td>['Support Vector Regression', 'Particle Swarm ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Particle Swarm Optimization, Support Vector R...</td>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Support Vector Regression, Particle Swarm Opt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ml_end_of_life</td>\n",
       "      <td>2-s2.0-85218456652</td>\n",
       "      <td>10.1007/978-3-031-69626-8_78</td>\n",
       "      <td>Machine Learning Integration in LCA: Addressin...</td>\n",
       "      <td>© The Author(s) 2025.Life Cycle Assessment (LC...</td>\n",
       "      <td>Life Cycle Assessment (LCA) is an essential to...</td>\n",
       "      <td>['Random Forest']</td>\n",
       "      <td>1</td>\n",
       "      <td>[Random Forest]</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Random Forest}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          query_id                 eid                              doi  \\\n",
       "5   ml_end_of_life  2-s2.0-85174142475               10.3390/asi6050076   \n",
       "6   ml_end_of_life  2-s2.0-85161673110  10.1016/j.resconrec.2023.107073   \n",
       "11  ml_end_of_life  2-s2.0-85171544836           10.30638/eemj.2023.018   \n",
       "12  ml_end_of_life  2-s2.0-85179507482          10.1115/DETC2023-114718   \n",
       "27  ml_end_of_life  2-s2.0-85218456652     10.1007/978-3-031-69626-8_78   \n",
       "\n",
       "                                                title  \\\n",
       "5   Measuring Carbon in Cities and Their Buildings...   \n",
       "6   Predictive modeling for the quantity of recycl...   \n",
       "11  END-OF-LIFE VEHICLES ASSESSMENT OF THE AUTOMOB...   \n",
       "12  PREDICTING THE QUANTITY OF RECYCLED END-OF-LIF...   \n",
       "27  Machine Learning Integration in LCA: Addressin...   \n",
       "\n",
       "                                             abstract  \\\n",
       "5   © 2023 by the authors.According to the Europea...   \n",
       "6   © 2023 The Author(s)The rapid development of m...   \n",
       "11  © 2023 Gheorghe Asachi Technical University of...   \n",
       "12  © 2023 American Society of Mechanical Engineer...   \n",
       "27  © The Author(s) 2025.Life Cycle Assessment (LC...   \n",
       "\n",
       "                                            clean_abs  \\\n",
       "5   According to the European Green Deal, excessiv...   \n",
       "6   However, the Stacking ensemble model is less w...   \n",
       "11  All rights reserved.Automotive industry is hig...   \n",
       "12  All rights reserved.End-of-life product recycl...   \n",
       "27  Life Cycle Assessment (LCA) is an essential to...   \n",
       "\n",
       "                                     ml_methods_regex  method_count  \\\n",
       "5                               ['Linear Regression']             1   \n",
       "6   ['Support Vector Regression', 'Linear Regressi...             3   \n",
       "11                                 ['Neural Network']             1   \n",
       "12  ['Support Vector Regression', 'Particle Swarm ...             2   \n",
       "27                                  ['Random Forest']             1   \n",
       "\n",
       "                                  ml_methods_scispacy  method_count_scispacy  \\\n",
       "5                                 [Linear Regression]                      1   \n",
       "6   [Support Vector Regression, Gradient Boosting,...                      3   \n",
       "11                                   [Neural Network]                      1   \n",
       "12  [Particle Swarm Optimization, Support Vector R...                      2   \n",
       "27                                    [Random Forest]                      1   \n",
       "\n",
       "   regex_set                                       scispacy_set  \n",
       "5         {}                                {Linear Regression}  \n",
       "6         {}  {Gradient Boosting, Support Vector Regression,...  \n",
       "11        {}                                   {Neural Network}  \n",
       "12        {}  {Support Vector Regression, Particle Swarm Opt...  \n",
       "27        {}                                    {Random Forest}  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract rows where SciSpaCy found at least one method\n",
    "# and regex found none\n",
    "scispacy_only_df = df[\n",
    "    (df[\"scispacy_set\"].apply(len) > 0) &\n",
    "    (df[\"regex_set\"].apply(len) == 0)\n",
    "]\n",
    "\n",
    "scispacy_only_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b157942d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "      <th>ml_methods_regex</th>\n",
       "      <th>method_count</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "      <th>method_count_scispacy</th>\n",
       "      <th>regex_set</th>\n",
       "      <th>scispacy_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [query_id, eid, doi, title, abstract, clean_abs, ml_methods_regex, method_count, ml_methods_scispacy, method_count_scispacy, regex_set, scispacy_set]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract rows where Regex found at least one method\n",
    "# and SciSpacy found none\n",
    "scispacy_only_df = df[\n",
    "    (df[\"regex_set\"].apply(len) > 0) &\n",
    "    (df[\"scispacy_set\"].apply(len) == 0)\n",
    "]\n",
    "\n",
    "scispacy_only_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e33f5",
   "metadata": {},
   "source": [
    "## Extract ML-Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01038781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common \"method head\" words and extract ML-related candidate phrases from parsed abstracts\n",
    "METHOD_HEADS = {\n",
    "    \"network\", \"networks\",\n",
    "    \"model\", \"models\",\n",
    "    \"algorithm\", \"algorithms\",\n",
    "    \"classifier\", \"classifiers\",\n",
    "    \"regression\",\n",
    "    \"forest\", \"forests\",\n",
    "    \"clustering\", \"clusterer\", \"clusterers\",\n",
    "    \"encoder\", \"encoders\",\n",
    "    \"autoencoder\", \"autoencoders\",\n",
    "    \"transformer\", \"transformers\",\n",
    "    \"estimators\", \"estimator\",\n",
    "    \"approach\", \"approaches\",\n",
    "    \"architecture\", \"architectures\",\n",
    "}\n",
    "\n",
    "def extract_candidate_phrases_from_doc(doc):\n",
    "    \"\"\"Extract candidate ML-method phrases from a spaCy Doc.\"\"\"\n",
    "    candidates = []\n",
    "\n",
    "    # Noun chunks that end with a \"method head\" word\n",
    "    for chunk in doc.noun_chunks:\n",
    "        tokens = [t for t in chunk if not t.is_punct]\n",
    "        if not tokens:\n",
    "            continue\n",
    "\n",
    "        head = tokens[-1].lemma_.lower()\n",
    "        if head in METHOD_HEADS:\n",
    "            if 1 <= len(tokens) <= 7:\n",
    "                phrase = chunk.text.strip()\n",
    "                candidates.append(phrase)\n",
    "\n",
    "    # All-caps acronyms (e.g., SVM, CNN, LSTM)\n",
    "    for token in doc:\n",
    "        if (\n",
    "            token.is_alpha\n",
    "            and token.text.isupper()\n",
    "            and 2 <= len(token.text) <= 6\n",
    "        ):\n",
    "            candidates.append(token.text)\n",
    "\n",
    "    # Remove duplicates, preserve order\n",
    "    return list(dict.fromkeys(candidates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "882b1926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33130/33130 [02:03<00:00, 267.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 40432 unique candidate phrases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract ML-related candidate phrases from all abstracts efficiently using spaCy's nlp.pipe\n",
    "texts = df[\"clean_abs\"].fillna(\"\").tolist()\n",
    "\n",
    "candidate_counter = collections.Counter()\n",
    "\n",
    "# Batch processing with multiple processes for faster NLP execution\n",
    "for doc in tqdm(\n",
    "    nlp.pipe(texts, batch_size=64, n_process=8),\n",
    "    total=len(texts)\n",
    "):\n",
    "    for cand in extract_candidate_phrases_from_doc(doc):\n",
    "        candidate_counter[cand] += 1\n",
    "\n",
    "print(f\"Extracted {len(candidate_counter)} unique candidate phrases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57879afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5519  ML\n",
      "3704  AI\n",
      "1268  SVM\n",
      "1243  RMSE\n",
      "1182  the model\n",
      "1139  ANN\n",
      " 967  RF\n",
      " 964  LSTM\n",
      " 955  RUL\n",
      " 892  AM\n",
      " 860  CNN\n",
      " 842  The model\n",
      " 795  This approach\n",
      " 765  MAE\n",
      " 747  machine learning algorithms\n",
      " 547  MDPI\n",
      " 541  machine learning models\n",
      " 532  DL\n",
      " 530  DT\n",
      " 511  Random Forest\n",
      " 497  models\n",
      " 470  KNN\n",
      " 461  MSE\n",
      " 460  SVR\n",
      " 443  SHAP\n",
      " 430  The approach\n",
      " 425  a novel approach\n",
      " 402  an approach\n",
      " 402  a model\n",
      " 389  MLP\n",
      " 374  this approach\n",
      " 368  The proposed approach\n",
      " 356  MAPE\n",
      " 352  PCA\n",
      " 346  our approach\n",
      " 335  the models\n",
      " 334  PSO\n",
      " 322  CC\n",
      " 320  random forest\n",
      " 307  GA\n",
      " 296  the proposed approach\n",
      " 293  Our approach\n",
      " 287  the proposed model\n",
      " 286  The models\n",
      " 285  algorithms\n",
      " 274  The proposed model\n",
      " 268  This model\n",
      " 265  the approach\n",
      " 263  RL\n",
      " 259  These models\n",
      " 255  these models\n",
      " 246  a machine learning model\n",
      " 243  DNN\n",
      " 241  neural networks\n",
      " 233  PV\n",
      " 233  IEEE\n",
      " 231  ML models\n",
      " 225  GPR\n",
      " 220  predictive models\n",
      " 216  NASA\n",
      " 213  LR\n",
      " 213  artificial neural networks\n",
      " 211  CNC\n",
      " 209  CPS\n",
      " 206  PHM\n",
      " 202  ELM\n",
      " 201  IT\n",
      " 199  RNN\n",
      " 198  UK\n",
      " 198  AUC\n",
      " 192  XAI\n",
      " 191  ML algorithms\n",
      " 186  the algorithm\n",
      " 182  LPBF\n",
      " 182  NN\n",
      " 176  CAD\n",
      " 173  MATLAB\n",
      " 167  NLP\n",
      " 167  FDM\n",
      " 166  IC\n",
      " 158  SEM\n",
      " 157  Machine learning algorithms\n",
      " 157  GRU\n",
      " 157  approaches\n",
      " 155  II\n",
      " 153  PLM\n",
      " 152  The algorithm\n",
      " 150  a new approach\n",
      " 149  BP\n",
      " 148  a machine learning approach\n",
      " 146  ARIMA\n",
      " 140  our model\n",
      " 139  RSM\n",
      " 137  Machine learning models\n",
      " 136  this model\n",
      " 135  FL\n",
      " 132  CFD\n",
      " 131  machine learning approaches\n",
      " 131  XGB\n",
      " 130  artificial neural network\n"
     ]
    }
   ],
   "source": [
    "# Show the top candidate phrases by frequency\n",
    "for phrase, count in candidate_counter.most_common(100):\n",
    "    print(f\"{count:4d}  {phrase}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59191c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-catalogue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
