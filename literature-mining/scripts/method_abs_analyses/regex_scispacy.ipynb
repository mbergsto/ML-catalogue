{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbe61b2",
   "metadata": {},
   "source": [
    "- Apply rule-based extraction to identify machine learning methods in abstracts\n",
    "- Test two complementary approaches:\n",
    "  - **Regex-based matching** for known ML terms\n",
    "  - **SciSpaCy + EntityRuler** for robust phrase detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5921f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "from typing import List\n",
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50837a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All directories verified/created.\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "\n",
    "data_path = Path(\"../../data/short-raw-refs-abs\")\n",
    "processed_abstracts_path = Path(\"../../data/processed/abstracts\")\n",
    "save_path = processed_abstracts_path / \"regex_scispacy\"\n",
    "ml_methods_path = Path(\"../../ml_methods/ml_methods_dict.json\")\n",
    "\n",
    "\n",
    "# Ensure directories exist\n",
    "for p in [data_path, processed_abstracts_path, save_path]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"All directories verified/created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a276afda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 52290 abstracts from 24 queries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105018574505</td>\n",
       "      <td>10.1016/j.measurement.2025.119261</td>\n",
       "      <td>Distillation anomaly and fault detection based...</td>\n",
       "      <td>© 2025 The Author(s)The detection of anomalies...</td>\n",
       "      <td>Indeed, highly efficient systems do not always...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105019192533</td>\n",
       "      <td>10.1007/978-3-032-06118-8_30</td>\n",
       "      <td>From Lab to Factory: Pitfalls and Guidelines f...</td>\n",
       "      <td>© The Author(s), under exclusive license to Sp...</td>\n",
       "      <td>The detection and localization of quality-rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105016669957</td>\n",
       "      <td>10.1007/978-3-032-04200-2_5</td>\n",
       "      <td>Intelligent Defect Detection for Manufacturing...</td>\n",
       "      <td>© The Author(s), under exclusive license to Sp...</td>\n",
       "      <td>In modern Industry, I4.0, artificial intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-85218693791</td>\n",
       "      <td>10.1038/s41598-025-90810-w</td>\n",
       "      <td>Hybrid machine learning framework for predicti...</td>\n",
       "      <td>© The Author(s) 2025.The critical necessity fo...</td>\n",
       "      <td>The critical necessity for sophisticated predi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105018301117</td>\n",
       "      <td>10.1016/j.comnet.2025.111753</td>\n",
       "      <td>BGP anomaly detection using the raw internet t...</td>\n",
       "      <td>© 2025 The AuthorsThe Border Gateway Protocol ...</td>\n",
       "      <td>Hence, detecting any anomaly concerning BGP an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          query_id                  eid  \\\n",
       "0  ml_anomaly_detection_production  2-s2.0-105018574505   \n",
       "1  ml_anomaly_detection_production  2-s2.0-105019192533   \n",
       "2  ml_anomaly_detection_production  2-s2.0-105016669957   \n",
       "3  ml_anomaly_detection_production   2-s2.0-85218693791   \n",
       "4  ml_anomaly_detection_production  2-s2.0-105018301117   \n",
       "\n",
       "                                 doi  \\\n",
       "0  10.1016/j.measurement.2025.119261   \n",
       "1       10.1007/978-3-032-06118-8_30   \n",
       "2        10.1007/978-3-032-04200-2_5   \n",
       "3         10.1038/s41598-025-90810-w   \n",
       "4       10.1016/j.comnet.2025.111753   \n",
       "\n",
       "                                               title  \\\n",
       "0  Distillation anomaly and fault detection based...   \n",
       "1  From Lab to Factory: Pitfalls and Guidelines f...   \n",
       "2  Intelligent Defect Detection for Manufacturing...   \n",
       "3  Hybrid machine learning framework for predicti...   \n",
       "4  BGP anomaly detection using the raw internet t...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  © 2025 The Author(s)The detection of anomalies...   \n",
       "1  © The Author(s), under exclusive license to Sp...   \n",
       "2  © The Author(s), under exclusive license to Sp...   \n",
       "3  © The Author(s) 2025.The critical necessity fo...   \n",
       "4  © 2025 The AuthorsThe Border Gateway Protocol ...   \n",
       "\n",
       "                                           clean_abs  \n",
       "0  Indeed, highly efficient systems do not always...  \n",
       "1  The detection and localization of quality-rela...  \n",
       "2  In modern Industry, I4.0, artificial intellige...  \n",
       "3  The critical necessity for sophisticated predi...  \n",
       "4  Hence, detecting any anomaly concerning BGP an...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load abstracts dataset\n",
    "\n",
    "abstracts_path = processed_abstracts_path / \"abstracts.csv\"\n",
    "df = pd.read_csv(abstracts_path)\n",
    "\n",
    "print(f\"Loaded {len(df)} abstracts from {df['query_id'].nunique()} queries.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f60535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 52290\n",
      "After removing duplicates: 33130\n",
      "Remaining duplicate DOIs: 0\n"
     ]
    }
   ],
   "source": [
    "# Count how many rows each query_id has\n",
    "query_counts = df[\"query_id\"].value_counts().to_dict()\n",
    "\n",
    "# Create a copy and map the counts to each row\n",
    "df = df.copy()\n",
    "df[\"query_size\"] = df[\"query_id\"].map(query_counts)\n",
    "\n",
    "# Sort so that query groups with fewer rows are prioritized\n",
    "df_sorted = df.sort_values(by=\"query_size\", ascending=True)\n",
    "\n",
    "# Remove duplicate DOIs, keeping the one in the smallest query group\n",
    "df_dedup = df_sorted.drop_duplicates(subset=\"doi\", keep=\"first\").drop(columns=[\"query_size\"])\n",
    "\n",
    "# Print results\n",
    "print(\"Original dataset size:\", len(df))\n",
    "print(\"After removing duplicates:\", len(df_dedup))\n",
    "print(\"Remaining duplicate DOIs:\", df_dedup[\"doi\"].duplicated().sum())\n",
    "\n",
    "df = df_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ec40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ml_methods_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    ml_methods_dict = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec15316",
   "metadata": {},
   "source": [
    "## Regex matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f33c5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33130/33130 [00:48<00:00, 682.54it/s]\n"
     ]
    }
   ],
   "source": [
    "def extract_methods(text, term_dict):\n",
    "    # Return empty list if input is not a string\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    found = []\n",
    "    \n",
    "    for method, phrases in term_dict.items():\n",
    "        for phrase in phrases:\n",
    "            # Escape special characters and enforce word boundaries\n",
    "            pattern = r\"\\b\" + re.escape(phrase.lower()) + r\"\\b\"\n",
    "            \n",
    "            # Perform case-insensitive boundary-safe regex search\n",
    "            if re.search(pattern, text.lower()):\n",
    "                found.append(method)\n",
    "                break  # Stop checking more variants for this method\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    return list(dict.fromkeys(found))\n",
    "\n",
    "# Apply extraction with pandas progress bar\n",
    "tqdm.pandas()\n",
    "df[\"ml_methods_regex\"] = df[\"clean_abs\"].fillna(\"\").progress_apply(\n",
    "    lambda x: extract_methods(x, ml_methods_dict)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6cde623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method_count\n",
      "0     18932\n",
      "1      6413\n",
      "2      4038\n",
      "3      1948\n",
      "4       973\n",
      "5       457\n",
      "6       209\n",
      "7       102\n",
      "8        33\n",
      "9        16\n",
      "10        6\n",
      "11        2\n",
      "12        1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ml_methods_regex\n",
       "Neural Network                  6598\n",
       "Random Forest                   3103\n",
       "Support Vector Machine          2176\n",
       "Decision Tree                   1652\n",
       "Artificial Neural Network       1609\n",
       "Convolutional Neural Network    1365\n",
       "Gradient Boosting               1185\n",
       "LSTM                            1107\n",
       "XGBoost                         1091\n",
       "Linear Regression                906\n",
       "Bayesian Method                  893\n",
       "Genetic Algorithm                843\n",
       "K-Nearest Neighbors              813\n",
       "Support Vector Regression        716\n",
       "Particle Swarm Optimization      597\n",
       "Principal Component Analysis     587\n",
       "Deep Neural Network              483\n",
       "Logistic Regression              473\n",
       "SHAP                             460\n",
       "Multi-Layer Perceptron           420\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many ML methods were detected per abstract using the regex-based approach\n",
    "df[\"method_count\"] = df[\"ml_methods_regex\"].str.len()\n",
    "print(df[\"method_count\"].value_counts().sort_index())\n",
    "\n",
    "# Show the top 20 most frequently detected ML methods across all abstracts\n",
    "df.explode(\"ml_methods_regex\")[\"ml_methods_regex\"].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91fc441",
   "metadata": {},
   "source": [
    "## Scispacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8fbe9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer', 'parser', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# Load the large SciSpaCy scientific language model and list all enabled NLP pipeline components\n",
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691d91b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 64 ML_METHOD patterns to EntityRuler.\n"
     ]
    }
   ],
   "source": [
    "# Add an EntityRuler to the NLP pipeline and register patterns for ML method detection\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "patterns = []\n",
    "\n",
    "# Create token-based matching patterns for each ML method phrase\n",
    "for label, phrases in ml_methods_dict.items():\n",
    "    for phrase in phrases:\n",
    "        # Create a case-insensitive match pattern using LOWER tokens\n",
    "        pattern = [{\"LOWER\": token.lower()} for token in phrase.split()]\n",
    "        patterns.append({\n",
    "            \"label\": \"ML_METHOD\",  # Custom entity label for ML methods\n",
    "            \"pattern\": pattern,\n",
    "            \"id\": label  # Canonical method name stored in ent_id_\n",
    "        })\n",
    "\n",
    "# Register all patterns in the EntityRuler\n",
    "ruler.add_patterns(patterns)\n",
    "print(f\"Added {len(patterns)} ML_METHOD patterns to EntityRuler.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd437b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ML method entities from a single abstract using the SciSpaCy EntityRuler\n",
    "def extract_ml_methods_scispacy(text: str) -> List[str]:\n",
    "    # Return empty list if input is not valid text\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    methods = []\n",
    "    \n",
    "    # Collect all detected ML_METHOD entities with their canonical IDs\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ML_METHOD\":\n",
    "            canonical = ent.ent_id_ if ent.ent_id_ else ent.text\n",
    "            methods.append(canonical)\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_methods = list(dict.fromkeys(methods))\n",
    "    return unique_methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6312ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33130/33130 [02:01<00:00, 271.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply the SciSpaCy EntityRuler to extract ML methods for all abstracts efficiently using nlp.pipe\n",
    "texts = df[\"clean_abs\"].fillna(\"\").tolist()\n",
    "\n",
    "ml_methods_all = []\n",
    "\n",
    "# Process abstracts in batches\n",
    "for doc in tqdm(nlp.pipe(texts, batch_size=32, n_process=8), total=len(texts)):\n",
    "    methods = []\n",
    "    \n",
    "    # Collect ML_METHOD entities found in each processed document\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ML_METHOD\":\n",
    "            canonical = ent.ent_id_ if ent.ent_id_ else ent.text\n",
    "            methods.append(canonical)\n",
    "            \n",
    "    # Store unique detected methods for this abstract\n",
    "    ml_methods_all.append(list(dict.fromkeys(methods)))\n",
    "\n",
    "# Save results\n",
    "df[\"ml_methods_scispacy\"] = ml_methods_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdab767e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed abstracts with ML methods to: ../../data/processed/abstracts/regex_scispacy/abstracts_with_ml_methods.csv\n"
     ]
    }
   ],
   "source": [
    "# Save updated dataframe with extracted ML methods\n",
    "output_path = save_path / \"abstracts_with_ml_methods.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved processed abstracts with ML methods to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250de0ad",
   "metadata": {},
   "source": [
    "### SciSpacy: Analyze Abstracts with ML methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7e0ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(save_path / \"abstracts_with_ml_methods.csv\")\n",
    "\n",
    "# Convert string lists to lists\n",
    "df[\"ml_methods_scispacy\"] = df[\"ml_methods_scispacy\"].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1d68766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blockchain-enabled decision system for reliabl...</td>\n",
       "      <td>10.1016/B978-0-443-33740-6.00012-8</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Systematic review of data modelling methods fo...</td>\n",
       "      <td>10.1080/19397038.2025.2563271</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clustering Locations of Collection Centers in ...</td>\n",
       "      <td>10.1109/TEMSCON-ASPAC62480.2024.11025082</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Artificial Intelligence: Basics, Impact, and H...</td>\n",
       "      <td>10.1188/23.CJON.595-601</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intersections between materials science and ma...</td>\n",
       "      <td>10.1039/d3va00106g</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Measuring Carbon in Cities and Their Buildings...</td>\n",
       "      <td>10.3390/asi6050076</td>\n",
       "      <td>[Linear Regression]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Predictive modeling for the quantity of recycl...</td>\n",
       "      <td>10.1016/j.resconrec.2023.107073</td>\n",
       "      <td>[Support Vector Regression, Gradient Boosting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Organizational Maturity and Its Influence on P...</td>\n",
       "      <td>10.1007/978-3-031-94484-0_27</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Toward Sustainable Manufacturing: A Review on ...</td>\n",
       "      <td>10.1109/ACCESS.2025.3576441</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Integrating Digital Twins and Robotics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Blockchain-enabled decision system for reliabl...   \n",
       "1  Systematic review of data modelling methods fo...   \n",
       "2  Clustering Locations of Collection Centers in ...   \n",
       "3  Artificial Intelligence: Basics, Impact, and H...   \n",
       "4  Intersections between materials science and ma...   \n",
       "5  Measuring Carbon in Cities and Their Buildings...   \n",
       "6  Predictive modeling for the quantity of recycl...   \n",
       "7  Organizational Maturity and Its Influence on P...   \n",
       "8  Toward Sustainable Manufacturing: A Review on ...   \n",
       "9             Integrating Digital Twins and Robotics   \n",
       "\n",
       "                                        doi  \\\n",
       "0        10.1016/B978-0-443-33740-6.00012-8   \n",
       "1             10.1080/19397038.2025.2563271   \n",
       "2  10.1109/TEMSCON-ASPAC62480.2024.11025082   \n",
       "3                   10.1188/23.CJON.595-601   \n",
       "4                        10.1039/d3va00106g   \n",
       "5                        10.3390/asi6050076   \n",
       "6           10.1016/j.resconrec.2023.107073   \n",
       "7              10.1007/978-3-031-94484-0_27   \n",
       "8               10.1109/ACCESS.2025.3576441   \n",
       "9                                       NaN   \n",
       "\n",
       "                                 ml_methods_scispacy  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  \n",
       "5                                [Linear Regression]  \n",
       "6  [Support Vector Regression, Gradient Boosting,...  \n",
       "7                                                 []  \n",
       "8                                                 []  \n",
       "9                                                 []  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 papers with their extracted ML methods from SciSpaCy\n",
    "df[[\"title\", \"doi\", \"ml_methods_scispacy\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fc65f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method_count_scispacy\n",
       "0     19301\n",
       "1      7420\n",
       "2      3320\n",
       "3      1606\n",
       "4       815\n",
       "5       384\n",
       "6       164\n",
       "7        73\n",
       "8        28\n",
       "9        12\n",
       "10        6\n",
       "11        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many ML methods SciSpaCy detected per abstract and summarize the distribution\n",
    "df[\"method_count_scispacy\"] = df[\"ml_methods_scispacy\"].str.len()\n",
    "df[\"method_count_scispacy\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a04ae7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ml_methods_scispacy\n",
       "Neural Network                  4547\n",
       "Random Forest                   3060\n",
       "Support Vector Machine          2127\n",
       "Decision Tree                   1614\n",
       "Artificial Neural Network       1551\n",
       "Convolutional Neural Network    1195\n",
       "Gradient Boosting               1173\n",
       "XGBoost                         1053\n",
       "LSTM                             964\n",
       "Bayesian Method                  882\n",
       "Linear Regression                862\n",
       "K-Nearest Neighbors              798\n",
       "Genetic Algorithm                748\n",
       "Support Vector Regression        693\n",
       "Principal Component Analysis     562\n",
       "Particle Swarm Optimization      542\n",
       "Logistic Regression              469\n",
       "Deep Neural Network              458\n",
       "SHAP                             445\n",
       "Multi-Layer Perceptron           391\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the top 20 most frequently detected ML methods using the SciSpaCy extraction\n",
    "df.explode(\"ml_methods_scispacy\")[\"ml_methods_scispacy\"].value_counts().head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc4c9f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Compounding Process Optimization for Recycled ...</td>\n",
       "      <td>10.1109/ICIPTM59628.2024.10563917</td>\n",
       "      <td>[Gradient Boosting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>Prospects for the future: Artificial intellige...</td>\n",
       "      <td>10.2174/9789815305753124010006</td>\n",
       "      <td>[Neural Network]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>Evaluating acceptance of video games using con...</td>\n",
       "      <td>10.1145/3342220.3344924</td>\n",
       "      <td>[Neural Network]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22488</th>\n",
       "      <td>Support Vector Regression Model for Determinin...</td>\n",
       "      <td>10.3390/electronics12143139</td>\n",
       "      <td>[Support Vector Regression]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20296</th>\n",
       "      <td>Interactive feature extraction for diagnostic ...</td>\n",
       "      <td>10.1145/3304079.3310288</td>\n",
       "      <td>[Random Forest]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "231    Compounding Process Optimization for Recycled ...   \n",
       "1101   Prospects for the future: Artificial intellige...   \n",
       "8728   Evaluating acceptance of video games using con...   \n",
       "22488  Support Vector Regression Model for Determinin...   \n",
       "20296  Interactive feature extraction for diagnostic ...   \n",
       "\n",
       "                                     doi          ml_methods_scispacy  \n",
       "231    10.1109/ICIPTM59628.2024.10563917          [Gradient Boosting]  \n",
       "1101      10.2174/9789815305753124010006             [Neural Network]  \n",
       "8728             10.1145/3342220.3344924             [Neural Network]  \n",
       "22488        10.3390/electronics12143139  [Support Vector Regression]  \n",
       "20296            10.1145/3304079.3310288              [Random Forest]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly inspect 5 abstracts where SciSpaCy successfully detected ML methods\n",
    "df[df[\"method_count_scispacy\"] > 0][[\"title\", \"doi\", \"ml_methods_scispacy\"]].sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde14409",
   "metadata": {},
   "source": [
    "## Compare Regex and SciSpacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d0459d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>regex_count</th>\n",
       "      <th>scispacy_count</th>\n",
       "      <th>both_count</th>\n",
       "      <th>regex_only</th>\n",
       "      <th>scispacy_only</th>\n",
       "      <th>union_count</th>\n",
       "      <th>jaccard_overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>6598</td>\n",
       "      <td>4547</td>\n",
       "      <td>4547</td>\n",
       "      <td>2051</td>\n",
       "      <td>0</td>\n",
       "      <td>6598</td>\n",
       "      <td>0.689148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3103</td>\n",
       "      <td>3060</td>\n",
       "      <td>3060</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>3103</td>\n",
       "      <td>0.986142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>2176</td>\n",
       "      <td>2127</td>\n",
       "      <td>2127</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>2176</td>\n",
       "      <td>0.977482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1652</td>\n",
       "      <td>1614</td>\n",
       "      <td>1614</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1652</td>\n",
       "      <td>0.976998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Artificial Neural Network</td>\n",
       "      <td>1609</td>\n",
       "      <td>1551</td>\n",
       "      <td>1551</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1609</td>\n",
       "      <td>0.963953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Convolutional Neural Network</td>\n",
       "      <td>1365</td>\n",
       "      <td>1195</td>\n",
       "      <td>1195</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>1365</td>\n",
       "      <td>0.875458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1185</td>\n",
       "      <td>1173</td>\n",
       "      <td>1172</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1186</td>\n",
       "      <td>0.988196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>1107</td>\n",
       "      <td>964</td>\n",
       "      <td>964</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>1107</td>\n",
       "      <td>0.870822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1091</td>\n",
       "      <td>1053</td>\n",
       "      <td>1053</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1091</td>\n",
       "      <td>0.965170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>906</td>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>906</td>\n",
       "      <td>0.951435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayesian Method</td>\n",
       "      <td>893</td>\n",
       "      <td>882</td>\n",
       "      <td>882</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>0.987682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Genetic Algorithm</td>\n",
       "      <td>843</td>\n",
       "      <td>748</td>\n",
       "      <td>748</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>843</td>\n",
       "      <td>0.887307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>813</td>\n",
       "      <td>798</td>\n",
       "      <td>798</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>813</td>\n",
       "      <td>0.981550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Support Vector Regression</td>\n",
       "      <td>716</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>716</td>\n",
       "      <td>0.967877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Particle Swarm Optimization</td>\n",
       "      <td>597</td>\n",
       "      <td>542</td>\n",
       "      <td>542</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>597</td>\n",
       "      <td>0.907873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Principal Component Analysis</td>\n",
       "      <td>587</td>\n",
       "      <td>562</td>\n",
       "      <td>562</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>587</td>\n",
       "      <td>0.957411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deep Neural Network</td>\n",
       "      <td>483</td>\n",
       "      <td>458</td>\n",
       "      <td>458</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>483</td>\n",
       "      <td>0.948240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>473</td>\n",
       "      <td>469</td>\n",
       "      <td>469</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>473</td>\n",
       "      <td>0.991543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SHAP</td>\n",
       "      <td>460</td>\n",
       "      <td>445</td>\n",
       "      <td>445</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>0.967391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Multi-Layer Perceptron</td>\n",
       "      <td>420</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>420</td>\n",
       "      <td>0.930952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gaussian Process Regression</td>\n",
       "      <td>396</td>\n",
       "      <td>385</td>\n",
       "      <td>385</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>396</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>345</td>\n",
       "      <td>333</td>\n",
       "      <td>333</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>0.965217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Recurrent Neural Network</td>\n",
       "      <td>318</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>0.940252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Explainable AI</td>\n",
       "      <td>294</td>\n",
       "      <td>294</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gated Recurrent Unit</td>\n",
       "      <td>210</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>0.938095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARIMA</td>\n",
       "      <td>151</td>\n",
       "      <td>147</td>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0.973510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Local Outlier Factor</td>\n",
       "      <td>44</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Squared Prediction Error</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hotelling T2</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          method  regex_count  scispacy_count  both_count  \\\n",
       "20                Neural Network         6598            4547        4547   \n",
       "23                 Random Forest         3103            3060        3060   \n",
       "27        Support Vector Machine         2176            2127        2127   \n",
       "4                  Decision Tree         1652            1614        1614   \n",
       "1      Artificial Neural Network         1609            1551        1551   \n",
       "3   Convolutional Neural Network         1365            1195        1195   \n",
       "10             Gradient Boosting         1185            1173        1172   \n",
       "15                          LSTM         1107             964         964   \n",
       "29                       XGBoost         1091            1053        1053   \n",
       "16             Linear Regression          906             862         862   \n",
       "2                Bayesian Method          893             882         882   \n",
       "9              Genetic Algorithm          843             748         748   \n",
       "14           K-Nearest Neighbors          813             798         798   \n",
       "28     Support Vector Regression          716             693         693   \n",
       "21   Particle Swarm Optimization          597             542         542   \n",
       "22  Principal Component Analysis          587             562         562   \n",
       "5            Deep Neural Network          483             458         458   \n",
       "18           Logistic Regression          473             469         469   \n",
       "25                          SHAP          460             445         445   \n",
       "19        Multi-Layer Perceptron          420             391         391   \n",
       "8    Gaussian Process Regression          396             385         385   \n",
       "13                       K-Means          345             333         333   \n",
       "24      Recurrent Neural Network          318             299         299   \n",
       "6                 Explainable AI          294             294         294   \n",
       "7           Gated Recurrent Unit          210             197         197   \n",
       "0                          ARIMA          151             147         147   \n",
       "12              Isolation Forest          103             103         103   \n",
       "17          Local Outlier Factor           44              42          42   \n",
       "26      Squared Prediction Error           28              16          16   \n",
       "11                  Hotelling T2           14               6           6   \n",
       "\n",
       "    regex_only  scispacy_only  union_count  jaccard_overlap  \n",
       "20        2051              0         6598         0.689148  \n",
       "23          43              0         3103         0.986142  \n",
       "27          49              0         2176         0.977482  \n",
       "4           38              0         1652         0.976998  \n",
       "1           58              0         1609         0.963953  \n",
       "3          170              0         1365         0.875458  \n",
       "10          13              1         1186         0.988196  \n",
       "15         143              0         1107         0.870822  \n",
       "29          38              0         1091         0.965170  \n",
       "16          44              0          906         0.951435  \n",
       "2           11              0          893         0.987682  \n",
       "9           95              0          843         0.887307  \n",
       "14          15              0          813         0.981550  \n",
       "28          23              0          716         0.967877  \n",
       "21          55              0          597         0.907873  \n",
       "22          25              0          587         0.957411  \n",
       "5           25              0          483         0.948240  \n",
       "18           4              0          473         0.991543  \n",
       "25          15              0          460         0.967391  \n",
       "19          29              0          420         0.930952  \n",
       "8           11              0          396         0.972222  \n",
       "13          12              0          345         0.965217  \n",
       "24          19              0          318         0.940252  \n",
       "6            0              0          294         1.000000  \n",
       "7           13              0          210         0.938095  \n",
       "0            4              0          151         0.973510  \n",
       "12           0              0          103         1.000000  \n",
       "17           2              0           44         0.954545  \n",
       "26          12              0           28         0.571429  \n",
       "11           8              0           14         0.428571  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure we are working with list -> set for easier membership checks\n",
    "df[\"regex_set\"] = df[\"ml_methods_regex\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "df[\"scispacy_set\"] = df[\"ml_methods_scispacy\"].apply(lambda x: set(x) if isinstance(x, list) else set())\n",
    "\n",
    "# Collect the universe of methods seen by either approach\n",
    "all_methods = sorted(\n",
    "    set().union(*df[\"regex_set\"]).union(*df[\"scispacy_set\"])\n",
    ")\n",
    "\n",
    "rows = []\n",
    "\n",
    "# For each method, compute overlap stats between regex and SciSpaCy\n",
    "for method in all_methods:\n",
    "    regex_mask = df[\"regex_set\"].apply(lambda s: method in s)\n",
    "    scis_mask = df[\"scispacy_set\"].apply(lambda s: method in s)\n",
    "    \n",
    "    regex_count = regex_mask.sum()\n",
    "    scispacy_count = scis_mask.sum()\n",
    "    both_count = (regex_mask & scis_mask).sum()\n",
    "    regex_only = (regex_mask & ~scis_mask).sum()\n",
    "    scispacy_only = (~regex_mask & scis_mask).sum()\n",
    "    union_count = (regex_mask | scis_mask).sum()\n",
    "    \n",
    "    jaccard = both_count / union_count if union_count > 0 else 0.0\n",
    "    \n",
    "    rows.append({\n",
    "        \"method\": method,\n",
    "        \"regex_count\": regex_count,\n",
    "        \"scispacy_count\": scispacy_count,\n",
    "        \"both_count\": both_count,\n",
    "        \"regex_only\": regex_only,\n",
    "        \"scispacy_only\": scispacy_only,\n",
    "        \"union_count\": union_count,\n",
    "        \"jaccard_overlap\": jaccard,\n",
    "    })\n",
    "\n",
    "overlap_df = pd.DataFrame(rows)\n",
    "\n",
    "# Sort by popularity (or by overlap) as you like\n",
    "overlap_df_sorted = overlap_df.sort_values(\"union_count\", ascending=False)\n",
    "\n",
    "# For a quick view: top 20 methods by total detections, with overlap stats\n",
    "overlap_df_sorted.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbaf8e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "      <th>ml_methods</th>\n",
       "      <th>method_count</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "      <th>method_count_scispacy</th>\n",
       "      <th>ml_methods_regex</th>\n",
       "      <th>regex_set</th>\n",
       "      <th>scispacy_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13735</th>\n",
       "      <td>ml_process_control</td>\n",
       "      <td>2-s2.0-85020415893</td>\n",
       "      <td>10.1117/12.2258039</td>\n",
       "      <td>Computational overlay metrology with adaptive ...</td>\n",
       "      <td>© 2017 SPIE.With photolithography as the funda...</td>\n",
       "      <td>With photolithography as the fundamental patte...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[Gradient Boosting]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Gradient Boosting}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 query_id                 eid                 doi  \\\n",
       "13735  ml_process_control  2-s2.0-85020415893  10.1117/12.2258039   \n",
       "\n",
       "                                                   title  \\\n",
       "13735  Computational overlay metrology with adaptive ...   \n",
       "\n",
       "                                                abstract  \\\n",
       "13735  © 2017 SPIE.With photolithography as the funda...   \n",
       "\n",
       "                                               clean_abs ml_methods  \\\n",
       "13735  With photolithography as the fundamental patte...         []   \n",
       "\n",
       "       method_count  ml_methods_scispacy  method_count_scispacy  \\\n",
       "13735             0  [Gradient Boosting]                      1   \n",
       "\n",
       "      ml_methods_regex regex_set         scispacy_set  \n",
       "13735               []        {}  {Gradient Boosting}  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract rows where SciSpaCy found at least one method\n",
    "# and regex found none\n",
    "scispacy_only_df = df[\n",
    "    (df[\"scispacy_set\"].apply(len) > 0) &\n",
    "    (df[\"regex_set\"].apply(len) == 0)\n",
    "]\n",
    "\n",
    "scispacy_only_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b157942d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "      <th>ml_methods</th>\n",
       "      <th>method_count</th>\n",
       "      <th>ml_methods_scispacy</th>\n",
       "      <th>method_count_scispacy</th>\n",
       "      <th>ml_methods_regex</th>\n",
       "      <th>regex_set</th>\n",
       "      <th>scispacy_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>ml_recycling_manufacturing</td>\n",
       "      <td>2-s2.0-85166934684</td>\n",
       "      <td>10.1080/15376494.2023.2238220</td>\n",
       "      <td>Machine learning and RSM-CCD analysis of green...</td>\n",
       "      <td>© 2023 Taylor &amp; Francis Group, LLC.This study ...</td>\n",
       "      <td>This study aims to serve as a performance indi...</td>\n",
       "      <td>['Neural Network', 'Artificial Neural Network']</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[Neural Network, Artificial Neural Network]</td>\n",
       "      <td>{Artificial Neural Network, Neural Network}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>ml_remanufacturing</td>\n",
       "      <td>2-s2.0-85185884385</td>\n",
       "      <td>10.1115/1.4064257</td>\n",
       "      <td>Multiscale Feature Fusion Convolutional Neural...</td>\n",
       "      <td>© 2024 by ASME.The detection of surface damage...</td>\n",
       "      <td>The detection of surface damage is an importan...</td>\n",
       "      <td>['Convolutional Neural Network']</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[Convolutional Neural Network]</td>\n",
       "      <td>{Convolutional Neural Network}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>ml_plm</td>\n",
       "      <td>2-s2.0-85209659742</td>\n",
       "      <td>10.1007/s11277-024-11659-2</td>\n",
       "      <td>Automated Sleep Disorder Diagnosis Utilising E...</td>\n",
       "      <td>© The Author(s), under exclusive licence to Sp...</td>\n",
       "      <td>Automated sleep disorders diagnosis is difficu...</td>\n",
       "      <td>['LSTM']</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[LSTM]</td>\n",
       "      <td>{LSTM}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>ml_plm</td>\n",
       "      <td>2-s2.0-105014826125</td>\n",
       "      <td>10.1016/j.jss.2025.112604</td>\n",
       "      <td>Syntactic multilingual probing of pre-trained ...</td>\n",
       "      <td>© 2025 The Author(s)Pre-trained language model...</td>\n",
       "      <td>However, due to their deep neural network-base...</td>\n",
       "      <td>['Neural Network', 'Deep Neural Network']</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[Neural Network, Deep Neural Network]</td>\n",
       "      <td>{Neural Network, Deep Neural Network}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>ml_disassembly</td>\n",
       "      <td>2-s2.0-85108906446</td>\n",
       "      <td>10.1145/3453800.3453830</td>\n",
       "      <td>Mask R-CNN Based Laptop Parts Detector for Dis...</td>\n",
       "      <td>© 2021 ACM.The efficient recycling of waste el...</td>\n",
       "      <td>The efficient recycling of waste electronic 3C...</td>\n",
       "      <td>['Convolutional Neural Network']</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[Convolutional Neural Network]</td>\n",
       "      <td>{Convolutional Neural Network}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       query_id                  eid  \\\n",
       "126  ml_recycling_manufacturing   2-s2.0-85166934684   \n",
       "156          ml_remanufacturing   2-s2.0-85185884385   \n",
       "372                      ml_plm   2-s2.0-85209659742   \n",
       "457                      ml_plm  2-s2.0-105014826125   \n",
       "609              ml_disassembly   2-s2.0-85108906446   \n",
       "\n",
       "                               doi  \\\n",
       "126  10.1080/15376494.2023.2238220   \n",
       "156              10.1115/1.4064257   \n",
       "372     10.1007/s11277-024-11659-2   \n",
       "457      10.1016/j.jss.2025.112604   \n",
       "609        10.1145/3453800.3453830   \n",
       "\n",
       "                                                 title  \\\n",
       "126  Machine learning and RSM-CCD analysis of green...   \n",
       "156  Multiscale Feature Fusion Convolutional Neural...   \n",
       "372  Automated Sleep Disorder Diagnosis Utilising E...   \n",
       "457  Syntactic multilingual probing of pre-trained ...   \n",
       "609  Mask R-CNN Based Laptop Parts Detector for Dis...   \n",
       "\n",
       "                                              abstract  \\\n",
       "126  © 2023 Taylor & Francis Group, LLC.This study ...   \n",
       "156  © 2024 by ASME.The detection of surface damage...   \n",
       "372  © The Author(s), under exclusive licence to Sp...   \n",
       "457  © 2025 The Author(s)Pre-trained language model...   \n",
       "609  © 2021 ACM.The efficient recycling of waste el...   \n",
       "\n",
       "                                             clean_abs  \\\n",
       "126  This study aims to serve as a performance indi...   \n",
       "156  The detection of surface damage is an importan...   \n",
       "372  Automated sleep disorders diagnosis is difficu...   \n",
       "457  However, due to their deep neural network-base...   \n",
       "609  The efficient recycling of waste electronic 3C...   \n",
       "\n",
       "                                          ml_methods  method_count  \\\n",
       "126  ['Neural Network', 'Artificial Neural Network']             2   \n",
       "156                 ['Convolutional Neural Network']             1   \n",
       "372                                         ['LSTM']             1   \n",
       "457        ['Neural Network', 'Deep Neural Network']             2   \n",
       "609                 ['Convolutional Neural Network']             1   \n",
       "\n",
       "    ml_methods_scispacy  method_count_scispacy  \\\n",
       "126                  []                      0   \n",
       "156                  []                      0   \n",
       "372                  []                      0   \n",
       "457                  []                      0   \n",
       "609                  []                      0   \n",
       "\n",
       "                                ml_methods_regex  \\\n",
       "126  [Neural Network, Artificial Neural Network]   \n",
       "156               [Convolutional Neural Network]   \n",
       "372                                       [LSTM]   \n",
       "457        [Neural Network, Deep Neural Network]   \n",
       "609               [Convolutional Neural Network]   \n",
       "\n",
       "                                       regex_set scispacy_set  \n",
       "126  {Artificial Neural Network, Neural Network}           {}  \n",
       "156               {Convolutional Neural Network}           {}  \n",
       "372                                       {LSTM}           {}  \n",
       "457        {Neural Network, Deep Neural Network}           {}  \n",
       "609               {Convolutional Neural Network}           {}  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract rows where Regex found at least one method\n",
    "# and SciSpacy found none\n",
    "scispacy_only_df = df[\n",
    "    (df[\"regex_set\"].apply(len) > 0) &\n",
    "    (df[\"scispacy_set\"].apply(len) == 0)\n",
    "]\n",
    "\n",
    "scispacy_only_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e33f5",
   "metadata": {},
   "source": [
    "## Extract ML-Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "01038781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common \"method head\" words and extract ML-related candidate phrases from parsed abstracts\n",
    "METHOD_HEADS = {\n",
    "    \"network\", \"networks\",\n",
    "    \"model\", \"models\",\n",
    "    \"algorithm\", \"algorithms\",\n",
    "    \"classifier\", \"classifiers\",\n",
    "    \"regression\",\n",
    "    \"forest\", \"forests\",\n",
    "    \"clustering\", \"clusterer\", \"clusterers\",\n",
    "    \"encoder\", \"encoders\",\n",
    "    \"autoencoder\", \"autoencoders\",\n",
    "    \"transformer\", \"transformers\",\n",
    "    \"estimators\", \"estimator\",\n",
    "    \"approach\", \"approaches\",\n",
    "    \"architecture\", \"architectures\",\n",
    "}\n",
    "\n",
    "def extract_candidate_phrases_from_doc(doc):\n",
    "    \"\"\"Extract candidate ML-method phrases from a spaCy Doc.\"\"\"\n",
    "    candidates = []\n",
    "\n",
    "    # Noun chunks that end with a \"method head\" word\n",
    "    for chunk in doc.noun_chunks:\n",
    "        tokens = [t for t in chunk if not t.is_punct]\n",
    "        if not tokens:\n",
    "            continue\n",
    "\n",
    "        head = tokens[-1].lemma_.lower()\n",
    "        if head in METHOD_HEADS:\n",
    "            if 1 <= len(tokens) <= 7:\n",
    "                phrase = chunk.text.strip()\n",
    "                candidates.append(phrase)\n",
    "\n",
    "    # All-caps acronyms (e.g., SVM, CNN, LSTM)\n",
    "    for token in doc:\n",
    "        if (\n",
    "            token.is_alpha\n",
    "            and token.text.isupper()\n",
    "            and 2 <= len(token.text) <= 6\n",
    "        ):\n",
    "            candidates.append(token.text)\n",
    "\n",
    "    # Remove duplicates, preserve order\n",
    "    return list(dict.fromkeys(candidates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "882b1926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 9209/33130 [00:33<01:12, 331.05it/s]Process Process-34:\n",
      "Process Process-32:\n",
      "Process Process-33:\n",
      "Process Process-28:\n",
      "Process Process-30:\n",
      "Process Process-29:\n",
      "Traceback (most recent call last):\n",
      "Process Process-27:\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in <listcomp>\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                  ^^^^^^^^^^^^^^\n",
      "  File \"spacy/tokens/doc.pyx\", line 1351, in spacy.tokens.doc.Doc.to_bytes\n",
      "  File \"spacy/tokens/doc.pyx\", line 1375, in spacy.tokens.doc.Doc.to_dict\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in <listcomp>\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "Process Process-31:\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 57, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in <listcomp>\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/pipeline/attributeruler.py\", line 142, in __call__\n",
      "    matches = self.match(doc)\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/pipeline/attributeruler.py\", line 149, in match\n",
      "    matches = self.matcher(doc, allow_missing=True, as_spans=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "KeyboardInterrupt\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 249, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1653, in minibatch\n",
      "    yield list(batch)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in <listcomp>\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in <listcomp>\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 251, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 264, in spacy.pipeline.transition_parser.Parser.predict\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 285, in spacy.pipeline.transition_parser.Parser.greedy_parse\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 334, in predict\n",
      "    return self._func(self, X, is_train=False)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/ml/tb_framework.py\", line 34, in forward\n",
      "    step_model = ParserStepModel(\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"spacy/ml/parser_model.pyx\", line 250, in spacy.ml.parser_model.ParserStepModel.__init__\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/concatenate.py\", line 57, in forward\n",
      "    Ys, callbacks = zip(*[layer(X, is_train=is_train) for layer in model.layers])\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/concatenate.py\", line 57, in <listcomp>\n",
      "    Ys, callbacks = zip(*[layer(X, is_train=is_train) for layer in model.layers])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"spacy/pipeline/trainable_pipe.pyx\", line 73, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"spacy/pipeline/trainable_pipe.pyx\", line 75, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/pipeline/tok2vec.py\", line 126, in predict\n",
      "    tokvecs = self.model.predict(docs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/with_array.py\", line 36, in forward\n",
      "    return cast(Tuple[SeqT, Callable], _ragged_forward(model, Xseq, is_train))\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 334, in predict\n",
      "    return self._func(self, X, is_train=False)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/with_array.py\", line 91, in _ragged_forward\n",
      "    Y, get_dX = layer(Xr.dataXd, is_train)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/concatenate.py\", line 57, in forward\n",
      "    Ys, callbacks = zip(*[layer(X, is_train=is_train) for layer in model.layers])\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/concatenate.py\", line 57, in <listcomp>\n",
      "    Ys, callbacks = zip(*[layer(X, is_train=is_train) for layer in model.layers])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/concatenate.py\", line 57, in forward\n",
      "    Ys, callbacks = zip(*[layer(X, is_train=is_train) for layer in model.layers])\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/concatenate.py\", line 57, in <listcomp>\n",
      "    Ys, callbacks = zip(*[layer(X, is_train=is_train) for layer in model.layers])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/hashembed.py\", line 72, in forward\n",
      "    output = model.ops.gather_add(vectors, keys)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/with_array.py\", line 36, in forward\n",
      "    return cast(Tuple[SeqT, Callable], _ragged_forward(model, Xseq, is_train))\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/with_array.py\", line 91, in _ragged_forward\n",
      "    Y, get_dX = layer(Xr.dataXd, is_train)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/concatenate.py\", line 57, in forward\n",
      "    Ys, callbacks = zip(*[layer(X, is_train=is_train) for layer in model.layers])\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/concatenate.py\", line 57, in <listcomp>\n",
      "    Ys, callbacks = zip(*[layer(X, is_train=is_train) for layer in model.layers])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/apps/eb/software/Anaconda3/2023.09-0/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in <listcomp>\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/hashembed.py\", line 72, in forward\n",
      "    output = model.ops.gather_add(vectors, keys)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/trainable_pipe.pyx\", line 73, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/trainable_pipe.pyx\", line 75, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in <listcomp>\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/pipeline/tok2vec.py\", line 126, in predict\n",
      "    tokvecs = self.model.predict(docs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py\", line 2364, in <listcomp>\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 334, in predict\n",
      "    return self._func(self, X, is_train=False)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 251, in pipe\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 264, in spacy.pipeline.transition_parser.Parser.predict\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 285, in spacy.pipeline.transition_parser.Parser.greedy_parse\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 334, in predict\n",
      "    return self._func(self, X, is_train=False)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/ml/tb_framework.py\", line 34, in forward\n",
      "    step_model = ParserStepModel(\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/ml/parser_model.pyx\", line 250, in spacy.ml.parser_model.ParserStepModel.__init__\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"spacy/pipeline/trainable_pipe.pyx\", line 73, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/with_array.py\", line 36, in forward\n",
      "    return cast(Tuple[SeqT, Callable], _ragged_forward(model, Xseq, is_train))\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"spacy/pipeline/trainable_pipe.pyx\", line 75, in pipe\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/with_array.py\", line 91, in _ragged_forward\n",
      "    Y, get_dX = layer(Xr.dataXd, is_train)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/pipeline/tok2vec.py\", line 126, in predict\n",
      "    tokvecs = self.model.predict(docs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 334, in predict\n",
      "    return self._func(self, X, is_train=False)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/with_array.py\", line 42, in forward\n",
      "    return cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/with_array.py\", line 77, in _list_forward\n",
      "    Yf, get_dXf = layer(Xf, is_train)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/maxout.py\", line 54, in forward\n",
      "    Z = model.ops.reshape3f(Y, Y.shape[0], nO, nP)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/backends/ops.py\", line 635, in reshape3f\n",
      "    def reshape3f(self, array: FloatsXd, d0: int, d1: int, d2: int) -> Floats3d:\n",
      "    \n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/residual.py\", line 41, in forward\n",
      "    Y, backprop_layer = model.layers[0](X, is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/with_array.py\", line 42, in forward\n",
      "    return cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/with_array.py\", line 77, in _list_forward\n",
      "    Yf, get_dXf = layer(Xf, is_train)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/residual.py\", line 41, in forward\n",
      "    Y, backprop_layer = model.layers[0](X, is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/layernorm.py\", line 24, in forward\n",
      "    N, mu, var = _get_moments(model.ops, X)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/layernorm.py\", line 75, in _get_moments\n",
      "    var: Floats2d = X.var(axis=1, keepdims=True) + 1e-08\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/numpy/core/_methods.py\", line 173, in _var\n",
      "    x = asanyarray(arr - arrmean)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/layernorm.py\", line 24, in forward\n",
      "    N, mu, var = _get_moments(model.ops, X)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/thinc/layers/layernorm.py\", line 74, in _get_moments\n",
      "    mu: Floats2d = X.mean(axis=1, keepdims=True)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/numpy/core/_methods.py\", line 118, in _mean\n",
      "    ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "/cluster/home/mbergst/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py:1734: UserWarning: [W127] Not all `Language.pipe` worker processes completed successfully\n",
      "  warnings.warn(Warnings.W127)\n",
      " 28%|██▊       | 9236/33130 [00:33<01:26, 275.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m candidate_counter = collections.Counter()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Batch processing with multiple processes for faster NLP execution\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_process\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcand\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mextract_candidate_phrases_from_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_counter\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcand\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py:1618\u001b[39m, in \u001b[36mLanguage.pipe\u001b[39m\u001b[34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[39m\n\u001b[32m   1616\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m pipes:\n\u001b[32m   1617\u001b[39m         docs = pipe(docs)\n\u001b[32m-> \u001b[39m\u001b[32m1618\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/language.py:1702\u001b[39m, in \u001b[36mLanguage._multiprocessing_pipe\u001b[39m\u001b[34m(self, texts, pipes, n_process, batch_size)\u001b[39m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (_, (byte_doc, context, byte_error)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[32m   1699\u001b[39m     \u001b[38;5;28mzip\u001b[39m(raw_texts, byte_tuples), \u001b[32m1\u001b[39m\n\u001b[32m   1700\u001b[39m ):\n\u001b[32m   1701\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m byte_doc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1702\u001b[39m         doc = \u001b[43mDoc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_doc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1703\u001b[39m         doc._context = context\n\u001b[32m   1704\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m doc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/tokens/doc.pyx:1362\u001b[39m, in \u001b[36mspacy.tokens.doc.Doc.from_bytes\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/tokens/doc.pyx:1455\u001b[39m, in \u001b[36mspacy.tokens.doc.Doc.from_dict\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/spacy/tokens/doc.pyx:1155\u001b[39m, in \u001b[36mspacy.tokens.doc.Doc.from_array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/numpy/core/_methods.py:55\u001b[39m, in \u001b[36m_any\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prod\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     52\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_prod(a, axis, dtype, out, keepdims, initial, where)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_any\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m, *, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     58\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m umr_any(a, axis, dtype, out, keepdims)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Extract ML-related candidate phrases from all abstracts efficiently using spaCy's nlp.pipe\n",
    "texts = df[\"clean_abs\"].fillna(\"\").tolist()\n",
    "\n",
    "candidate_counter = collections.Counter()\n",
    "\n",
    "# Batch processing with multiple processes for faster NLP execution\n",
    "for doc in tqdm(\n",
    "    nlp.pipe(texts, batch_size=64, n_process=8),\n",
    "    total=len(texts)\n",
    "):\n",
    "    for cand in extract_candidate_phrases_from_doc(doc):\n",
    "        candidate_counter[cand] += 1\n",
    "\n",
    "print(f\"Extracted {len(candidate_counter)} unique candidate phrases.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57879afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5519  ML\n",
      "3704  AI\n",
      "1268  SVM\n",
      "1243  RMSE\n",
      "1182  the model\n",
      "1139  ANN\n",
      " 967  RF\n",
      " 964  LSTM\n",
      " 955  RUL\n",
      " 892  AM\n",
      " 860  CNN\n",
      " 842  The model\n",
      " 795  This approach\n",
      " 765  MAE\n",
      " 747  machine learning algorithms\n",
      " 547  MDPI\n",
      " 541  machine learning models\n",
      " 532  DL\n",
      " 530  DT\n",
      " 511  Random Forest\n",
      " 497  models\n",
      " 470  KNN\n",
      " 461  MSE\n",
      " 460  SVR\n",
      " 443  SHAP\n",
      " 430  The approach\n",
      " 425  a novel approach\n",
      " 402  an approach\n",
      " 402  a model\n",
      " 389  MLP\n",
      " 374  this approach\n",
      " 368  The proposed approach\n",
      " 356  MAPE\n",
      " 352  PCA\n",
      " 346  our approach\n",
      " 335  the models\n",
      " 334  PSO\n",
      " 322  CC\n",
      " 320  random forest\n",
      " 307  GA\n",
      " 296  the proposed approach\n",
      " 293  Our approach\n",
      " 287  the proposed model\n",
      " 286  The models\n",
      " 285  algorithms\n",
      " 274  The proposed model\n",
      " 268  This model\n",
      " 265  the approach\n",
      " 263  RL\n",
      " 259  These models\n",
      " 255  these models\n",
      " 246  a machine learning model\n",
      " 243  DNN\n",
      " 241  neural networks\n",
      " 233  PV\n",
      " 233  IEEE\n",
      " 231  ML models\n",
      " 225  GPR\n",
      " 220  predictive models\n",
      " 216  NASA\n",
      " 213  LR\n",
      " 213  artificial neural networks\n",
      " 211  CNC\n",
      " 209  CPS\n",
      " 206  PHM\n",
      " 202  ELM\n",
      " 201  IT\n",
      " 199  RNN\n",
      " 198  UK\n",
      " 198  AUC\n",
      " 192  XAI\n",
      " 191  ML algorithms\n",
      " 186  the algorithm\n",
      " 182  LPBF\n",
      " 182  NN\n",
      " 176  CAD\n",
      " 173  MATLAB\n",
      " 167  NLP\n",
      " 167  FDM\n",
      " 166  IC\n",
      " 158  SEM\n",
      " 157  Machine learning algorithms\n",
      " 157  GRU\n",
      " 157  approaches\n",
      " 155  II\n",
      " 153  PLM\n",
      " 152  The algorithm\n",
      " 150  a new approach\n",
      " 149  BP\n",
      " 148  a machine learning approach\n",
      " 146  ARIMA\n",
      " 140  our model\n",
      " 139  RSM\n",
      " 137  Machine learning models\n",
      " 136  this model\n",
      " 135  FL\n",
      " 132  CFD\n",
      " 131  machine learning approaches\n",
      " 131  XGB\n",
      " 130  artificial neural network\n"
     ]
    }
   ],
   "source": [
    "# Show the top candidate phrases by frequency\n",
    "for phrase, count in candidate_counter.most_common(100):\n",
    "    print(f\"{count:4d}  {phrase}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59191c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-catalogue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
