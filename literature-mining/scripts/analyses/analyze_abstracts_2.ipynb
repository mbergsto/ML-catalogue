{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0fa4c62",
   "metadata": {},
   "source": [
    "- Make cleaning of text softer, since Scibert can handle it well.\n",
    "- Larger max_length since abstracts are often larger than 256 tokens. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da60786",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b67554ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca6e106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All directories verified/created.\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "\n",
    "data_path = Path(\"../../data/short-raw-refs-abs\")\n",
    "table_path = Path(\"../../reports/tables\")\n",
    "figure_path = Path(\"../../reports/figures\")\n",
    "keywords_path = Path(\"../../keywords\")\n",
    "processed_abstracts_path = Path(\"../../data/processed/abstracts\")\n",
    "\n",
    "# Ensure directories exist\n",
    "for p in [data_path, table_path, figure_path, keywords_path, processed_abstracts_path]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"All directories verified/created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d884fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "CREATE_ABSTRACTS_DATASET = False\n",
    "\n",
    "# Number of topics used for K-means\n",
    "n_topics = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f32dfc",
   "metadata": {},
   "source": [
    "#### Create Abstracts dataset (only need to do this once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37868b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: Clean Abstracts\n",
    "# Basic text cleaning\n",
    "\n",
    "# Light cleaning for model input: keep most of the original signal\n",
    "def clean_text_for_model(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove Scopus-style copyright header at the very beginning\n",
    "    text = re.sub(r\"^©\\s*\\d{0,4}\\s*the author\\(s\\)\\s*\", \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Optionally strip URLs and extra whitespace, but keep punctuation, numbers, etc.\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c50df74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "if CREATE_ABSTRACTS_DATASET:\n",
    "\n",
    "    for folder in sorted(data_path.iterdir()):\n",
    "        if not folder.is_dir():\n",
    "            continue\n",
    "        query_id = folder.name\n",
    "        jsonl_files = list(folder.glob(\"*.jsonl\"))\n",
    "        for fp in jsonl_files:\n",
    "            with fp.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    try:\n",
    "                        rec = json.loads(line)\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "\n",
    "                    abs_txt = rec.get(\"abstract\") or rec.get(\"description\") or \"\"\n",
    "                    if isinstance(abs_txt, list):\n",
    "                        abs_txt = \" \".join(str(x) for x in abs_txt if x)\n",
    "\n",
    "                    # Cover date was not included in last script\n",
    "                    records.append({\n",
    "                        \"query_id\": query_id,\n",
    "                        \"eid\": rec.get(\"eid\"),\n",
    "                        \"doi\": rec.get(\"doi\"),\n",
    "                        \"title\": rec.get(\"title\"),\n",
    "                        # \"coverDate\": rec.get(\"coverDate\"),\n",
    "                        \"abstract\": abs_txt.strip()\n",
    "                    })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # Remove empty abstracts early\n",
    "    df = df[df[\"abstract\"].notna() & (df[\"abstract\"].str.strip() != \"\")]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Clean abstracts\n",
    "    df[\"clean_abs\"] = df[\"abstract\"].apply(clean_text)\n",
    "    \n",
    "    print(f\"\\nCollected {len(df)} abstracts from {len(df['query_id'].unique())} queries\")\n",
    "\n",
    "    # Save for later analysis\n",
    "    out_path = processed_abstracts_path / \"abstracts.csv\"\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a3b55a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 32714 abstracts\n"
     ]
    }
   ],
   "source": [
    "# Load dataframe with abstracts\n",
    "# Only if it has been created earlier\n",
    "\n",
    "if not CREATE_ABSTRACTS_DATASET:\n",
    "    abstracts_path = processed_abstracts_path / \"abstracts.csv\"\n",
    "    df = pd.read_csv(abstracts_path) \n",
    "    print(f\"Loaded {len(df)} abstracts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "024c1eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105018574505</td>\n",
       "      <td>10.1016/j.measurement.2025.119261</td>\n",
       "      <td>Distillation anomaly and fault detection based...</td>\n",
       "      <td>© 2025 The Author(s)The detection of anomalies...</td>\n",
       "      <td>the detection of anomalies in production proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105019192533</td>\n",
       "      <td>10.1007/978-3-032-06118-8_30</td>\n",
       "      <td>From Lab to Factory: Pitfalls and Guidelines f...</td>\n",
       "      <td>© The Author(s), under exclusive license to Sp...</td>\n",
       "      <td>under exclusive license to springer nature swi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          query_id                  eid  \\\n",
       "0  ml_anomaly_detection_production  2-s2.0-105018574505   \n",
       "1  ml_anomaly_detection_production  2-s2.0-105019192533   \n",
       "\n",
       "                                 doi  \\\n",
       "0  10.1016/j.measurement.2025.119261   \n",
       "1       10.1007/978-3-032-06118-8_30   \n",
       "\n",
       "                                               title  \\\n",
       "0  Distillation anomaly and fault detection based...   \n",
       "1  From Lab to Factory: Pitfalls and Guidelines f...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  © 2025 The Author(s)The detection of anomalies...   \n",
       "1  © The Author(s), under exclusive license to Sp...   \n",
       "\n",
       "                                           clean_abs  \n",
       "0  the detection of anomalies in production proce...  \n",
       "1  under exclusive license to springer nature swi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b9270d",
   "metadata": {},
   "source": [
    "## Create Topics with K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aff82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TF-IDF vectorization\n",
    "\n",
    "# # Convert cleaned abstracts to TF-IDF features\n",
    "# tfidf = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
    "# X = tfidf.fit_transform(df[\"clean_abs\"])\n",
    "\n",
    "# print(f\"TF-IDF shape: {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b18d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # K-Means topic clustering\n",
    "\n",
    "# km = KMeans(n_clusters=n_topics, random_state=42)\n",
    "# df[\"topic\"] = km.fit_predict(X)\n",
    "\n",
    "# df[\"topic\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2c40b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show top TF-IDF words per topic\n",
    "# terms = tfidf.get_feature_names_out()\n",
    "\n",
    "# for i in range(n_topics):\n",
    "#     idx = km.cluster_centers_[i].argsort()[::-1][:10]\n",
    "#     top_terms = [terms[j] for j in idx]\n",
    "#     print(f\"Topic {i}: {', '.join(top_terms)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "985a2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count how many abstracts per query belong to each topic\n",
    "# topic_dist = df.groupby([\"query_id\", \"topic\"]).size().unstack(fill_value=0)\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# sns.heatmap(topic_dist, cmap=\"Blues\", annot=True, fmt=\"d\")\n",
    "# plt.title(\"Topic distribution across queries\")\n",
    "# plt.ylabel(\"Query ID\")\n",
    "# plt.xlabel(\"Topic\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a8a64eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for later analysis\n",
    "# save_path = table_path / \"abstract_topics.csv\"\n",
    "# df.to_csv(save_path, index=False)\n",
    "# print(f\"Saved topic assignments to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271d890d",
   "metadata": {},
   "source": [
    "## Analyze with Keywords (Supervised / Unsupervised / Reinforcement)\n",
    "\n",
    "Each article is classified using keyword matching based on its cleaned abstract.\n",
    "The classification is **multi-label**, meaning an article may be tagged as\n",
    "supervised, unsupervised, and/or reinforcement learning depending on which\n",
    "keywords appear as whole words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2adbcc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all keywords \n",
    "\n",
    "def load_keyword_file(path: Path) -> list[str]:\n",
    "    keywords = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"#\"):\n",
    "                continue\n",
    "            keywords.append(line.lower())\n",
    "    return keywords\n",
    "\n",
    "\n",
    "def load_all_keywords(base_dir: Path = keywords_path) -> dict[str, list[str]]:\n",
    "    return {\n",
    "        \"supervised\": load_keyword_file(base_dir / \"supervised.txt\"),\n",
    "        \"unsupervised\": load_keyword_file(base_dir / \"unsupervised.txt\"),\n",
    "        \"reinforcement\": load_keyword_file(base_dir / \"reinforcement.txt\"),\n",
    "    }\n",
    "\n",
    "\n",
    "ml_keywords = load_all_keywords()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a24a72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "      <th>is_supervised</th>\n",
       "      <th>is_unsupervised</th>\n",
       "      <th>is_reinforcement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105018574505</td>\n",
       "      <td>10.1016/j.measurement.2025.119261</td>\n",
       "      <td>Distillation anomaly and fault detection based...</td>\n",
       "      <td>© 2025 The Author(s)The detection of anomalies...</td>\n",
       "      <td>the detection of anomalies in production proce...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105019192533</td>\n",
       "      <td>10.1007/978-3-032-06118-8_30</td>\n",
       "      <td>From Lab to Factory: Pitfalls and Guidelines f...</td>\n",
       "      <td>© The Author(s), under exclusive license to Sp...</td>\n",
       "      <td>under exclusive license to springer nature swi...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          query_id                  eid  \\\n",
       "0  ml_anomaly_detection_production  2-s2.0-105018574505   \n",
       "1  ml_anomaly_detection_production  2-s2.0-105019192533   \n",
       "\n",
       "                                 doi  \\\n",
       "0  10.1016/j.measurement.2025.119261   \n",
       "1       10.1007/978-3-032-06118-8_30   \n",
       "\n",
       "                                               title  \\\n",
       "0  Distillation anomaly and fault detection based...   \n",
       "1  From Lab to Factory: Pitfalls and Guidelines f...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  © 2025 The Author(s)The detection of anomalies...   \n",
       "1  © The Author(s), under exclusive license to Sp...   \n",
       "\n",
       "                                           clean_abs  is_supervised  \\\n",
       "0  the detection of anomalies in production proce...          False   \n",
       "1  under exclusive license to springer nature swi...          False   \n",
       "\n",
       "   is_unsupervised  is_reinforcement  \n",
       "0             True             False  \n",
       "1             True             False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each ML category, create a binary column (1/0) indicating\n",
    "# whether any of that category's keywords appear in the cleaned abstract.\n",
    "# (Uses word-boundary matching so e.g. 'supervised' does NOT match inside 'unsupervised')\n",
    "\n",
    "def contains_keyword(text, keyword):\n",
    "    # Escape keyword and enforce word boundaries (\\b)\n",
    "    pattern = rf\"\\b{re.escape(keyword)}\\b\"\n",
    "    return re.search(pattern, text) is not None\n",
    "\n",
    "for label in ml_keywords.keys():\n",
    "    df[f\"is_{label}\"] = df[\"clean_abs\"].apply(\n",
    "        lambda t, lab=label: any(contains_keyword(str(t).lower(), w) for w in ml_keywords[lab])\n",
    "\n",
    "    )\n",
    "    \n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "265f511b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "      <th>is_supervised</th>\n",
       "      <th>is_unsupervised</th>\n",
       "      <th>is_reinforcement</th>\n",
       "      <th>ml_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105018574505</td>\n",
       "      <td>10.1016/j.measurement.2025.119261</td>\n",
       "      <td>Distillation anomaly and fault detection based...</td>\n",
       "      <td>© 2025 The Author(s)The detection of anomalies...</td>\n",
       "      <td>the detection of anomalies in production proce...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[unsupervised]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105019192533</td>\n",
       "      <td>10.1007/978-3-032-06118-8_30</td>\n",
       "      <td>From Lab to Factory: Pitfalls and Guidelines f...</td>\n",
       "      <td>© The Author(s), under exclusive license to Sp...</td>\n",
       "      <td>under exclusive license to springer nature swi...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[unsupervised]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105016669957</td>\n",
       "      <td>10.1007/978-3-032-04200-2_5</td>\n",
       "      <td>Intelligent Defect Detection for Manufacturing...</td>\n",
       "      <td>© The Author(s), under exclusive license to Sp...</td>\n",
       "      <td>under exclusive license to springer nature swi...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[supervised, unsupervised]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-85218693791</td>\n",
       "      <td>10.1038/s41598-025-90810-w</td>\n",
       "      <td>Hybrid machine learning framework for predicti...</td>\n",
       "      <td>© The Author(s) 2025.The critical necessity fo...</td>\n",
       "      <td>the critical necessity for sophisticated predi...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[supervised, unsupervised]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ml_anomaly_detection_production</td>\n",
       "      <td>2-s2.0-105018301117</td>\n",
       "      <td>10.1016/j.comnet.2025.111753</td>\n",
       "      <td>BGP anomaly detection using the raw internet t...</td>\n",
       "      <td>© 2025 The AuthorsThe Border Gateway Protocol ...</td>\n",
       "      <td>the authorsthe border gateway protocol bgp is ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[unsupervised]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          query_id                  eid  \\\n",
       "0  ml_anomaly_detection_production  2-s2.0-105018574505   \n",
       "1  ml_anomaly_detection_production  2-s2.0-105019192533   \n",
       "2  ml_anomaly_detection_production  2-s2.0-105016669957   \n",
       "3  ml_anomaly_detection_production   2-s2.0-85218693791   \n",
       "4  ml_anomaly_detection_production  2-s2.0-105018301117   \n",
       "\n",
       "                                 doi  \\\n",
       "0  10.1016/j.measurement.2025.119261   \n",
       "1       10.1007/978-3-032-06118-8_30   \n",
       "2        10.1007/978-3-032-04200-2_5   \n",
       "3         10.1038/s41598-025-90810-w   \n",
       "4       10.1016/j.comnet.2025.111753   \n",
       "\n",
       "                                               title  \\\n",
       "0  Distillation anomaly and fault detection based...   \n",
       "1  From Lab to Factory: Pitfalls and Guidelines f...   \n",
       "2  Intelligent Defect Detection for Manufacturing...   \n",
       "3  Hybrid machine learning framework for predicti...   \n",
       "4  BGP anomaly detection using the raw internet t...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  © 2025 The Author(s)The detection of anomalies...   \n",
       "1  © The Author(s), under exclusive license to Sp...   \n",
       "2  © The Author(s), under exclusive license to Sp...   \n",
       "3  © The Author(s) 2025.The critical necessity fo...   \n",
       "4  © 2025 The AuthorsThe Border Gateway Protocol ...   \n",
       "\n",
       "                                           clean_abs  is_supervised  \\\n",
       "0  the detection of anomalies in production proce...          False   \n",
       "1  under exclusive license to springer nature swi...          False   \n",
       "2  under exclusive license to springer nature swi...           True   \n",
       "3  the critical necessity for sophisticated predi...           True   \n",
       "4  the authorsthe border gateway protocol bgp is ...          False   \n",
       "\n",
       "   is_unsupervised  is_reinforcement                     ml_type  \n",
       "0             True             False              [unsupervised]  \n",
       "1             True             False              [unsupervised]  \n",
       "2             True             False  [supervised, unsupervised]  \n",
       "3             True             False  [supervised, unsupervised]  \n",
       "4             True             False              [unsupervised]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column: \"ml_type\" that lists all categorys with True\n",
    "\n",
    "def resolve_label(row):\n",
    "    labels = []\n",
    "    if row[\"is_supervised\"]: labels.append(\"supervised\")\n",
    "    if row[\"is_unsupervised\"]: labels.append(\"unsupervised\")\n",
    "    if row[\"is_reinforcement\"]: labels.append(\"reinforcement\")\n",
    "    return labels or [\"unknown\"]\n",
    "\n",
    "df[\"ml_type\"] = df.apply(resolve_label, axis=1)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db34c5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ml_type\n",
       "unknown          19265\n",
       "supervised        9949\n",
       "unsupervised      3843\n",
       "reinforcement     1851\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency of each ML category\n",
    "df[\"ml_type\"].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a883fdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ml_type</th>\n",
       "      <th>reinforcement</th>\n",
       "      <th>supervised</th>\n",
       "      <th>unknown</th>\n",
       "      <th>unsupervised</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ml_anomaly_detection_production</th>\n",
       "      <td>27</td>\n",
       "      <td>275</td>\n",
       "      <td>75</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_automation</th>\n",
       "      <td>114</td>\n",
       "      <td>314</td>\n",
       "      <td>1157</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_defect_detection</th>\n",
       "      <td>20</td>\n",
       "      <td>288</td>\n",
       "      <td>329</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_manufacturing_optimization</th>\n",
       "      <td>297</td>\n",
       "      <td>1077</td>\n",
       "      <td>2455</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_planning_production</th>\n",
       "      <td>209</td>\n",
       "      <td>771</td>\n",
       "      <td>1260</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_plm</th>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>169</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_predictive_maintenance</th>\n",
       "      <td>168</td>\n",
       "      <td>1533</td>\n",
       "      <td>2359</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_process_control</th>\n",
       "      <td>203</td>\n",
       "      <td>976</td>\n",
       "      <td>1905</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_process_modeling</th>\n",
       "      <td>36</td>\n",
       "      <td>189</td>\n",
       "      <td>502</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_process_optimization</th>\n",
       "      <td>28</td>\n",
       "      <td>162</td>\n",
       "      <td>406</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_product_design</th>\n",
       "      <td>40</td>\n",
       "      <td>319</td>\n",
       "      <td>983</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_product_development</th>\n",
       "      <td>23</td>\n",
       "      <td>204</td>\n",
       "      <td>619</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_production_optimization</th>\n",
       "      <td>467</td>\n",
       "      <td>2412</td>\n",
       "      <td>4099</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_quality_control</th>\n",
       "      <td>32</td>\n",
       "      <td>475</td>\n",
       "      <td>785</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_robotics_production</th>\n",
       "      <td>80</td>\n",
       "      <td>131</td>\n",
       "      <td>633</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_rul</th>\n",
       "      <td>33</td>\n",
       "      <td>528</td>\n",
       "      <td>899</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ml_supply_chain</th>\n",
       "      <td>66</td>\n",
       "      <td>225</td>\n",
       "      <td>630</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ml_type                          reinforcement  supervised  unknown  \\\n",
       "query_id                                                              \n",
       "ml_anomaly_detection_production             27         275       75   \n",
       "ml_automation                              114         314     1157   \n",
       "ml_defect_detection                         20         288      329   \n",
       "ml_manufacturing_optimization              297        1077     2455   \n",
       "ml_planning_production                     209         771     1260   \n",
       "ml_plm                                       8          70      169   \n",
       "ml_predictive_maintenance                  168        1533     2359   \n",
       "ml_process_control                         203         976     1905   \n",
       "ml_process_modeling                         36         189      502   \n",
       "ml_process_optimization                     28         162      406   \n",
       "ml_product_design                           40         319      983   \n",
       "ml_product_development                      23         204      619   \n",
       "ml_production_optimization                 467        2412     4099   \n",
       "ml_quality_control                          32         475      785   \n",
       "ml_robotics_production                      80         131      633   \n",
       "ml_rul                                      33         528      899   \n",
       "ml_supply_chain                             66         225      630   \n",
       "\n",
       "ml_type                          unsupervised  \n",
       "query_id                                       \n",
       "ml_anomaly_detection_production           590  \n",
       "ml_automation                             146  \n",
       "ml_defect_detection                       120  \n",
       "ml_manufacturing_optimization             304  \n",
       "ml_planning_production                    193  \n",
       "ml_plm                                     14  \n",
       "ml_predictive_maintenance                 724  \n",
       "ml_process_control                        355  \n",
       "ml_process_modeling                        62  \n",
       "ml_process_optimization                    46  \n",
       "ml_product_design                         123  \n",
       "ml_product_development                     64  \n",
       "ml_production_optimization                581  \n",
       "ml_quality_control                        163  \n",
       "ml_robotics_production                     72  \n",
       "ml_rul                                    202  \n",
       "ml_supply_chain                            84  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency for each query\n",
    "df.explode(\"ml_type\").groupby([\"query_id\", \"ml_type\"]).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8940b752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_supervised       0.304121\n",
       "is_unsupervised     0.117473\n",
       "is_reinforcement    0.056581\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of abstracts that mention each ML category\n",
    "df[[\"is_supervised\", \"is_unsupervised\", \"is_reinforcement\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec1b18d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='ml_type'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot frequency of ML categories across all abstracts\n",
    "df[\"ml_type\"].explode().value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9176f824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>eid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>clean_abs</th>\n",
       "      <th>is_supervised</th>\n",
       "      <th>is_unsupervised</th>\n",
       "      <th>is_reinforcement</th>\n",
       "      <th>ml_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>ml_manufacturing_optimization</td>\n",
       "      <td>2-s2.0-85208191905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Hidden Costs of Surface Finish in Powder M...</td>\n",
       "      <td>© 2024 Advances in Powder Metallurgy and Parti...</td>\n",
       "      <td>advances in powder metallurgy and particulate ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[unknown]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21562</th>\n",
       "      <td>ml_production_optimization</td>\n",
       "      <td>2-s2.0-105004589842</td>\n",
       "      <td>10.1016/j.ejps.2025.107102</td>\n",
       "      <td>Testing on continuous production of mefenamic ...</td>\n",
       "      <td>© 2025 The AuthorsIn the pharmaceutical manufa...</td>\n",
       "      <td>the authorsin the pharmaceutical manufacturing...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[unknown]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            query_id                  eid  \\\n",
       "4945   ml_manufacturing_optimization   2-s2.0-85208191905   \n",
       "21562     ml_production_optimization  2-s2.0-105004589842   \n",
       "\n",
       "                              doi  \\\n",
       "4945                          NaN   \n",
       "21562  10.1016/j.ejps.2025.107102   \n",
       "\n",
       "                                                   title  \\\n",
       "4945   The Hidden Costs of Surface Finish in Powder M...   \n",
       "21562  Testing on continuous production of mefenamic ...   \n",
       "\n",
       "                                                abstract  \\\n",
       "4945   © 2024 Advances in Powder Metallurgy and Parti...   \n",
       "21562  © 2025 The AuthorsIn the pharmaceutical manufa...   \n",
       "\n",
       "                                               clean_abs  is_supervised  \\\n",
       "4945   advances in powder metallurgy and particulate ...          False   \n",
       "21562  the authorsin the pharmaceutical manufacturing...          False   \n",
       "\n",
       "       is_unsupervised  is_reinforcement    ml_type  \n",
       "4945             False             False  [unknown]  \n",
       "21562            False             False  [unknown]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of abstracts that were classified as \"unknown\"\n",
    "# Should analyze to improve keyword sets\n",
    "df[df[\"ml_type\"].apply(lambda x: x == [\"unknown\"])].sample(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcd9b0d",
   "metadata": {},
   "source": [
    "### Check most common ML method (most common keyword)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8abcb877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_text = \" \".join(df[\"clean_abs\"])\n",
    "\n",
    "# method_counts = collections.Counter()\n",
    "\n",
    "# for label, words in ml_keywords.items():\n",
    "#     for w in words:\n",
    "#         # Regex: match keyword as a whole word, case-insensitive\n",
    "#         pattern = rf\"\\b{re.escape(w)}\\b\"\n",
    "#         count = df[\"clean_abs\"].str.contains(pattern, regex=True, case=False).sum()\n",
    "#         method_counts[w] = count\n",
    "\n",
    "# method_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6707f48",
   "metadata": {},
   "source": [
    "### Notes on Keyword-Based Classification\n",
    "\n",
    "The keyword approach provides a simple first pass, but it has clear limitations:\n",
    "- Many abstracts are labeled **unknown** because keywords may be absent, implicit, or expressed differently.\n",
    "- Some methods overlap terminology (e.g., “semi-supervised”), which can lead to misclassification.\n",
    "- Context is ignored, so the presence of a term does not guarantee it is the main ML method.\n",
    "\n",
    "These limitations explain the large number of “unknown” cases and motivate using a more robust model-based classifier later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f21c5",
   "metadata": {},
   "source": [
    "## Training a Multi-Label ML-Method Classifier Using Keyword Pseudo-Labels\n",
    "\n",
    "- The keyword-based approach provides noisy but useful initial labels for each article (e.g., supervised / unsupervised / reinforcement).  \n",
    "- In the following steps, we use these pseudo-labels to train a **multi-label transformer model** (e.g., SciBERT or DistilBERT) on the abstracts. \n",
    "- This allows the model to learn richer linguistic patterns and produce more accurate classifications than the raw keyword method, while requiring **no manual labeling up front**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5f7febd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e25440bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_supervised       0.739758\n",
      "is_unsupervised     0.285746\n",
      "is_reinforcement    0.137631\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "label_cols = [\"is_supervised\", \"is_unsupervised\", \"is_reinforcement\"]\n",
    "\n",
    "# Keep only rows that have at least one positive label (optional but often useful)\n",
    "df_model = df.copy()\n",
    "mask_any_label = df_model[label_cols].sum(axis=1) > 0\n",
    "df_model = df_model[mask_any_label].reset_index(drop=True)\n",
    "\n",
    "print(df_model[label_cols].mean())  # quick check of label frequencies\n",
    "\n",
    "dataset = Dataset.from_pandas(df_model[[\"clean_abs\"] + label_cols])\n",
    "\n",
    "# Train/validation split\n",
    "splits = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_ds = splits[\"train\"]\n",
    "val_ds = splits[\"test\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a519c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 11/11 [00:00<00:00, 25.75ba/s]\n",
      "Creating CSV from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 28.45ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train_ds to: ../../data/processed/abstracts/scibert_2/train_ds.csv\n",
      "Saved val_ds to:   ../../data/processed/abstracts/scibert_2/val_ds.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure scibert directory exists\n",
    "scibert_path = processed_abstracts_path / \"scibert_2\"\n",
    "scibert_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save datasets\n",
    "train_path = scibert_path / \"train_ds.csv\"\n",
    "val_path = scibert_path / \"val_ds.csv\"\n",
    "\n",
    "train_ds.to_csv(train_path, index=False)\n",
    "val_ds.to_csv(val_path, index=False)\n",
    "\n",
    "print(f\"Saved train_ds to: {train_path}\")\n",
    "print(f\"Saved val_ds to:   {val_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c10a2a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_abs</th>\n",
       "      <th>is_supervised</th>\n",
       "      <th>is_unsupervised</th>\n",
       "      <th>is_reinforcement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>th european conference on information systems ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>copyright the authors this is an open access a...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ieeeartificial intelligence has been creating ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mechanical property prediction plays a crucial...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>by the authorsin the era of technology develop...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_abs  is_supervised  \\\n",
       "0  th european conference on information systems ...          False   \n",
       "1  copyright the authors this is an open access a...           True   \n",
       "2  ieeeartificial intelligence has been creating ...           True   \n",
       "3  mechanical property prediction plays a crucial...           True   \n",
       "4  by the authorsin the era of technology develop...           True   \n",
       "\n",
       "   is_unsupervised  is_reinforcement  \n",
       "0             True              True  \n",
       "1            False              True  \n",
       "2            False             False  \n",
       "3            False             False  \n",
       "4            False             False  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.to_pandas().head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b49c055f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10759/10759 [00:01<00:00, 7048.39 examples/s]\n",
      "Map: 100%|██████████| 2690/2690 [00:00<00:00, 7108.04 examples/s]\n",
      "Map: 100%|██████████| 10759/10759 [00:04<00:00, 2426.34 examples/s]\n",
      "Map: 100%|██████████| 2690/2690 [00:01<00:00, 2433.10 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"  # or \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "label_cols = [\"is_supervised\", \"is_unsupervised\", \"is_reinforcement\"]\n",
    "\n",
    "# Add a single multi-label 'labels' column\n",
    "def add_labels(example):\n",
    "    example[\"labels\"] = [float(example[c]) for c in label_cols]\n",
    "    return example\n",
    "\n",
    "train_ds_l = train_ds.map(add_labels)\n",
    "val_ds_l   = val_ds.map(add_labels)\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"clean_abs\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "train_ds_tok = train_ds_l.map(tokenize_batch, batched=True)\n",
    "val_ds_tok   = val_ds_l.map(tokenize_batch, batched=True)\n",
    "\n",
    "def set_format(ds):\n",
    "    return ds.with_format(\n",
    "        type=\"torch\",\n",
    "        columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    )\n",
    "\n",
    "train_ds_tok = set_format(train_ds_tok)\n",
    "val_ds_tok   = set_format(val_ds_tok)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label_cols),\n",
    "    problem_type=\"multi_label_classification\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef60ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8\n",
      "Tesla P100-PCIE-16GB\n",
      "(6, 0)\n",
      "['sm_70', 'sm_75', 'sm_80', 'sm_86', 'sm_90', 'sm_100', 'sm_120']\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.cuda.get_device_capability())\n",
    "print(torch.cuda.get_arch_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73f00e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1251351/310402851.py:31: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nSearch for `cudaErrorNoKernelImageForDevice' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     17\u001b[39m training_args = TrainingArguments(\n\u001b[32m     18\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./ml_type_model\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     eval_strategy=\u001b[33m\"\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     logging_steps=\u001b[32m50\u001b[39m,\n\u001b[32m     29\u001b[39m )\n\u001b[32m     31\u001b[39m trainer = Trainer(\n\u001b[32m     32\u001b[39m     model=model,\n\u001b[32m     33\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     compute_metrics=compute_metrics,\n\u001b[32m     38\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/transformers/trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/transformers/trainer.py:2674\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2667\u001b[39m context = (\n\u001b[32m   2668\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2670\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2671\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2672\u001b[39m )\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2677\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2679\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2680\u001b[39m ):\n\u001b[32m   2681\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2682\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/transformers/trainer.py:4020\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4017\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   4019\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4020\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4022\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   4023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4024\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4025\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   4026\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/transformers/trainer.py:4110\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4108\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   4109\u001b[39m     inputs = {**inputs, **kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m4110\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4111\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   4112\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   4113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1482\u001b[39m, in \u001b[36mBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1474\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1475\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1476\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1477\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1478\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1479\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1480\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1482\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1483\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1484\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1488\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1489\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1490\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1494\u001b[39m pooled_output = outputs[\u001b[32m1\u001b[39m]\n\u001b[32m   1496\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.dropout(pooled_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:936\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    934\u001b[39m         token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n\u001b[32m--> \u001b[39m\u001b[32m936\u001b[39m embedding_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    945\u001b[39m     attention_mask = torch.ones((batch_size, seq_length + past_key_values_length), device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:179\u001b[39m, in \u001b[36mBertEmbeddings.forward\u001b[39m\u001b[34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[39m\n\u001b[32m    176\u001b[39m         token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=\u001b[38;5;28mself\u001b[39m.position_ids.device)\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     inputs_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m token_type_embeddings = \u001b[38;5;28mself\u001b[39m.token_type_embeddings(token_type_ids)\n\u001b[32m    182\u001b[39m embeddings = inputs_embeds + token_type_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/torch/nn/modules/sparse.py:192\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/ml-catalogue/lib/python3.11/site-packages/torch/nn/functional.py:2542\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2536\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2537\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2538\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2539\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2540\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2541\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2542\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: no kernel image is available for execution on the device\nSearch for `cudaErrorNoKernelImageForDevice' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = 1 / (1 + np.exp(-logits))           # sigmoid\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    # Flatten over labels\n",
    "    return {\n",
    "        \"f1_micro\": f1_score(labels, preds, average=\"micro\", zero_division=0),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "        \"precision_micro\": precision_score(labels, preds, average=\"micro\", zero_division=0),\n",
    "        \"recall_micro\": recall_score(labels, preds, average=\"micro\", zero_division=0),\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ml_type_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_micro\",\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds_tok,\n",
    "    eval_dataset=val_ds_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f7b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ml_types_batched(texts, trainer, threshold=0.5, batch_size=64, max_length=512):\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "\n",
    "    model = trainer.model\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "\n",
    "        enc = tokenizer(\n",
    "            batch_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        enc = {k: v.to(model.device) for k, v in enc.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(**enc).logits\n",
    "\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        preds = (probs >= threshold).astype(int)\n",
    "\n",
    "        all_probs.append(probs)\n",
    "        all_preds.append(preds)\n",
    "\n",
    "    all_probs = np.vstack(all_probs)\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    return all_preds, all_probs\n",
    "\n",
    "\n",
    "texts = df[\"clean_abs\"].tolist()\n",
    "preds, probs = predict_ml_types_batched(texts, trainer, batch_size=64, threshold=0.5)\n",
    "\n",
    "for i, col in enumerate(label_cols):\n",
    "    df[f\"pred_{col}\"] = preds[:, i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcaa52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(label_cols):\n",
    "    df[f\"pred_{col}\"] = preds[:, i]\n",
    "\n",
    "pred_cols = [f\"pred_{c}\" for c in label_cols]\n",
    "cols_to_save = [\n",
    "    \"query_id\", \"eid\", \"doi\", \"title\", \"abstract\", \"clean_abs\",\n",
    "] + label_cols + pred_cols\n",
    "\n",
    "save_path = scibert_path / \"abstracts_with_predictions.csv\"\n",
    "df[cols_to_save].to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"Saved predictions to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf44d2a9",
   "metadata": {},
   "source": [
    "## Analyze Scibert Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e1db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = Path(\"../../data/processed/abstracts/scibert_2/abstracts_with_predictions.csv\")\n",
    "\n",
    "pred_cols = [\"pred_is_supervised\",\"pred_is_unsupervised\",\"pred_is_reinforcement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b52a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(pred_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd519c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[pred_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[pred_cols].mean().plot(kind=\"bar\")\n",
    "plt.title(\"Share of abstracts predicted to use each ML type\")\n",
    "plt.ylabel(\"Fraction of abstracts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2332f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4), constrained_layout=True)\n",
    "\n",
    "for ax, col in zip(axes, label_cols):\n",
    "    ctab = pd.crosstab(df[col], df[f\"pred_{col}\"], rownames=[\"keyword\"], colnames=[\"model\"])\n",
    "    \n",
    "    sns.heatmap(\n",
    "        ctab,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        cbar=False,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(col.replace(\"is_\", \"\").capitalize())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small per-label stats\n",
    "for col in label_cols:\n",
    "    pred = df[f\"pred_{col}\"]\n",
    "    true = df[col]\n",
    "\n",
    "    tp = ((true == 1) & (pred == 1)).sum()\n",
    "    fp = ((true == 0) & (pred == 1)).sum()\n",
    "    fn = ((true == 1) & (pred == 0)).sum()\n",
    "    tn = ((true == 0) & (pred == 0)).sum()\n",
    "\n",
    "    print(\n",
    "        f\"\\n=== {col} ===\\n\"\n",
    "        f\"TP: {tp}\\nFP: {fp}\\nFN: {fn}\\nTN: {tn}\\n\"\n",
    "        f\"Precision: {tp/(tp+fp+1e-9):.3f}\\n\"\n",
    "        f\"Recall:    {tp/(tp+fn+1e-9):.3f}\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f0ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a few rows where the model disagrees with keyword labels (only among keyword-labeled rows)\n",
    "\n",
    "mask_labeled = df[label_cols].sum(axis=1) > 0\n",
    "mask_disagree = (df[[f\"pred_{c}\" for c in label_cols]].values != df[label_cols].values).any(axis=1)\n",
    "\n",
    "df_mismatch = df[mask_labeled & mask_disagree]\n",
    "\n",
    "df_mismatch.sample(10)[\n",
    "    [\"doi\", \"title\", \"clean_abs\"] \n",
    "    + label_cols \n",
    "    + [f\"pred_{c}\" for c in label_cols]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbab2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483ac769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-catalogue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
